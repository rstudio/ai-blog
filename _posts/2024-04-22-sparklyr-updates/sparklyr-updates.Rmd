---
title: "News from the sparkly-verse"
description: >
  TODO: Add description
author:
  - name: Edgar Ruiz
    affiliation: Posit
    affiliation_url: https://www.posit.co/
slug: sparklyr-updates-q1-2024
date: 2024-04-22
categories:
  - Packages/Releases  
  - Spark
  - R
output:
  distill::distill_article:
    self_contained: false
    toc: true
preview: images/sparklyr.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  eval = FALSE
  )
```



## sparklyr 1.8.5

### Fixes

- Fixes quoting issue with `dbplyr` 2.5.0 (#3429)

- Fixes Windows OS identification (#3426)

### Package improvements

- Removes dependency on `tibble`, all calls are now redirected to `dplyr` (#3399)

- Removes dependency on `rapddirs` (#3401): 
  - Backwards compatibility with `sparklyr` 0.5 is no longer needed
  - Replicates selection of cache directory 

- Converts `spark_apply()` to a method (#3418)

## pysparklyr 0.1.4

### New

* Adds support for `spark_apply()` via the `rpy2` Python library
  * It will not automatically distribute packages, it will assume that the
  necessary packages are already installed in each node. This also means that
  the `packages` argument is not supported
  * As in its original implementation, schema inferring works, and as with the
  original implementation, it has a performance cost. Unlike the original, the 
  Databricks, and Spark, Connect version will return a 'columns' specification
  that you can use for the next time you run the call.
  
### Improvements

* At connection time, it enables Arrow by default. It does this by setting
these two configuration settings to true: 
  * `spark.sql.execution.arrow.pyspark.enabled`
  * `spark.sql.execution.arrow.pyspark.fallback.enabled`


## sparkxgb 

