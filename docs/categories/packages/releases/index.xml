<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>RStudio AI Blog</title>
    <link>https://blogs.rstudio.com/tensorflow/</link>
    <atom:link href="https://blogs.rstudio.com/tensorflow/index.xml" rel="self" type="application/rss+xml"/>
    <description>News, concepts, and applications as regards deep learning, probabilistic computation, distributed computing and machine learning automation from R.
</description>
    <image>
      <title>RStudio AI Blog</title>
      <url>https://blogs.rstudio.com/tensorflow/images/favicon.png</url>
      <link>https://blogs.rstudio.com/tensorflow/</link>
    </image>
    <generator>Distill</generator>
    <lastBuildDate>Sun, 18 Oct 2020 00:00:00 +0000</lastBuildDate>
    <item>
      <title>sparklyr.flint 0.2: ASOF Joins, OLS Regression, and additional summarizers</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-10-12-sparklyr-flint-0.2.0-released</link>
      <description>


&lt;p&gt;Since &lt;a href="https://cran.r-project.org/web/packages/sparklyr.flint/index.html"&gt;&lt;code&gt;sparklyr.flint&lt;/code&gt;&lt;/a&gt;, a &lt;a href="https://sparklyr.ai"&gt;&lt;code&gt;sparklyr&lt;/code&gt;&lt;/a&gt; extension for leveraging &lt;a href="https://github.com/twosigma/flint"&gt;Flint&lt;/a&gt; time series functionalities through &lt;code&gt;sparklyr&lt;/code&gt;, was &lt;a href="https://blogs.rstudio.com/ai/posts/2020-09-07-sparklyr-flint"&gt;introduced&lt;/a&gt; in September, we have made a number of enhancements to it, and have successfully submitted &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2 to CRAN.&lt;/p&gt;
&lt;p&gt;In this blog post, we highlight the following new features and improvements from &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#asof-joins"&gt;ASOF Joins&lt;/a&gt; of Timeseries RDDs&lt;/li&gt;
&lt;li&gt;&lt;a href="#ols-regression"&gt;OLS Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#additional-summarizers"&gt;Additional Summarizers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#better-integration-with-sparklyr"&gt;Better Integration With &lt;code&gt;sparklyr&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="asof-joins"&gt;ASOF Joins&lt;/h2&gt;
&lt;p&gt;For those unfamiliar with the term, ASOF joins are temporal join operations based on inexact matching of timestamps. Within the context of &lt;a href="https://spark.apache.org"&gt;Apache Spark&lt;/a&gt;, a join operation, loosely speaking, matches records from two data frames (let’s call them &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt;) based on some criteria. A temporal join implies matching records in &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt; based on timestamps, and with inexact matching of timestamps permitted, it is typically useful to join &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt; along one of the following temporal directions:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Looking behind: if a record from &lt;code&gt;left&lt;/code&gt; has timestamp &lt;code&gt;t&lt;/code&gt;, then it gets matched with ones from &lt;code&gt;right&lt;/code&gt; having the most recent timestamp less than or equal to &lt;code&gt;t&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Looking ahead: if a record from &lt;code&gt;left&lt;/code&gt; has timestamp &lt;code&gt;t,&lt;/code&gt; then it gets matched with ones from &lt;code&gt;right&lt;/code&gt; having the smallest timestamp greater than or equal to (or alternatively, strictly greater than) &lt;code&gt;t&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, oftentimes it is not useful to consider two timestamps as “matching” if they are too far apart. Therefore, an additional constraint on the maximum amount of time to look behind or look ahead is usually also part of an ASOF join operation.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2, all ASOF join functionalities of Flint are accessible via the &lt;code&gt;asof_join()&lt;/code&gt; method. For example, given 2 timeseries RDDs &lt;code&gt;left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(sparklyr)
library(sparklyr.flint)

sc &amp;lt;- spark_connect(master = &amp;quot;local&amp;quot;)
left &amp;lt;- copy_to(sc, tibble::tibble(t = seq(10), u = seq(10))) %&amp;gt;%
  from_sdf(is_sorted = TRUE, time_unit = &amp;quot;SECONDS&amp;quot;, time_column = &amp;quot;t&amp;quot;)
right &amp;lt;- copy_to(sc, tibble::tibble(t = seq(10) + 1, v = seq(10) + 1L)) %&amp;gt;%
  from_sdf(is_sorted = TRUE, time_unit = &amp;quot;SECONDS&amp;quot;, time_column = &amp;quot;t&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following prints the result of matching each record from &lt;code&gt;left&lt;/code&gt; with the most recent record(s) from &lt;code&gt;right&lt;/code&gt; that are at most 1 second behind.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(asof_join(left, right, tol = &amp;quot;1s&amp;quot;, direction = &amp;quot;&amp;gt;=&amp;quot;) %&amp;gt;% to_sdf())

## # Source: spark&amp;lt;?&amp;gt; [?? x 3]
##    time                    u     v
##    &amp;lt;dttm&amp;gt;              &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
##  1 1970-01-01 00:00:01     1    NA
##  2 1970-01-01 00:00:02     2     2
##  3 1970-01-01 00:00:03     3     3
##  4 1970-01-01 00:00:04     4     4
##  5 1970-01-01 00:00:05     5     5
##  6 1970-01-01 00:00:06     6     6
##  7 1970-01-01 00:00:07     7     7
##  8 1970-01-01 00:00:08     8     8
##  9 1970-01-01 00:00:09     9     9
## 10 1970-01-01 00:00:10    10    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whereas if we change the temporal direction to “&amp;lt;”, then each record from &lt;code&gt;left&lt;/code&gt; will be matched with any record(s) from &lt;code&gt;right&lt;/code&gt; that is strictly in the future and is at most 1 second ahead of the current record from &lt;code&gt;left&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(asof_join(left, right, tol = &amp;quot;1s&amp;quot;, direction = &amp;quot;&amp;lt;&amp;quot;) %&amp;gt;% to_sdf())

## # Source: spark&amp;lt;?&amp;gt; [?? x 3]
##    time                    u     v
##    &amp;lt;dttm&amp;gt;              &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
##  1 1970-01-01 00:00:01     1     2
##  2 1970-01-01 00:00:02     2     3
##  3 1970-01-01 00:00:03     3     4
##  4 1970-01-01 00:00:04     4     5
##  5 1970-01-01 00:00:05     5     6
##  6 1970-01-01 00:00:06     6     7
##  7 1970-01-01 00:00:07     7     8
##  8 1970-01-01 00:00:08     8     9
##  9 1970-01-01 00:00:09     9    10
## 10 1970-01-01 00:00:10    10    11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice regardless of which temporal direction is selected, an outer-left join is always performed (i.e., all timestamp values and &lt;code&gt;u&lt;/code&gt; values of &lt;code&gt;left&lt;/code&gt; from above will always be present in the output, and the &lt;code&gt;v&lt;/code&gt; column in the output will contain &lt;code&gt;NA&lt;/code&gt; whenever there is no record from &lt;code&gt;right&lt;/code&gt; that meets the matching criteria).&lt;/p&gt;
&lt;h2 id="ols-regression"&gt;OLS Regression&lt;/h2&gt;
&lt;p&gt;You might be wondering whether the version of this functionality in Flint is more or less identical to &lt;code&gt;lm()&lt;/code&gt; in R. Turns out it has much more to offer than &lt;code&gt;lm()&lt;/code&gt; does. An OLS regression in Flint will compute useful metrics such as &lt;a href="https://en.wikipedia.org/wiki/Akaike_information_criterion"&gt;Akaike information criterion&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion"&gt;Bayesian information criterion&lt;/a&gt;, both of which are useful for model selection purposes, and the calculations of both are parallelized by Flint to fully utilize computational power available in a Spark cluster. In addition, Flint supports ignoring regressors that are constant or nearly constant, which becomes useful when an intercept term is included. To see why this is the case, we need to briefly examine the goal of the OLS regression, which is to find some column vector of coefficients &lt;span class="math inline"&gt;\(\mathbf{\beta}\)&lt;/span&gt; that minimizes &lt;span class="math inline"&gt;\(\|\mathbf{y} - \mathbf{X} \mathbf{\beta}\|^2\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(\mathbf{y}\)&lt;/span&gt; is the column vector of response variables, and &lt;span class="math inline"&gt;\(\mathbf{X}\)&lt;/span&gt; is a matrix consisting of columns of regressors plus an entire column of &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;s representing the intercept terms. The solution to this problem is &lt;span class="math inline"&gt;\(\mathbf{\beta} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y}\)&lt;/span&gt;, assuming the Gram matrix &lt;span class="math inline"&gt;\(\mathbf{X}^\intercal\mathbf{X}\)&lt;/span&gt; is non-singular. However, if &lt;span class="math inline"&gt;\(\mathbf{X}\)&lt;/span&gt; contains a column of all &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;s of intercept terms, and another column formed by a regressor that is constant (or nearly so), then columns of &lt;span class="math inline"&gt;\(\mathbf{X}\)&lt;/span&gt; will be linearly dependent (or nearly so) and &lt;span class="math inline"&gt;\(\mathbf{X}^\intercal\mathbf{X}\)&lt;/span&gt; will be singular (or nearly so), which presents an issue computation-wise. However, if a regressor is constant, then it essentially plays the same role as the intercept terms do. So simply excluding such a constant regressor in &lt;span class="math inline"&gt;\(\mathbf{X}\)&lt;/span&gt; solves the problem. Also, speaking of inverting the Gram matrix, readers remembering the concept of “condition number” from numerical analysis must be thinking to themselves how computing &lt;span class="math inline"&gt;\(\mathbf{\beta} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y}\)&lt;/span&gt; could be numerically unstable if &lt;span class="math inline"&gt;\(\mathbf{X}^\intercal\mathbf{X}\)&lt;/span&gt; has a large condition number. This is why Flint also outputs the condition number of the Gram matrix in the OLS regression result, so that one can sanity-check the underlying quadratic minimization problem being solved is well-conditioned.&lt;/p&gt;
&lt;p&gt;So, to summarize, the OLS regression functionality implemented in Flint not only outputs the solution to the problem, but also calculates useful metrics that help data scientists assess the sanity and predictive quality of the resulting model.&lt;/p&gt;
&lt;p&gt;To see OLS regression in action with &lt;code&gt;sparklyr.flint&lt;/code&gt;, one can run the following example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mtcars_sdf &amp;lt;- copy_to(sc, mtcars, overwrite = TRUE) %&amp;gt;%
  dplyr::mutate(time = 0L)
mtcars_ts &amp;lt;- from_sdf(mtcars_sdf, is_sorted = TRUE, time_unit = &amp;quot;SECONDS&amp;quot;)
model &amp;lt;- ols_regression(mtcars_ts, mpg ~ hp + wt) %&amp;gt;% to_sdf()

print(model %&amp;gt;% dplyr::select(akaikeIC, bayesIC, cond))

## # Source: spark&amp;lt;?&amp;gt; [?? x 3]
##   akaikeIC bayesIC    cond
##      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1     155.    159. 345403.

# ^ output says condition number of the Gram matrix was within reason&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and obtain &lt;span class="math inline"&gt;\(\mathbf{\beta}\)&lt;/span&gt;, the vector of optimal coefficients, with the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;print(model %&amp;gt;% dplyr::pull(beta))

## [[1]]
## [1] -0.03177295 -3.87783074&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="additional-summarizers"&gt;Additional Summarizers&lt;/h2&gt;
&lt;p&gt;The EWMA (Exponential Weighted Moving Average), EMA half-life, and the standardized moment summarizers (namely, skewness and kurtosis) along with a few others which were missing in &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.1 are now fully supported in &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2.&lt;/p&gt;
&lt;h2 id="better-integration-with-sparklyr"&gt;Better Integration With &lt;code&gt;sparklyr&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;While &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.1 included a &lt;code&gt;collect()&lt;/code&gt; method for exporting data from a Flint time-series RDD to an R data frame, it did not have a similar method for extracting the underlying Spark data frame from a Flint time-series RDD. This was clearly an oversight. In &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2, one can call &lt;code&gt;to_sdf()&lt;/code&gt; on a timeseries RDD to get back a Spark data frame that is usable in &lt;code&gt;sparklyr&lt;/code&gt; (e.g., as shown by &lt;code&gt;model %&amp;gt;% to_sdf() %&amp;gt;% dplyr::select(...)&lt;/code&gt; examples from above). One can also get to the underlying Spark data frame JVM object reference by calling &lt;code&gt;spark_dataframe()&lt;/code&gt; on a Flint time-series RDD (this is usually unnecessary in vast majority of &lt;code&gt;sparklyr&lt;/code&gt; use cases though).&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have presented a number of new features and improvements introduced in &lt;code&gt;sparklyr.flint&lt;/code&gt; 0.2 and deep-dived into some of them in this blog post. We hope you are as excited about them as we are.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;h2 id="acknowledgement"&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;The author would like to thank Mara (&lt;a href="https://github.com/batpigandme"&gt;@batpigandme&lt;/a&gt;), Sigrid (&lt;a href="https://github.com/skeydan"&gt;@skeydan&lt;/a&gt;), and Javier (&lt;a href="https://github.com/javierluraschi"&gt;@javierluraschi&lt;/a&gt;) for their fantastic editorial inputs on this blog post!&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5 xmlns:distill="https://distill.pub/journal/">21fc4b2e51e9d4a153f2dae536e7279b</distill:md5>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-10-12-sparklyr-flint-0.2.0-released</guid>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-10-12-sparklyr-flint-0.2.0-released/images/sparklyr-flint-0.2.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>sparklyr 1.4: Weighted Sampling, Tidyr Verbs, Robust Scaler, RAPIDS, and more</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-09-30-sparklyr-1.4.0-released</link>
      <description>Sparklyr 1.4 is now available! This release comes with delightful new features such as weighted sampling and tidyr verbs support for Spark dataframes, robust scaler for standardizing data based on median and interquartile range, spark_connect interface for RAPIDS GPU acceleration plugin, as well as a number of dplyr-related improvements.</description>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-09-30-sparklyr-1.4.0-released</guid>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-09-30-sparklyr-1.4.0-released/images/sparklyr-1.4.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Please allow me to introduce myself: Torch for R</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-09-29-introducing-torch-for-r</link>
      <description>Today, we are excited to introduce torch, an R package that allows you to use PyTorch-like functionality natively from R. No Python installation is required: torch is built directly on top of libtorch, a C++ library that provides the tensor-computation and automatic-differentiation capabilities essential to building neural networks.</description>
      <category>Packages/Releases</category>
      <category>Torch</category>
      <category>R</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-09-29-introducing-torch-for-r</guid>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-09-29-introducing-torch-for-r/images/pt.png" medium="image" type="image/png" width="919" height="264"/>
    </item>
    <item>
      <title>sparklyr 1.3: Higher-order Functions, Avro and Custom Serializers</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released</link>
      <description>Sparklyr 1.3 is now available, featuring exciting new functionalities such as integration of Spark higher-order functions and data import/export in Avro and in user-defined serialization formats.</description>
      <category>Packages/Releases</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released</guid>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released/images/sparklyr-1.3.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>sparklyr 1.2: Foreach, Spark 3.0 and Databricks Connect</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released</link>
      <description>A new sparklyr release is now available. This sparklyr 1.2 release features new functionalities such as support for Databricks Connect, a Spark backend for the 'foreach' package, inter-op improvements for working with Spark 3.0 preview, as well as a number of bug fixes and improvements addressing user-visible pain points.</description>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released</guid>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released/images/sparklyr.png" medium="image" type="image/png" width="1241" height="307"/>
    </item>
    <item>
      <title>pins 0.4: Versioning</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Javier Luraschi</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04</link>
      <description>A new release of pins is available on CRAN today. This release adds support to time travel across dataset versions, which improves collaboration and protects your code from breaking when remote resources change unexpectedly.</description>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Data Management</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04</guid>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>tfhub: R interface to TensorFlow Hub</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0</link>
      <description>TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0</guid>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0/images/tfhub.png" medium="image" type="image/png" width="1365" height="909"/>
    </item>
    <item>
      <title>Getting started with Keras from R - the 2020 edition</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020</link>
      <description>Looking for materials to get started with deep learning from R? This post presents useful tutorials, guides, and background documentation on the new TensorFlow for R website.  Advanced users will find pointers to applications of new release 2.0 (or upcoming 2.1!) features alluded to in the recent TensorFlow 2.0 post.</description>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020</guid>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020/images/website.png" medium="image" type="image/png" width="1591" height="725"/>
    </item>
    <item>
      <title>tfprobability 0.8 on CRAN: Now how can you use it?</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran</link>
      <description>Part of the r-tensorflow ecosystem, tfprobability is an R wrapper to TensorFlow Probability, the Python probabilistic programming framework developed by Google. We take the occasion of tfprobability's acceptance on CRAN to give a high-level introduction, highlighting interesting use cases and applications.</description>
      <category>Probabilistic ML/DL</category>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran</guid>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran/images/tfprobability.png" medium="image" type="image/png" width="518" height="600"/>
    </item>
    <item>
      <title>Innocent unicorns considered harmful? How to experiment with GPT-2 from R</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sigrid Keydana</dc:creator>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Javier Luraschi</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2</link>
      <description>Is society ready to deal with challenges brought about by artificially-generated  information - fake images, fake videos, fake text? While this post won't answer that question, it should help form an opinion on the threat exerted by fake text as of this writing, autumn 2019.  We introduce gpt2, an R package that wraps OpenAI's public implementation of GPT-2, the language model that early this year surprised the NLP community with the unprecedented quality of its creations.</description>
      <category>Natural Language Processing</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2</guid>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>TensorFlow 2.0 is here - what changes for R users?</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges</link>
      <description>TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges</guid>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/images/thumb.png" medium="image" type="image/png" width="400" height="400"/>
    </item>
    <item>
      <title>Auto-Keras: Tuning-free deep learning from R</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Juan Cruz Rodriguez</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras</link>
      <description>Sometimes in deep learning, architecture design and hyperparameter tuning pose substantial challenges. Using Auto-Keras, none of these is needed: We start a search procedure and extract the best-performing model. This post presents Auto-Keras in action on the well-known MNIST dataset.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras</guid>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras/images/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>lime v0.4: The Kitten Picture Edition</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Lin Pedersen</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition</link>
      <description>A new major release of lime has landed on CRAN. lime is an R port of the Python library of the same name by Marco Ribeiro that allows the user to pry open black box machine learning models and explain their outcomes on a per-observation basis</description>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <category>Explainability</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition</guid>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition/images/unnamed-chunk-8-1.png" medium="image" type="image/png" width="1344" height="672"/>
    </item>
    <item>
      <title>R Interface to Google CloudML</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml</link>
      <description>We are excited to announce the availability of the cloudml package, which provides an R interface to Google Cloud Machine Learning Engine. CloudML provides a number of services including on-demand access to training on GPUs and hyperparameter tuning to optimize key attributes of model architectures.</description>
      <category>Cloud</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml</guid>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml/images/cloudml.png" medium="image" type="image/png" width="394" height="211"/>
    </item>
    <item>
      <title>tfruns: Tools for TensorFlow Training Runs</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns</link>
      <description>The tfruns package provides a suite of tools for tracking, visualizing, and managing TensorFlow training runs and experiments from R.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns</guid>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns/preview.png" medium="image" type="image/png" width="2006" height="1116"/>
    </item>
    <item>
      <title>Keras for R</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r</link>
      <description>We are excited to announce that the keras package is now available on CRAN. The package provides an R interface to Keras, a high-level neural networks API developed with a focus on enabling fast experimentation.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r</guid>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r/preview.png" medium="image" type="image/png" width="669" height="414"/>
    </item>
    <item>
      <title>TensorFlow Estimators</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Yuan Tang</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r</link>
      <description>The tfestimators package is an R interface to TensorFlow Estimators, a high-level API that provides implementations of many different model types including linear models and deep neural networks.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r</guid>
      <pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r/tensorflow-architecture.png" medium="image" type="image/png" width="1198" height="796"/>
    </item>
    <item>
      <title>TensorFlow v1.3 Released</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released</link>
      <description>The final release of TensorFlow v1.3 is now available. This release marks the initial availability of several canned estimators including DNNClassifier and  DNNRegressor.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released</guid>
      <pubDate>Thu, 17 Aug 2017 00:00:00 +0000</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released/tensorflow-logo.png" medium="image" type="image/png" width="3876" height="741"/>
    </item>
  </channel>
</rss>
