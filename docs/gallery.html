<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>RStudio AI Blog: Gallery of featured posts</title>


  <link rel="icon" type="image/png" href="images/favicon.png"/>


  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="RStudio AI Blog: Gallery of featured posts"/>
  <meta property="og:type" content="article"/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="RStudio AI Blog"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="RStudio AI Blog: Gallery of featured posts"/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","listing"]}},"value":[{"type":"character","attributes":{},"value":["Gallery of featured posts"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["posts"]}},"value":[{"type":"character","attributes":{},"value":["2020-07-31-fnn-vae-for-noisy-timeseries","2020-07-20-fnn-lstm","2020-06-24-deep-attractors","2020-05-15-model-inversion-attacks","2020-02-19-kl-divergence","2019-11-27-gettingstarted-2020","2019-12-20-differential-privacy","2019-12-10-variational-gaussian-process","2019-05-24-varying-slopes","2019-10-03-intro-to-hmc","2019-08-23-unet","2019-03-15-concepts-way-to-dl","2019-04-05-bijectors-flows","2019-02-07-audio-background","2019-01-24-vq-vae","2018-11-12-uncertainty_estimates_dropout","2018-10-22-mmd-vae","2018-09-26-embeddings-recommender","2018-09-20-eager-pix2pix","2018-09-17-eager-captioning","2018-06-06-simple-audio-classification-keras","2018-07-17-activity-detection","2018-07-30-attention-layer","2018-09-07-getting-started","2018-01-24-keras-fraud-autoencoder","2018-01-09-keras-duplicate-questions-quora","2018-01-29-dl-for-cancer-immunotherapy","2018-06-25-sunspots-lstm","2017-12-20-time-series-forecasting-with-recurrent-neural-networks","2017-12-07-text-classification-with-keras","2017-12-14-image-classification-on-small-datasets","2017-12-22-word-embeddings-with-keras","2018-09-10-eager-style-transfer"]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->

  <script type="application/javascript">

    window.headroom_prevent_pin = false;

    window.document.addEventListener("DOMContentLoaded", function (event) {

      // initialize headroom for banner
      var header = $('header').get(0);
      var headerHeight = header.offsetHeight;
      var headroom = new Headroom(header, {
        onPin : function() {
          if (window.headroom_prevent_pin) {
            window.headroom_prevent_pin = false;
            headroom.unpin();
          }
        }
      });
      headroom.init();
      if(window.location.hash)
        headroom.unpin();
      $(header).addClass('headroom--transition');

      // offset scroll location for banner on hash change
      // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
      window.addEventListener("hashchange", function(event) {
        window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
      });

      // responsive menu
      $('.distill-site-header').each(function(i, val) {
        var topnav = $(this);
        var toggle = topnav.find('.nav-toggle');
        toggle.on('click', function() {
          topnav.toggleClass('responsive');
        });
      });

      // nav dropdowns
      $('.nav-dropbtn').click(function(e) {
        $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
        $(this).parent().siblings('.nav-dropdown')
           .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $("body").click(function(e){
        $('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $(".nav-dropdown").click(function(e){
        e.stopPropagation();
      });
    });
  </script>

  <style type="text/css">

  /* Theme (user-documented overrideables for nav appearance) */

  .distill-site-nav {
    color: rgba(255, 255, 255, 0.8);
    background-color: #455a64;
    font-size: 15px;
    font-weight: 300;
  }

  .distill-site-nav a {
    color: inherit;
    text-decoration: none;
  }

  .distill-site-nav a:hover {
    color: white;
  }

  @media print {
    .distill-site-nav {
      display: none;
    }
  }

  .distill-site-header {

  }

  .distill-site-footer {

  }


  /* Site Header */

  .distill-site-header {
    width: 100%;
    box-sizing: border-box;
    z-index: 3;
  }

  .distill-site-header .nav-left {
    display: inline-block;
    margin-left: 8px;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header .nav-left {
      margin-left: 0;
    }
  }


  .distill-site-header .nav-right {
    float: right;
    margin-right: 8px;
  }

  .distill-site-header a,
  .distill-site-header .title {
    display: inline-block;
    text-align: center;
    padding: 14px 10px 14px 10px;
  }

  .distill-site-header .title {
    font-size: 18px;
  }

  .distill-site-header .logo {
    padding: 0;
  }

  .distill-site-header .logo img {
    display: none;
    max-height: 20px;
    width: auto;
    margin-bottom: -4px;
  }

  .distill-site-header .nav-image img {
    max-height: 18px;
    width: auto;
    display: inline-block;
    margin-bottom: -3px;
  }



  @media screen and (min-width: 1000px) {
    .distill-site-header .logo img {
      display: inline-block;
    }
    .distill-site-header .nav-left {
      margin-left: 20px;
    }
    .distill-site-header .nav-right {
      margin-right: 20px;
    }
    .distill-site-header .title {
      padding-left: 12px;
    }
  }


  .distill-site-header .nav-toggle {
    display: none;
  }

  .nav-dropdown {
    display: inline-block;
    position: relative;
  }

  .nav-dropdown .nav-dropbtn {
    border: none;
    outline: none;
    color: rgba(255, 255, 255, 0.8);
    padding: 16px 10px;
    background-color: transparent;
    font-family: inherit;
    font-size: inherit;
    font-weight: inherit;
    margin: 0;
    margin-top: 1px;
    z-index: 2;
  }

  .nav-dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 200px;
    border: 1px solid rgba(0,0,0,0.15);
    border-radius: 4px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
    z-index: 1;
    margin-top: 2px;
    white-space: nowrap;
    padding-top: 4px;
    padding-bottom: 4px;
  }

  .nav-dropdown-content hr {
    margin-top: 4px;
    margin-bottom: 4px;
    border: none;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .nav-dropdown-active {
    display: block;
  }

  .nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
    color: black;
    padding: 6px 24px;
    text-decoration: none;
    display: block;
    text-align: left;
  }

  .nav-dropdown-content .nav-dropdown-header {
    display: block;
    padding: 5px 24px;
    padding-bottom: 0;
    text-transform: uppercase;
    font-size: 14px;
    color: #999999;
    white-space: nowrap;
  }

  .nav-dropdown:hover .nav-dropbtn {
    color: white;
  }

  .nav-dropdown-content a:hover {
    background-color: #ddd;
    color: black;
  }

  .nav-right .nav-dropdown-content {
    margin-left: -45%;
    right: 0;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
    .distill-site-header a.nav-toggle {
      float: right;
      display: block;
    }
    .distill-site-header .title {
      margin-left: 0;
    }
    .distill-site-header .nav-right {
      margin-right: 0;
    }
    .distill-site-header {
      overflow: hidden;
    }
    .nav-right .nav-dropdown-content {
      margin-left: 0;
    }
  }


  @media screen and (max-width: 768px) {
    .distill-site-header.responsive {position: relative;}
    .distill-site-header.responsive a.nav-toggle {
      position: absolute;
      right: 0;
      top: 0;
    }
    .distill-site-header.responsive a,
    .distill-site-header.responsive .nav-dropdown {
      display: block;
      text-align: left;
    }
    .distill-site-header.responsive .nav-left,
    .distill-site-header.responsive .nav-right {
      width: 100%;
    }
    .distill-site-header.responsive .nav-dropdown {float: none;}
    .distill-site-header.responsive .nav-dropdown-content {position: relative;}
    .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
      display: block;
      width: 100%;
      text-align: left;
    }
  }

  /* Site Footer */

  .distill-site-footer {
    width: 100%;
    overflow: hidden;
    box-sizing: border-box;
    z-index: 3;
    margin-top: 30px;
    padding-top: 30px;
    padding-bottom: 30px;
    text-align: center;
  }

  /* Headroom */

  d-title {
    padding-top: 6rem;
  }

  @media print {
    d-title {
      padding-top: 4rem;
    }
  }

  .headroom {
    z-index: 1000;
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
  }

  .headroom--transition {
    transition: all .4s ease-in-out;
  }

  .headroom--unpinned {
    top: -100px;
  }

  .headroom--pinned {
    top: 0;
  }

  </style>

  <link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
  <link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
  <script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for table of contents */

  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }

  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }

  .d-toc a {
    border-bottom: none;
  }

  .d-toc ul {
    padding-left: 0;
  }

  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }

  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }

  .d-toc li {
    margin-bottom: 0.9em;
  }

  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }

  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }



  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */

  d-code {
    overflow-x: auto !important;
  }

  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  pre.text-output {

    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  @media(min-width: 768px) {

  d-code {
    overflow-x: visible !important;
  }

  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }

  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }



  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }


  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="site_libs/header-attrs-2.3/header-attrs.js"></script>
  <script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-20375833-3');
  </script>
  <!--/radix_placeholder_site_in_header-->


</head>

<body class="layout-listing">

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Gallery of featured posts","authors":[]}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="images/rstudio.png"/>
</span>
<a href="index.html" class="title">AI Blog</a>
</div>
<div class="nav-right">
<a href="index.html">Home</a>
<a href="gallery.html">Gallery</a>
<a href="about.html">About</a>
<a href="contributing.html">Contributing</a>
<a href="index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->
<!--radix_placeholder_article_listing-->

<style type="text/css">

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 1em;
}

.posts-list .metadata .tags {
  margin-top: 1em;
}

.posts-list .tags .tag {
  color: rgba(0,0,0,0.67);
  padding: 0.3em 0.5em;
  margin: 0;
  font-size: 80%;
  border: 1px solid rgba(0,0,0,0.4);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 35%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 15%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 72%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}

.downlevel .posts-list .post-preview {
  color: inherit;
}

</style>

<script type="application/javascript">

function init_posts_list() {

  function load_image(img) {
    var src = $(img).attr('data-src');
    if (src) {
      $(img).attr('src', src);
      $(img).load(function() {
        img.removeAttribute('data-src');
      });
    }
  }

  function set_posts_visible(posts, visible) {
    if (visible) {

      // show bottom border by default
      $(posts).removeClass('post-preview-last');

      // apply limits if need be
      var max_posts = 25;
      var apply_limits = $('.posts-container').hasClass('posts-apply-limit');
      if (apply_limits && posts.length > max_posts) {
        posts = $(posts).slice(0, max_posts);
      } else {
        $('.posts-more a').addClass('hidden');
      }

      // apply last style
      $(posts.slice(-1)[0]).addClass('post-preview-last');

      $(posts).removeClass('hidden');
      $(posts).find('img[data-src]').each(function(i, img) {
        load_image(img);
      });
    } else {
      $(posts).addClass('hidden');
    }
  }

  function apply_hash_filter() {

    // clear active state
    $('.categories .active').removeClass('active');

    // mark all posts invisible to start
    set_posts_visible($('.posts-list').children('a'), false);

    // if we have a hash filter
    if (window.location.hash) {

      // mark posts that match the category visible
      var page_category = window.location.hash.replace("#", "");
      var posts = $('.post-metadata').map(function(idx, script) {
        var metadata = $.parseJSON($(script).html());
        var post = null;
        $.each(metadata.categories, function(idx, category) {
          category = category.replace(/ /g,"_");
          if (category == page_category) {
            post = $(script).parent().get();
            return false;
          }
        });
        return post;
      });
      set_posts_visible(posts, true);

      // mark the hash active
      $('.categories li>a[href="' + window.location.hash + '"]').addClass('active');

    } else {

      // no hash filter, make all posts visible (subject to max display)
      set_posts_visible($('.posts-list').children(), true);

    }
  }

  // more articles
  function apply_post_limits(apply) {
    if (apply) {
      $('.posts-container').addClass('posts-apply-limit');
      $('.posts-more a').removeClass('hidden');
    } else {
      $('.posts-container').removeClass('posts-apply-limit');
      $('.posts-more a').addClass('hidden');
    }
  }

  // hash filter handling
  apply_hash_filter();
  $(window).on('hashchange',function() {
    apply_post_limits(true);
    apply_hash_filter();
  });

  // more articles link
  $('.posts-more a').click(function(e) {
    e.preventDefault();
    apply_post_limits(false);
    apply_hash_filter();
    return false;
  });

}

</script>



<div class="posts-container posts-with-sidebar posts-apply-limit l-screen-inset">
<div class="posts-list">
<h1 class="posts-list-caption">Gallery of featured posts</h1>
<a href="posts/2020-07-31-fnn-vae-for-noisy-timeseries/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["R","TensorFlow/Keras","Time Series","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">July 31, 2020</div>
</div>
<div class="thumbnail">
<img data-src="posts/2020-07-31-fnn-vae-for-noisy-timeseries/images/kb.jpg"/>
</div>
<div class="description">
<h2>FNN-VAE for noisy time series forecasting</h2>
<p>In the last part of this mini-series on forecasting with false nearest neighbors (FNN) loss, we replace the LSTM autoencoder from the previous post by a convolutional VAE, resulting in equivalent prediction performance but significantly lower training time. In addition, we find that FNN regularization is of great help when an underlying deterministic process is obscured by substantial noise.</p>
</div>
</a>
<a href="posts/2020-07-20-fnn-lstm/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["R","TensorFlow/Keras","Time Series","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">July 20, 2020</div>
</div>
<div class="thumbnail">
<img data-src="posts/2020-07-20-fnn-lstm/images/old_faithful.jpg"/>
</div>
<div class="description">
<h2>Time series prediction with FNN-LSTM</h2>
<p>In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, "vanilla LSTM", FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast.</p>
</div>
</a>
<a href="posts/2020-06-24-deep-attractors/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["R","TensorFlow/Keras","Time Series","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">June 24, 2020</div>
</div>
<div class="thumbnail">
<img data-src="posts/2020-06-24-deep-attractors/images/x_z.gif"/>
</div>
<div class="description">
<h2>Deep attractors: Where deep learning meets chaos</h2>
<p>In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.</p>
</div>
</a>
<a href="posts/2020-05-15-model-inversion-attacks/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["R","Privacy & Security","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">May 15, 2020</div>
</div>
<div class="thumbnail">
<img data-src="posts/2020-05-15-model-inversion-attacks/images/results.png"/>
</div>
<div class="description">
<h2>Hacking deep learning: model inversion attack by example</h2>
<p>Compared to other applications, deep learning models might not seem too likely as victims of privacy attacks. However, methods exist to determine whether an entity was used in the training set (an adversarial attack called member inference), and techniques subsumed under "model inversion" allow to reconstruct raw data input given just model output (and sometimes, context information). This post shows an end-to-end example of model inversion, and explores mitigation strategies using TensorFlow Privacy.</p>
</div>
</a>
<a href="posts/2020-02-19-kl-divergence/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Probabilistic ML/DL","Concepts"]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 19, 2020</div>
</div>
<div class="thumbnail">
<img data-src="posts/2020-02-19-kl-divergence/images/ultimatemachine.jpg"/>
</div>
<div class="description">
<h2>Infinite surprise - the iridescent personality of Kullback-Leibler divergence</h2>
<p>Kullback-Leibler divergence is not just used to train variational autoencoders or Bayesian networks (and not just a hard-to-pronounce thing). It is a fundamental concept in information theory, put to use in a vast range of applications. Most interestingly, it's not always about constraint, regularization or compression. Quite on the contrary, sometimes it is about novelty, discovery and surprise.</p>
</div>
</a>
<a href="posts/2019-11-27-gettingstarted-2020/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Packages/Releases","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 27, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-11-27-gettingstarted-2020/images/website.png"/>
</div>
<div class="description">
<h2>Getting started with Keras from R - the 2020 edition</h2>
<p>Looking for materials to get started with deep learning from R? This post presents useful tutorials, guides, and background documentation on the new TensorFlow for R website.  Advanced users will find pointers to applications of new release 2.0 (or upcoming 2.1!) features alluded to in the recent TensorFlow 2.0 post.</p>
</div>
</a>
<a href="posts/2019-12-20-differential-privacy/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Privacy & Security","TensorFlow/Keras","Time Series"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-12-20-differential-privacy/images/cat.png"/>
</div>
<div class="description">
<h2>Differential Privacy with TensorFlow</h2>
<p>Differential Privacy guarantees that results of a database query are basically independent of the presence in the data of a single individual. Applied to machine learning, we expect that no single training example influences the parameters of the trained model in a substantial way. This post introduces TensorFlow Privacy, a library built on top of TensorFlow, that can be used to train differentially private deep learning models from R.</p>
</div>
</a>
<a href="posts/2019-12-10-variational-gaussian-process/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Probabilistic ML/DL","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 10, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-12-10-variational-gaussian-process/images/kernel_cookbook.png"/>
</div>
<div class="description">
<h2>Gaussian Process Regression with tfprobability</h2>
<p>Continuing our tour of applications of TensorFlow Probability (TFP), after Bayesian Neural Networks, Hamiltonian Monte Carlo and State Space Models, here we show an example of Gaussian Process Regression. In fact, what we see is a rather "normal" Keras network, defined and trained in pretty much the usual way, with TFP's Variational Gaussian Process layer pulling off all the magic.</p>
</div>
</a>
<a href="posts/2019-05-24-varying-slopes/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Bayesian Modeling","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">May 24, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-05-24-varying-slopes/images/thumb.png"/>
</div>
<div class="description">
<h2>Hierarchical partial pooling, continued: Varying slopes models with TensorFlow Probability</h2>
<p>This post builds on our recent introduction to multi-level modeling with tfprobability, the R wrapper to TensorFlow Probability. We show how to pool not just mean values ("intercepts"), but also relationships ("slopes"), thus enabling models to learn from data in an even broader way. Again, we use an example from Richard McElreath's "Statistical Rethinking"; the terminology as well as the way we present this topic are largely owed to this book.</p>
</div>
</a>
<a href="posts/2019-10-03-intro-to-hmc/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Bayesian Modeling","Concepts"]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 3, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-10-03-intro-to-hmc/images/mb.png"/>
</div>
<div class="description">
<h2>On leapfrogs, crashing satellites, and going nuts: A very first conceptual introduction to Hamiltonian Monte Carlo</h2>
<p>TensorFlow Probability, and its R wrapper tfprobability, provide Markov Chain Monte Carlo (MCMC) methods that were used in a number of recent posts on this blog. These posts were directed to users already comfortable with the method, and terminology, per se, which readers mainly interested in deep learning won't necessarily be. Here we try to make up leeway, introducing Hamitonian Monte Carlo (HMC) as well as a few often-heard "buzzwords" accompanying it, always striving to keep in mind what it is all "for".</p>
</div>
</a>
<a href="posts/2019-08-23-unet/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Image Recognition & Image Processing","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">Aug. 23, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-08-23-unet/images/unet.png"/>
</div>
<div class="description">
<h2>Image segmentation with U-Net</h2>
<p>In image segmentation, every pixel of an image is assigned a class. Depending on the application, classes could be different cell types; or the task could be binary, as in "cancer cell yes or no?". Area of application notwithstanding, the established neural network architecture of choice is U-Net. In this post, we show how to preprocess data and train a U-Net model on the Kaggle Carvana image segmentation data.</p>
</div>
</a>
<a href="posts/2019-03-15-concepts-way-to-dl/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Meta","Concepts"]}</script>
<div class="metadata">
<div class="publishedDate">March 15, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-03-15-concepts-way-to-dl/images/prev.jpg"/>
</div>
<div class="description">
<h2>Math, code, concepts: A third road to deep learning</h2>
<p>Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it's all about.</p>
</div>
</a>
<a href="posts/2019-04-05-bijectors-flows/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Probabilistic ML/DL","TensorFlow/Keras","Concepts","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">April 5, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-04-05-bijectors-flows/images/flows.png"/>
</div>
<div class="description">
<h2>Getting into the flow: Bijectors in TensorFlow Probability</h2>
<p>Normalizing flows are one of the lesser known, yet fascinating and successful architectures in unsupervised deep learning. In this post we provide a basic introduction to flows using tfprobability, an R wrapper to TensorFlow Probability. Upcoming posts will build on this, using more complex flows on more complex data.</p>
</div>
</a>
<a href="posts/2019-02-07-audio-background/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Concepts","Audio Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Feb. 7, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-02-07-audio-background/images/seven2.png"/>
</div>
<div class="description">
<h2>Audio classification with Keras: Looking closer at the non-deep learning parts</h2>
<p>Sometimes, deep learning is seen - and welcomed - as a way to avoid laborious preprocessing of data. However, there are cases where preprocessing of sorts does not only help improve prediction, but constitutes a fascinating topic in itself. One such case is audio classification. In this post, we build on a previous post on this blog, this time focusing on explaining some of the non-deep learning background. We then link the concepts explained to updated for near-future releases TensorFlow code.</p>
</div>
</a>
<a href="posts/2019-01-24-vq-vae/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Probabilistic ML/DL","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 24, 2019</div>
</div>
<div class="thumbnail">
<img data-src="posts/2019-01-24-vq-vae/images/thumb1.png"/>
</div>
<div class="description">
<h2>Discrete Representation Learning with VQ-VAE and TensorFlow Probability</h2>
<p>Mostly when thinking of Variational Autoencoders (VAEs), we picture the prior as an isotropic Gaussian. But this is by no means a necessity. The Vector Quantised Variational Autoencoder (VQ-VAE) described in van den Oord et al's "Neural Discrete Representation Learning" features a discrete latent space that allows to learn impressively concise latent representations. In this post, we combine elements of Keras, TensorFlow, and TensorFlow Probability to see if we can generate convincing letters resembling those in Kuzushiji-MNIST.</p>
</div>
</a>
<a href="posts/2018-11-12-uncertainty_estimates_dropout/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Image Recognition & Image Processing","Probabilistic ML/DL","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">Nov. 12, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-11-12-uncertainty_estimates_dropout/images/thumb.png"/>
</div>
<div class="description">
<h2>You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks</h2>
<p>In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is.</p>
</div>
</a>
<a href="posts/2018-10-22-mmd-vae/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Unsupervised Learning","Image Recognition & Image Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Oct. 22, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-10-22-mmd-vae/images/thumb.png"/>
</div>
<div class="description">
<h2>Representation learning with MMD-VAE</h2>
<p>Like GANs, variational autoencoders (VAEs) are often used to generate images. However, VAEs add an additional promise: namely, to model an underlying latent space. Here, we first look at a typical implementation that maximizes the evidence lower bound. Then, we compare it to one of the more recent competitors, MMD-VAE, from the Info-VAE (information maximizing VAE) family.</p>
</div>
</a>
<a href="posts/2018-09-26-embeddings-recommender/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Tabular Data"]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 26, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-09-26-embeddings-recommender/images/m.png"/>
</div>
<div class="description">
<h2>Collaborative filtering with embeddings</h2>
<p>Embeddings are not just for use in natural language processing. Here we apply embeddings to a common task in collaborative filtering - predicting user ratings - and on our way, strive for a better understanding of what an embedding layer really does.</p>
</div>
</a>
<a href="posts/2018-09-20-eager-pix2pix/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Image Recognition & Image Processing","Unsupervised Learning"]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 20, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-09-20-eager-pix2pix/images/pix2pixlosses.png"/>
</div>
<div class="description">
<h2>Image-to-image translation with pix2pix</h2>
<p>Conditional GANs (cGANs) may be used to generate one type of object based on another - e.g., a map based on a photo, or a color video based on black-and-white. Here, we show how to implement the pix2pix approach with Keras and eager execution.</p>
</div>
</a>
<a href="posts/2018-09-17-eager-captioning/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Natural Language Processing","TensorFlow/Keras","Image Recognition & Image Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 17, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-09-17-eager-captioning/images/showattendandtell.png"/>
</div>
<div class="description">
<h2>Attention-based Image Captioning with Keras</h2>
<p>Image captioning is a challenging task at intersection of vision and language. Here, we demonstrate using Keras and eager execution to incorporate an attention mechanism that allows the network to concentrate on image features relevant to the current state of text generation.</p>
</div>
</a>
<a href="posts/2018-06-06-simple-audio-classification-keras/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Audio Processing"]}</script>
<div class="metadata">
<div class="publishedDate">June 6, 2018</div>
</div>
<div class="thumbnail">
<img data-src="https://upload.wikimedia.org/wikipedia/commons/6/61/FFT-Time-Frequency-View.png"/>
</div>
<div class="description">
<h2>Simple Audio Classification with Keras</h2>
<p>In this tutorial we will build a deep learning model to classify words. We will use the Speech Commands dataset which consists of 65,000 one-second audio files of people saying 30 different words.</p>
</div>
</a>
<a href="posts/2018-07-17-activity-detection/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":[]}</script>
<div class="metadata">
<div class="publishedDate">July 17, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-07-17-activity-detection/index_files/figure-html5/unnamed-chunk-8-1.png"/>
</div>
<div class="description">
<h2>Classifying physical activity from smartphone data</h2>
<p>Using Keras to train a convolutional neural network to classify physical activity. The dataset was built from the recordings of 30 subjects performing basic activities and postural transitions while carrying a waist-mounted smartphone with embedded inertial sensors.</p>
</div>
</a>
<a href="posts/2018-07-30-attention-layer/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["Natural Language Processing","TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">July 30, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-07-30-attention-layer/images/attention.png"/>
</div>
<div class="description">
<h2>Attention-based Neural Machine Translation with Keras</h2>
<p>As sequence to sequence prediction tasks get more involved, attention mechanisms have proven helpful. A prominent example is neural machine translation. Following a recent Google Colaboratory notebook, we show how to implement attention in R.</p>
</div>
</a>
<a href="posts/2018-09-07-getting-started/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras"]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 7, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-09-07-getting-started/images/digits.png"/>
</div>
<div class="description">
<h2>Getting started with deep learning in R</h2>
<p>Many fields are benefiting from the use of deep learning, and with the R keras, tensorflow and related packages, you can now easily do state of the art deep learning in R. In this post, we want to give some orientation as to how to best get started.</p>
</div>
</a>
<a href="posts/2018-01-24-keras-fraud-autoencoder/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Unsupervised Learning","Cloud"]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 25, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-01-24-keras-fraud-autoencoder/images/preview.png"/>
</div>
<div class="description">
<h2>Predicting Fraud with Autoencoders and Keras</h2>
<p>In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset.</p>
</div>
</a>
<a href="posts/2018-01-09-keras-duplicate-questions-quora/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Natural Language Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 9, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-01-09-keras-duplicate-questions-quora/keras-duplicate-questions-quora.png"/>
</div>
<div class="description">
<h2>Classifying Duplicate Questions from Quora with Keras</h2>
<p>In this post we will use Keras to classify duplicated questions from Quora. Our implementation is inspired by the Siamese Recurrent Architecture, with modifications to the similarity measure and the embedding layers (the original paper uses pre-trained word vectors)</p>
</div>
</a>
<a href="posts/2018-01-29-dl-for-cancer-immunotherapy/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Tabular Data"]}</script>
<div class="metadata">
<div class="publishedDate">Jan. 29, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-01-29-dl-for-cancer-immunotherapy/images/01_ffn_02_results_3_by_3_confusion_matrix.png"/>
</div>
<div class="description">
<h2>Deep Learning for Cancer Immunotherapy</h2>
<p>The aim of this post is to illustrate how deep learning is being applied in cancer immunotherapy (Immuno-oncology or Immunooncology) - a cancer treatment strategy, where the aim is to utilize the cancer patient's own immune system to fight the cancer.</p>
</div>
</a>
<a href="posts/2018-06-25-sunspots-lstm/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Time Series"]}</script>
<div class="metadata">
<div class="publishedDate">June 25, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-06-25-sunspots-lstm/images/backtested_test.png"/>
</div>
<div class="description">
<h2>Predicting Sunspot Frequency with Keras</h2>
<p>In this post we will examine making time series predictions using the sunspots dataset that ships with base R. Sunspots are dark spots on the sun, associated with lower temperature. Our post will focus on both how to apply deep learning to time series forecasting, and how to properly apply cross validation in this domain.</p>
</div>
</a>
<a href="posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Time Series"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 20, 2017</div>
</div>
<div class="thumbnail">
<img data-src="posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/images/jena_temp-r.png"/>
</div>
<div class="description">
<h2>Time Series Forecasting with Recurrent Neural Networks</h2>
<p>In this post, we'll review three advanced techniques for improving the performance and generalization power of recurrent neural networks.  We'll demonstrate all three concepts on a temperature-forecasting problem, where you have access to a time series of data points coming from sensors installed on the roof of a building.</p>
</div>
</a>
<a href="posts/2017-12-07-text-classification-with-keras/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Natural Language Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 7, 2017</div>
</div>
<div class="thumbnail">
<img data-src="posts/2017-12-07-text-classification-with-keras/images/training-history.png"/>
</div>
<div class="description">
<h2>Deep Learning for Text Classification with Keras</h2>
<p>Two-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. In this excerpt from the book Deep Learning with R, you'll learn to classify movie reviews as positive or negative, based on the text content of the reviews.</p>
</div>
</a>
<a href="posts/2017-12-14-image-classification-on-small-datasets/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Image Recognition & Image Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 14, 2017</div>
</div>
<div class="thumbnail">
<img data-src="posts/2017-12-14-image-classification-on-small-datasets/images/swapping_fc_classifier.png"/>
</div>
<div class="description">
<h2>Image Classification on Small Datasets with Keras</h2>
<p>Having to train an image-classification model using very little data is a common situation, in this article we review three techniques for tackling this problem including feature extraction and fine tuning from a pretrained network.</p>
</div>
</a>
<a href="posts/2017-12-22-word-embeddings-with-keras/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Natural Language Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Dec. 22, 2017</div>
</div>
<div class="thumbnail">
<img data-src="posts/2017-12-22-word-embeddings-with-keras/word-embeddings-with-keras.png"/>
</div>
<div class="description">
<h2>Word Embeddings with Keras</h2>
<p>Word embedding is a method used to map words of a vocabulary to dense vectors of real numbers where semantically similar words are mapped to nearby points. In this example we'll use Keras to generate word embeddings for the Amazon Fine Foods Reviews dataset.</p>
</div>
</a>
<a href="posts/2018-09-10-eager-style-transfer/" class="post-preview">
<script class="post-metadata" type="text/json">{"categories":["TensorFlow/Keras","Unsupervised Learning","Image Recognition & Image Processing"]}</script>
<div class="metadata">
<div class="publishedDate">Sept. 10, 2018</div>
</div>
<div class="thumbnail">
<img data-src="posts/2018-09-10-eager-style-transfer/images/preview.png"/>
</div>
<div class="description">
<h2>Neural style transfer with eager execution and Keras</h2>
<p>Continuing our series on combining Keras with TensorFlow eager execution, we show how to implement neural style transfer in a straightforward way. Based on this easy-to-adapt example, you can easily perform style transfer on your own images.</p>
</div>
</a>
</div>
<div class="posts-sidebar">
<div class="sidebar-section categories">
<h3>Categories</h3>
<ul>
<li>
<a href="#Audio_Processing">Audio Processing</a>
<span class="category-count">(2)</span>
</li>
<li>
<a href="#Bayesian_Modeling">Bayesian Modeling</a>
<span class="category-count">(2)</span>
</li>
<li>
<a href="#Cloud">Cloud</a>
<span class="category-count">(1)</span>
</li>
<li>
<a href="#Concepts">Concepts</a>
<span class="category-count">(5)</span>
</li>
<li>
<a href="#Image_Recognition_&amp;_Image_Processing">Image Recognition &amp; Image Processing</a>
<span class="category-count">(7)</span>
</li>
<li>
<a href="#Meta">Meta</a>
<span class="category-count">(1)</span>
</li>
<li>
<a href="#Natural_Language_Processing">Natural Language Processing</a>
<span class="category-count">(5)</span>
</li>
<li>
<a href="#Packages/Releases">Packages/Releases</a>
<span class="category-count">(1)</span>
</li>
<li>
<a href="#Privacy_&amp;_Security">Privacy &amp; Security</a>
<span class="category-count">(2)</span>
</li>
<li>
<a href="#Probabilistic_ML/DL">Probabilistic ML/DL</a>
<span class="category-count">(5)</span>
</li>
<li>
<a href="#R">R</a>
<span class="category-count">(4)</span>
</li>
<li>
<a href="#Tabular_Data">Tabular Data</a>
<span class="category-count">(2)</span>
</li>
<li>
<a href="#TensorFlow/Keras">TensorFlow/Keras</a>
<span class="category-count">(29)</span>
</li>
<li>
<a href="#Time_Series">Time Series</a>
<span class="category-count">(6)</span>
</li>
<li>
<a href="#Unsupervised_Learning">Unsupervised Learning</a>
<span class="category-count">(9)</span>
</li>
</ul>
</div>
</div>
<div class="posts-more">
<a href="#">More articles &raquo;</a>
</div>
</div>
<!--/radix_placeholder_article_listing-->

<div class="d-title">
<h1>Gallery of featured posts</h1>

</div>


<div class="d-article">

<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
