<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: TensorFlow Addons and classic Keras</title>

<meta property="description" itemprop="description" content="Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-05-16"/>
<meta property="article:created" itemprop="dateCreated" content="2020-05-16"/>
<meta name="article:author" content="Turgut Abdullayev"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: TensorFlow Addons and classic Keras"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/images/tfaddons.png"/>
<meta property="og:image:width" content="2074"/>
<meta property="og:image:height" content="2400"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: TensorFlow Addons and classic Keras"/>
<meta property="twitter:description" content="Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/images/tfaddons.png"/>
<meta property="twitter:image:width" content="2074"/>
<meta property="twitter:image:height" content="2400"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: TensorFlow Addons and classic Keras"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/05/16"/>
<meta name="citation_publication_date" content="2020/05/16"/>
<meta name="citation_author" content="Turgut Abdullayev"/>
<meta name="citation_author_institution" content="Baku State University"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Gaussian error linear units (gelus);citation_publication_date=2016;citation_author=Dan Hendrycks;citation_author=Kevin Gimpel"/>
  <meta name="citation_reference" content="citation_title=Group normalization;citation_publication_date=2018;citation_author=Yuxin Wu;citation_author=Kaiming He"/>
  <meta name="citation_reference" content="citation_title=Generalized intersection over union: A metric and a loss for bounding box regression;citation_publication_date=2019;citation_author=Hamid Rezatofighi;citation_author=Nathan Tsoi;citation_author=JunYoung Gwak;citation_author=Amir Sadeghian;citation_author=Ian Reid;citation_author=Silvio Savarese"/>
  <meta name="citation_reference" content="citation_title=IoU loss for 2D/3D object detection;citation_publication_date=2019;citation_author=Dingfu Zhou;citation_author=Jin Fang;citation_author=Xibin Song;citation_author=Chenye Guan;citation_author=Junbo Yin;citation_author=Yuchao Dai;citation_author=Ruigang Yang"/>
  <meta name="citation_reference" content="citation_title=On the variance of the adaptive learning rate and beyond;citation_publication_date=2019;citation_author=Liyuan Liu;citation_author=Haoming Jiang;citation_author=Pengcheng He;citation_author=Weizhu Chen;citation_author=Xiaodong Liu;citation_author=Jianfeng Gao;citation_author=Jiawei Han"/>
  <meta name="citation_reference" content="citation_title=Lookahead optimizer: K steps forward, 1 step back;citation_publication_date=2019;citation_author=Michael R. Zhang;citation_author=James Lucas;citation_author=Geoffrey Hinton;citation_author=Jimmy Ba"/>
  <meta name="citation_reference" content="citation_title=Attention is all you need;citation_publication_date=2017;citation_author=Ashish Vaswani;citation_author=Noam Shazeer;citation_author=Niki Parmar;citation_author=Jakob Uszkoreit;citation_author=Llion Jones;citation_author=Aidan N. Gomez;citation_author=Lukasz Kaiser;citation_author=Illia Polosukhin"/>
  <meta name="citation_reference" content="citation_title=Efficient estimation of word representations in vector space;citation_publication_date=2013;citation_author=Tomas Mikolov;citation_author=Kai Chen;citation_author=Greg Corrado;citation_author=Jeffrey Dean"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","categories","creative_commons","repository_url","bibliography","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["TensorFlow Addons and classic Keras"]},{"type":"character","attributes":{},"value":["Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation"]}},"value":[{"type":"character","attributes":{},"value":["Turgut Abdullayev"]},{"type":"character","attributes":{},"value":["https://github.com/henry090"]},{"type":"character","attributes":{},"value":["Baku State University"]}]}]},{"type":"character","attributes":{},"value":["05-16-2020"]},{"type":"character","attributes":{},"value":["TensorFlow/Keras","Packages/Releases"]},{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["https://github.com/henry090/tfaddons_intro"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","toc_depth"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[2]}]}]},{"type":"character","attributes":{},"value":["images/tfaddons.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","files/new_k.rds","files/old_k.rds","files/tune.csv","images/activations.png","images/bert.png","images/dino_transformer.jpeg","images/giou.png","images/group_norm.png","images/lookahead.png","images/tfaddons.png","tfaddons_files/bowser-1.9.3/bowser.min.js","tfaddons_files/crosstalk-1.1.0.1/css/crosstalk.css","tfaddons_files/crosstalk-1.1.0.1/js/crosstalk.js","tfaddons_files/crosstalk-1.1.0.1/js/crosstalk.js.map","tfaddons_files/crosstalk-1.1.0.1/js/crosstalk.min.js","tfaddons_files/crosstalk-1.1.0.1/js/crosstalk.min.js.map","tfaddons_files/DiagrammeR-styles-0.2/styles.css","tfaddons_files/distill-2.2.21/template.v2.js","tfaddons_files/echarts4r-4.3.2/custom/renderers.js","tfaddons_files/echarts4r-4.3.2/dataTool.min.js","tfaddons_files/echarts4r-4.3.2/echarts-gl.min.js","tfaddons_files/echarts4r-4.3.2/echarts.min.js","tfaddons_files/echarts4r-4.3.2/ecStat.min.js","tfaddons_files/echarts4r-4.3.2/plugins/echarts-graph-modularity.min.js","tfaddons_files/echarts4r-4.3.2/plugins/echarts-liquidfill.min.js","tfaddons_files/echarts4r-4.3.2/plugins/echarts-wordcloud.min.js","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/echarts-leaflet.js","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/images/layers-2x.png","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/images/layers.png","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/images/marker-icon-2x.png","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/images/marker-icon.png","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/images/marker-shadow.png","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/leaflet.css","tfaddons_files/echarts4r-4.3.2/plugins/leaflet/leaflet.js","tfaddons_files/echarts4r-4.3.2/themes/auritus.js","tfaddons_files/echarts4r-4.3.2/themes/chalk.js","tfaddons_files/echarts4r-4.3.2/themes/dark.js","tfaddons_files/echarts4r-4.3.2/themes/essos.js","tfaddons_files/echarts4r-4.3.2/themes/halloween.js","tfaddons_files/echarts4r-4.3.2/themes/infographic.js","tfaddons_files/echarts4r-4.3.2/themes/macarons.js","tfaddons_files/echarts4r-4.3.2/themes/purple-passion.js","tfaddons_files/echarts4r-4.3.2/themes/roma.js","tfaddons_files/echarts4r-4.3.2/themes/shine.js","tfaddons_files/echarts4r-4.3.2/themes/vintage.js","tfaddons_files/echarts4r-4.3.2/themes/walden.js","tfaddons_files/echarts4r-4.3.2/themes/wef.js","tfaddons_files/echarts4r-4.3.2/themes/weforum.js","tfaddons_files/echarts4r-4.3.2/themes/westeros.js","tfaddons_files/echarts4r-4.3.2/themes/wonderland.js","tfaddons_files/echarts4r-4.3.2/world.js","tfaddons_files/echarts4r-binding-0.2.3/echarts4r.js","tfaddons_files/figure-html5/unnamed-chunk-16-1.png","tfaddons_files/figure-html5/unnamed-chunk-21-1.png","tfaddons_files/figure-html5/unnamed-chunk-22-1.png","tfaddons_files/figure-html5/unnamed-chunk-23-1.png","tfaddons_files/grViz-binding-1.0.6.1/grViz.js","tfaddons_files/htmlwidgets-1.5.1/htmlwidgets.js","tfaddons_files/jquery-1.11.3/jquery-AUTHORS.txt","tfaddons_files/jquery-1.11.3/jquery.js","tfaddons_files/jquery-1.11.3/jquery.min.js","tfaddons_files/jquery-1.11.3/jquery.min.map","tfaddons_files/mapbox-0.38.0/mapbox-gl.css","tfaddons_files/mapbox-0.38.0/mapbox-gl.js","tfaddons_files/plotly-binding-4.9.2.1/plotly.js","tfaddons_files/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css","tfaddons_files/plotly-main-1.52.2/plotly-latest.min.js","tfaddons_files/typedarray-0.1/typedarray.min.js","tfaddons_files/viz-1.8.2/viz.js","tfaddons_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative;}
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

d-code {
  overflow-x: auto !important;
}

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {

d-code {
  overflow-x: visible !important;
}

pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      // map unknown languages to "clike" (without this they just dissapear)
      if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                               "javascript", "js", "julia", "lua", "markdown",
                               "markup", "mathml", "python", "svg", "xml"]) == -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
  <script src="../../site_libs/plotly-binding-4.9.2.1/plotly.js"></script>
  <script src="../../site_libs/typedarray-0.1/typedarray.min.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <link href="../../site_libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
  <script src="../../site_libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
  <link href="../../site_libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
  <script src="../../site_libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
  <script src="../../site_libs/viz-1.8.2/viz.js"></script>
  <link href="../../site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
  <script src="../../site_libs/grViz-binding-1.0.6.1/grViz.js"></script>
  <link href="../../site_libs/echarts4r-4.3.2/plugins/leaflet/leaflet.css" rel="stylesheet" />
  <script src="../../site_libs/echarts4r-4.3.2/echarts.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/echarts-gl.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/ecStat.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/dataTool.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/world.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/plugins/echarts-wordcloud.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/plugins/echarts-liquidfill.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/plugins/echarts-graph-modularity.min.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/plugins/leaflet/leaflet.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/plugins/leaflet/echarts-leaflet.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/dark.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/vintage.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/westeros.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/essos.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/wonderland.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/walden.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/chalk.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/infographic.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/macarons.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/roma.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/shine.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/purple-passion.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/halloween.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/wef.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/weforum.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/themes/auritus.js"></script>
  <script src="../../site_libs/echarts4r-4.3.2/custom/renderers.js"></script>
  <link href="../../site_libs/mapbox-0.38.0/mapbox-gl.css" rel="stylesheet" />
  <script src="../../site_libs/mapbox-0.38.0/mapbox-gl.js"></script>
  <script src="../../site_libs/echarts4r-binding-0.2.3/echarts4r.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-102325748-2"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-102325748-2');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"TensorFlow Addons and classic Keras","description":"Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library.","authors":[{"author":"Turgut Abdullayev","authorURL":"https://github.com/henry090","affiliation":"Baku State University","affiliationURL":"#"}],"publishedDate":"2020-05-16T00:00:00.000+04:00","citationText":"Abdullayev, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>TensorFlow Addons and classic Keras</h1>
<p>Keras is a very powerful framework for building Neural Networks. However, in a fast-moving field like ML, there are a lot of features that are not integrated into core TensorFlow. In this post, we will introduce new types of callbacks, activations, layers, optimizers, losses, metrics, and many more interesting features that are developed by SIG-addons, and fully compatible with the Keras library.</p>
</div>

<div class="d-byline">
  Turgut Abdullayev <a href="https://github.com/henry090" class="uri">https://github.com/henry090</a> (Baku State University)
  
<br/>05-16-2020
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#activations">Activations</a></li>
<li><a href="#layers">Layers</a></li>
<li><a href="#losses">Losses</a></li>
<li><a href="#optimizers">Optimizers</a></li>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#example-of-tf-addons-with-keras">Example of TF Addons with Keras</a></li>
<li><a href="#callbacks">Callbacks</a></li>
<li><a href="#end-notes">End notes</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<p>The <a href="https://github.com/henry090/tfaddons">tfaddons</a> package provides R wrappers to TensorFlow Addons.</p>
<p>The new features by <a href="https://www.tensorflow.org/addons">SIG-addons for TensorFlow 2.x</a> make working with Keras even more exciting. Because ready to use additional functionalities help users to apply different techniques without any effort (e.g.Â writing custom losses, metrics, classes). But which operations exactly do SIG-addons provide us?</p>
<ul>
<li>activations</li>
<li>callbacks</li>
<li>image</li>
<li>layers</li>
<li>losses</li>
<li>metrics</li>
<li>optimizers</li>
<li>rnn</li>
<li>seq2seq</li>
<li>text</li>
</ul>
<p>To make things easier we made the new types of ops very similar to <a href="https://keras.rstudio.com/">keras</a> library. E.g. to access activations one can print <code>activation</code> and see the available list of functions.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure">
<img src="images/activations.png" alt=" " width="682" class=external />
<p class="caption">
</p>
</div>
</div>
<p>Before we start, please make sure that the TensorFlow version in your system is <code>2.x</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tensorflow::install_tensorflow() </code></pre>
</div>
<p>Later, one needs to install <code>tfaddons</code>. Note that currently the package is under development and has to be installed from Github:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
devtools::install_github(&#39;henry090/tfaddons&#39;)</code></pre>
</div>
<h2 id="activations">Activations</h2>
<p>We can take a look at classic Keras activations and later, see the new ones from <strong>tfaddons</strong>.</p>
<h3 id="generate-random-data">Generate random data</h3>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(42)
x_data &lt;- matrix(data = runif(100,-2.4,2.4), nrow = 100,ncol = 5)
y_data &lt;-  seq(-5,4.9,0.1) %&gt;% as.matrix()

old_keras = c(&#39;activation_elu&#39;,&#39;activation_exponential&#39;,&#39;activation_hard_sigmoid&#39;,
              &#39;activation_linear&#39;,&#39;activation_relu&#39;,&#39;activation_selu&#39;,
              &#39;activation_sigmoid&#39;,&#39;activation_softmax&#39;,&#39;activation_softplus&#39;,
              &#39;activation_softsign&#39;,&#39;activation_tanh&#39;)

k_clear_session()</code></pre>
</div>
<h3 id="activation-extraction">Activation Extraction</h3>
<p>A small function will quickly provide us with results. So, first we train a model and then extract activations of 1st layer from each model.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(plotly)
library(keras)
get_activations &lt;- function(activations) {
  keras_list = list()
  for (i in 1:length(activations)) {
    activation_fun = eval(parse(text = activations[i]))
    model = keras_model_sequential() %&gt;% 
      layer_dense(1, input_shape = ncol(x_data),
                  activation = activation_fun) %&gt;% 
      layer_dense(1, activation = &#39;linear&#39;) %&gt;% 
      compile(optimizer = &#39;adagrad&#39;, loss = &#39;mae&#39;,
              metrics = &#39;mse&#39;)
    
    model %&gt;% fit(x_data, y_data, verbose = 0,
                  batch_size = 1, epochs = 2)
    
    inputs = model$input                                          
    outputs = lapply(1:length(model$layers), function(x) model$layers[[x]]$output)   
    functions = lapply(1:length(outputs), function(x) 
      k_function(list(inputs), list(outputs[[x]]) ))
    
    act_layers = list()
    
    for (j in 1:nrow(x_data)) {
      res = k_reshape(x_data[j,],c(1, 5))
      layer_outs = functions[[1]](res)[[1]]
      act_layers[[j]] &lt;- layer_outs
    }
    
    activation = do.call(rbind, act_layers) %&gt;% as.vector() %&gt;% sort()
    x = seq(-5, 4.9, 0.1)
    df = data.frame(x = x, activation = activation)
    
    a &lt;- list(
      text = paste(activations[i]),
      xref = &quot;paper&quot;,
      yref = &quot;paper&quot;,
      yanchor = &quot;bottom&quot;,
      xanchor = &quot;center&quot;,
      align = &quot;center&quot;,
      x = 0.5,
      y = 1,
      showarrow = FALSE
    )
    
    p = plot_ly(df, x = ~x, y = ~activation, 
            mode = &#39;lines&#39;, type = &#39;scatter&#39;,color = I(&#39;#CE0002&#39;),
            hovertext = paste(activations[i])) %&gt;% 
      layout(annotations = a)
    keras_list[[i]] &lt;- p
  }
  keras_list
}</code></pre>
</div>
<h3 id="classic-keras">Classic Keras</h3>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
old_k = get_activations(old_keras)
subplot(lapply(1:length(old_keras), function(x) old_k[[x]]),nrows = 3, 
        shareX = TRUE, margin = 0.03) %&gt;% layout(showlegend = FALSE)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-screen-inset">
<div id="htmlwidget-7f50a1dcae7d67443a2b" style="width:624px;height:576px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-7f50a1dcae7d67443a2b">{"x":{"data":[{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.847836673259735,-0.84707248210907,-0.845698356628418,-0.843720376491547,-0.843396306037903,-0.824985027313232,-0.823991000652313,-0.821287274360657,-0.792695999145508,-0.790205419063568,-0.786729097366333,-0.763477385044098,-0.747686505317688,-0.743818998336792,-0.742108523845673,-0.724635362625122,-0.710442662239075,-0.689911484718323,-0.680513679981232,-0.667955219745636,-0.666815280914307,-0.65687370300293,-0.633774518966675,-0.624226570129395,-0.602585315704346,-0.594033718109131,-0.578155219554901,-0.553912937641144,-0.520718097686768,-0.46777081489563,-0.467059135437012,-0.439670860767365,-0.413177669048309,-0.375687599182129,-0.366056680679321,-0.345336675643921,-0.340156197547913,-0.319273948669434,-0.228523552417755,-0.216766655445099,-0.183066427707672,-0.149280369281769,-0.134589731693268,-0.0922244191169739,-0.0770679712295532,0.0507678240537643,0.0515048876404762,0.0515245497226715,0.0539713352918625,0.0691420882940292,0.2242751121521,0.236742734909058,0.24743278324604,0.304297685623169,0.417814761400223,0.444372922182083,0.445580691099167,0.523903846740723,0.530550360679626,0.545170783996582,0.587908744812012,0.627162337303162,0.657938480377197,0.664219319820404,0.693912386894226,0.724140465259552,0.768757820129395,0.821604371070862,0.822520673274994,0.877966940402985,0.887349367141724,0.891138911247253,0.915136873722076,0.933272421360016,0.973709881305695,1.03495192527771,1.06831848621368,1.16749405860901,1.23183679580688,1.24044847488403,1.24973487854004,1.26135265827179,1.31283748149872,1.45603895187378,1.51727104187012,1.5236918926239,1.52693951129913,1.5578054189682,1.59858071804047,1.62637960910797,1.63254201412201,1.64158272743225,1.65263974666595,1.67767119407654,1.71870839595795,1.76908147335052,1.77876245975494,1.7963935136795,1.81366372108459,1.83651638031006],"mode":"lines","hovertext":["activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu","activation_elu"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[0.17000325024128,0.170806780457497,0.172250986099243,0.174328505992889,0.174668729305267,0.193933263421059,0.194969847798347,0.197787642478943,0.227438807487488,0.230009809136391,0.23359540104866,0.257492780685425,0.273642629384995,0.277588933706284,0.279333084821701,0.297112375497818,0.311504870653152,0.33225229382515,0.34172186255455,0.35435077548027,0.355495721101761,0.365471243858337,0.388584285974503,0.398112684488297,0.419657677412033,0.428151994943619,0.443896502256393,0.467867523431778,0.500567734241486,0.552455008029938,0.553150415420532,0.579867362976074,0.605638265609741,0.641990303993225,0.651307880878448,0.67132568359375,0.676324725151062,0.696452498435974,0.783517301082611,0.794751167297363,0.826897799968719,0.859048187732697,0.873004078865051,0.913173317909241,0.927517116069794,1.04920089244843,1.049929022789,1.0499484539032,1.0523693561554,1.06750428676605,1.23533487319946,1.24991714954376,1.2625572681427,1.33197546005249,1.4821754693985,1.51969349384308,1.52142190933228,1.63782131671906,1.64809966087341,1.67093670368195,1.73952376842499,1.80499672889709,1.85804843902588,1.86906540393829,1.92203974723816,1.97751128673553,2.06232714653015,2.16750502586365,2.16937565803528,2.28559851646423,2.30587267875671,2.31411170959473,2.36697793006897,2.40772914886475,2.50113749504089,2.64954948425293,2.73408269882202,3.00159740447998,3.18899893760681,3.21495366096497,3.24317765235901,3.27883744239807,3.44164252281189,3.93825149536133,4.17189931869507,4.19718885421753,4.21003866195679,4.334144115448,4.5037202835083,4.62311887741089,4.6500129699707,4.68975114822388,4.73881387710571,4.85178852081299,5.04286289215088,5.28772258758545,5.33612489700317,5.4254150390625,5.51433038711548,5.63422727584839],"mode":"lines","hovertext":["activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential","activation_exponential"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x2","yaxis":"y2","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00792017579078674,0.0205409824848175,0.0479990839958191,0.0584390163421631,0.0772534310817719,0.104654014110565,0.139850527048111,0.191234737634659,0.191890031099319,0.216464638710022,0.239118814468384,0.269487231969833,0.276994168758392,0.292765378952026,0.296630591154099,0.311909079551697,0.373277693986893,0.380694389343262,0.40135246515274,0.421224892139435,0.429620623588562,0.453057378530502,0.461177200078964,0.525400459766388,0.525761902332306,0.525771498680115,0.526971340179443,0.534410715103149,0.61048412322998,0.616597950458527,0.621840059757233,0.649725198745728,0.705391228199005,0.718414723873138,0.719006896018982,0.757414698600769,0.760673999786377,0.76784348487854,0.788801193237305,0.808050155639648,0.823141992092133,0.826221942901611,0.840782761573792,0.855605840682983,0.877485036849976,0.903399705886841,0.903849005699158,0.931038498878479,0.935639441013336,0.937497675418854,0.949265718460083,0.95815896987915,0.977988481521606,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"mode":"lines","hovertext":["activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid","activation_hard_sigmoid"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x3","yaxis":"y3","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-3.97215533256531,-3.92278504371643,-3.88547444343567,-3.84738540649414,-3.82647109031677,-3.7176456451416,-3.62898921966553,-3.57491183280945,-3.55102467536926,-3.53149342536926,-3.51817989349365,-3.45812368392944,-3.37003350257874,-3.30335140228271,-3.29633498191833,-3.28246355056763,-3.15017914772034,-2.84080934524536,-2.72958254814148,-2.7044837474823,-2.68442153930664,-2.66581702232361,-2.52681159973145,-2.31255507469177,-2.24047040939331,-2.10816407203674,-2.02080368995667,-1.98162376880646,-1.92977905273438,-1.92159259319305,-1.90132284164429,-1.78153777122498,-1.7795581817627,-1.66538918018341,-1.56899893283844,-1.50369465351105,-1.43954610824585,-1.42597711086273,-1.3594890832901,-1.27468633651733,-1.18235599994659,-1.15077018737793,-1.13641107082367,-0.967203080654144,-0.964594006538391,-0.907218217849731,-0.661977887153625,-0.539128065109253,-0.516033470630646,-0.489098519086838,-0.153951928019524,-0.121177338063717,-0.115891329944134,-0.115848861634731,-0.114256516098976,0.168683335185051,0.204455807805061,0.307707965373993,0.344696044921875,0.432245224714279,0.523255825042725,0.555930614471436,0.826294302940369,0.893604755401611,0.910633087158203,0.980114221572876,1.01318669319153,1.14697670936584,1.24678134918213,1.35504627227783,1.35793328285217,1.58430981636047,1.73937058448792,1.86008560657501,1.94297397136688,1.98896777629852,2.10993623733521,2.16553807258606,2.30628800392151,2.36980724334717,2.37721109390259,2.46050548553467,2.52500748634338,2.67300367355347,2.78157830238342,2.92320656776428,2.93758344650269,2.97044682502747,3.11006903648376,3.33362698554993,3.36913108825684,3.39493131637573,3.71554636955261,3.74848055839539,3.7607159614563,4.00084972381592,4.00532484054565,4.03284215927124,4.0521674156189,4.06299018859863],"mode":"lines","hovertext":["activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear","activation_linear"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x4","yaxis":"y4","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.02633873000741,0.0267707109451294,0.0267822332680225,0.0282162539660931,0.037107527256012,0.128028035163879,0.135335087776184,0.141600295901299,0.174927711486816,0.241457968950272,0.25702315568924,0.257730960845947,0.303634703159332,0.307530134916306,0.316098898649216,0.341146737337112,0.364152520895004,0.382189780473709,0.385870903730392,0.403273493051529,0.420989573001862,0.447138905525208,0.478111356496811,0.478648394346237,0.5111443400383,0.516643226146698,0.518864154815674,0.532928884029388,0.54355788230896,0.567257404327393,0.603150248527527,0.62270575761795,0.680830597877502,0.718540787696838,0.723587989807129,0.729030430316925,0.735839486122131,0.766013622283936,0.849941253662109,0.885828256607056,0.889591455459595,0.891494691371918,0.909584641456604,0.93348240852356,0.949774622917175,0.953386425971985,0.958685040473938,0.965165197849274,0.979835629463196,1.00388693809509,1.0334095954895,1.03908336162567,1.04941642284393,1.05953824520111,1.07293164730072],"mode":"lines","hovertext":["activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu","activation_relu"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y5","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-1.75333690643311,-1.75297427177429,-1.7526820898056,-1.75236654281616,-1.75218558311462,-1.75114727020264,-1.75016820430756,-1.74950444698334,-1.74919378757477,-1.74893152713776,-1.74874830245972,-1.74787533283234,-1.74644505977631,-1.74523091316223,-1.74509596824646,-1.7448251247406,-1.7419410943985,-1.7325085401535,-1.72790837287903,-1.72676086425781,-1.72581231594086,-1.7249071598053,-1.71728992462158,-1.70198714733124,-1.69564163684845,-1.68206918239594,-1.67152774333954,-1.66633701324463,-1.65898668766022,-1.65777349472046,-1.65470504760742,-1.63455736637115,-1.63419330120087,-1.61127936840057,-1.58866453170776,-1.57139492034912,-1.55271804332733,-1.54853415489197,-1.52676749229431,-1.49569356441498,-1.45709693431854,-1.44262945652008,-1.43582463264465,-1.34367489814758,-1.34206485748291,-1.30503082275391,-1.10578072071075,-0.975109577178955,-0.947767317295074,-0.914669990539551,-0.370140254497528,-0.300857037305832,-0.289363354444504,-0.289270639419556,-0.285790413618088,0.255445957183838,0.311308622360229,0.472548276185989,0.53030914068222,0.667026937007904,0.809150040149689,0.860175251960754,1.28237807750702,1.38749074935913,1.41408216953278,1.52258503437042,1.5742312669754,1.78315901756287,1.93901491165161,2.10808277130127,2.1125910282135,2.46610307693481,2.70824766159058,2.89675736427307,3.02619647979736,3.09802103042603,3.28692650794983,3.37375545501709,3.59355163574219,3.69274377822876,3.70430588722229,3.83437919616699,3.93510627746582,4.16621828079224,4.33576965332031,4.55693769454956,4.57938861846924,4.63070869445801,4.8487434387207,5.19785451889038,5.25329828262329,5.29358816146851,5.79426383972168,5.84569358825684,5.86480093002319,6.23979616165161,6.24678516387939,6.28975629806519,6.3199348449707,6.33683586120605],"mode":"lines","hovertext":["activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu","activation_selu"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x2","yaxis":"y6","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"mode":"lines","hovertext":["activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid","activation_sigmoid"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x3","yaxis":"y7","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"mode":"lines","hovertext":["activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax","activation_softmax"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x4","yaxis":"y8","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[0.0193843618035316,0.0203414466232061,0.0210956446826458,0.0218941140919924,0.0223451890051365,0.024844765663147,0.0270836297422647,0.0285457950085402,0.0292162001132965,0.0297758542001247,0.0301633905619383,0.0319741666316986,0.034825261682272,0.0371482372283936,0.0374013297259808,0.0379066914319992,0.0430751256644726,0.0579991489648819,0.0645086020231247,0.0660725310444832,0.0673489272594452,0.0685538947582245,0.0782386660575867,0.0957843661308289,0.102489449083805,0.115970633924007,0.125771448016167,0.130415081977844,0.136806756258011,0.137842372059822,0.140438094735146,0.156728625297546,0.15701200067997,0.174175426363945,0.189985796809196,0.201426714658737,0.213266998529434,0.215850278735161,0.228917151689529,0.246601760387421,0.267215490341187,0.274605214595795,0.278022944927216,0.321144163608551,0.321851372718811,0.337740033864975,0.413214087486267,0.455872982740402,0.46426910161972,0.474214285612106,0.612114429473877,0.627036690711975,0.629467725753784,0.629487276077271,0.630220949649811,0.770350217819214,0.789448916912079,0.846299886703491,0.867284893989563,0.918242692947388,0.973108470439911,0.993270218372345,1.16917586326599,1.2153913974762,1.22722959518433,1.2761344909668,1.29974627494812,1.39738285541534,1.47233819961548,1.55557942390442,1.55782580375671,1.73797178268433,1.86559724807739,1.96708810329437,2.03777194023132,2.0773229598999,2.18240261077881,2.23118710517883,2.35593891143799,2.41279053688049,2.41943860054016,2.49451971054077,2.55301380157471,2.68829822540283,2.78841543197632,2.919997215271,2.93341183662415,2.96411395072937,3.0951087474823,3.3065197467804,3.34026145935059,3.36480808258057,3.67148971557617,3.70314621925354,3.71491384506226,3.94651341438293,3.95084047317505,3.977454662323,3.99615383148193,4.00662899017334],"mode":"lines","hovertext":["activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus","activation_softplus"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y9","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.509686291217804,-0.509019315242767,-0.507823944091797,-0.506111741065979,-0.505832195281982,-0.490351498126984,-0.489536732435226,-0.487330466508865,-0.464813113212585,-0.462914764881134,-0.460280448198318,-0.443079859018326,-0.431769818067551,-0.429040610790253,-0.427838414907455,-0.415718972682953,-0.406074613332748,-0.392403930425644,-0.386246860027313,-0.378108948469162,-0.377375096082687,-0.371007680892944,-0.3564233481884,-0.350473910570145,-0.337142288684845,-0.331928759813309,-0.322322994470596,-0.307828962802887,-0.288275748491287,-0.257660448551178,-0.257253021001816,-0.241643339395523,-0.226660758256912,-0.205622389912605,-0.200244143605232,-0.188704386353493,-0.185825273394585,-0.174241676926613,-0.124191880226135,-0.117729172110558,-0.0992148742079735,-0.0806563645601273,-0.07258390635252,-0.04928058385849,-0.0409314222633839,0.0288869775831699,0.029271213337779,0.029281459748745,0.0305547751486301,0.0383756905794144,0.111660048365593,0.117067739367485,0.12165229767561,0.145260691642761,0.188787043094635,0.198337987065315,0.198766976594925,0.225639864802361,0.227837562561035,0.232628241181374,0.246297419071198,0.258430033922195,0.267672628164291,0.269530594348907,0.278188347816467,0.286793768405914,0.299127042293549,0.313194453716278,0.313433408737183,0.327588438987732,0.329926192760468,0.330865800380707,0.336755365133286,0.341137886047363,0.350704163312912,0.364674627780914,0.372036129236221,0.392943054437637,0.405778169631958,0.407454997301102,0.409252613782883,0.411486208438873,0.421184539794922,0.446552485227585,0.456733554601669,0.457779437303543,0.458306968212128,0.463269591331482,0.469687670469284,0.473975986242294,0.47491729259491,0.476292103528976,0.477963775396347,0.481708973646164,0.487734198570251,0.494941264390945,0.496303200721741,0.498764723539352,0.501152634620667,0.504277765750885],"mode":"lines","hovertext":["activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign","activation_softsign"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x2","yaxis":"y10","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.985578894615173,-0.984675705432892,-0.983956098556519,-0.983186960220337,-0.982749283313751,-0.980282783508301,-0.978017568588257,-0.976511597633362,-0.975814163684845,-0.975228846073151,-0.974821925163269,-0.972902595996857,-0.96982342004776,-0.967265784740448,-0.966984748840332,-0.966421723365784,-0.960557043552399,-0.942651629447937,-0.9344522356987,-0.932450890541077,-0.930808901786804,-0.929251909255981,-0.916504621505737,-0.892472863197327,-0.883011043071747,-0.863584935665131,-0.84916079044342,-0.842246890068054,-0.832652747631073,-0.831090152263641,-0.827163994312286,-0.802235186100006,-0.801797568798065,-0.775056540966034,-0.750077307224274,-0.731831550598145,-0.712825059890747,-0.708663761615753,-0.687547028064728,-0.658823788166046,-0.625208616256714,-0.613138973712921,-0.607554972171783,-0.537170946598053,-0.536019504070282,-0.510196387767792,-0.389328390359879,-0.3228919506073,-0.310012757778168,-0.294847249984741,-0.0958653166890144,-0.075703538954258,-0.0724455341696739,-0.0724193528294563,-0.0714375972747803,0.1034205108881,0.125299513339996,0.187699615955353,0.209716647863388,0.260955363512039,0.312701463699341,0.330854028463364,0.47099182009697,0.502809762954712,0.510653018951416,0.541781187057495,0.556100606918335,0.610730767250061,0.648055851459503,0.685298383235931,0.68624621629715,0.753551244735718,0.79216605424881,0.818426489830017,0.834689676761627,0.8431316614151,0.863483130931854,0.871992945671082,0.891372442245483,0.899182140827179,0.900057077407837,0.909416615962982,0.916084825992584,0.929654181003571,0.938238263130188,0.947923183441162,0.94881933927536,0.950812101364136,0.958466291427612,0.968359291553497,0.969700932502747,0.970640540122986,0.980172991752625,0.980958521366119,0.981242477893829,0.986037611961365,0.986114323139191,0.986576855182648,0.986892402172089,0.987066030502319],"mode":"lines","hovertext":["activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh","activation_tanh"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x3","yaxis":"y11","frame":null}],"layout":{"xaxis":{"domain":[0,0.22],"automargin":true,"title":"x","anchor":"y9"},"xaxis2":{"domain":[0.28,0.47],"automargin":true,"title":"x","anchor":"y10"},"xaxis3":{"domain":[0.53,0.72],"automargin":true,"title":"x","anchor":"y11"},"xaxis4":{"domain":[0.78,1],"automargin":true,"title":"x","anchor":"y8"},"yaxis11":{"domain":[0,0.303333333333333],"automargin":true,"anchor":"x3"},"yaxis10":{"domain":[0,0.303333333333333],"automargin":true,"anchor":"x2"},"yaxis9":{"domain":[0,0.303333333333333],"automargin":true,"anchor":"x"},"yaxis8":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x4"},"yaxis7":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x3"},"yaxis6":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x2"},"yaxis5":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x"},"yaxis4":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x4"},"yaxis3":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x3"},"yaxis2":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x2"},"yaxis":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x"},"annotations":[{"text":"activation_elu","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.11,"y":1,"showarrow":false},{"text":"activation_exponential","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.375,"y":1,"showarrow":false},{"text":"activation_hard_sigmoid","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.625,"y":1,"showarrow":false},{"text":"activation_linear","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.89,"y":1,"showarrow":false},{"text":"activation_relu","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.11,"y":0.636666666666667,"showarrow":false},{"text":"activation_selu","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.375,"y":0.636666666666667,"showarrow":false},{"text":"activation_sigmoid","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.625,"y":0.636666666666667,"showarrow":false},{"text":"activation_softmax","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.89,"y":0.636666666666667,"showarrow":false},{"text":"activation_softplus","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.11,"y":0.303333333333333,"showarrow":false},{"text":"activation_softsign","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.375,"y":0.303333333333333,"showarrow":false},{"text":"activation_tanh","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.625,"y":0.303333333333333,"showarrow":false}],"shapes":[],"images":[],"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"attrs":{"67e457c0394":{"x":{},"y":{},"mode":"lines","hovertext":"activation_elu","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e50cf0d2f":{"x":{},"y":{},"mode":"lines","hovertext":"activation_exponential","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e496ab21b":{"x":{},"y":{},"mode":"lines","hovertext":"activation_hard_sigmoid","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e7bd33044":{"x":{},"y":{},"mode":"lines","hovertext":"activation_linear","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e6605ffde":{"x":{},"y":{},"mode":"lines","hovertext":"activation_relu","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e13e17c26":{"x":{},"y":{},"mode":"lines","hovertext":"activation_selu","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e389dacfc":{"x":{},"y":{},"mode":"lines","hovertext":"activation_sigmoid","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e77c7f16d":{"x":{},"y":{},"mode":"lines","hovertext":"activation_softmax","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e67bb688a":{"x":{},"y":{},"mode":"lines","hovertext":"activation_softplus","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e40cc713a":{"x":{},"y":{},"mode":"lines","hovertext":"activation_softsign","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e2e1db812":{"x":{},"y":{},"mode":"lines","hovertext":"activation_tanh","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"}},"source":"A","config":{"showSendToCloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"subplot":true,"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
<h3 id="tensorflow-addons-activations">TensorFlow Addons Activations</h3>
<p>Now, the same for the new activation functions from TensorFlow Addons.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
new_keras = c(&#39;activation_gelu&#39;,&#39;activation_hardshrink&#39;,&#39;activation_lisht&#39;,
              &#39;activation_mish&#39;, &#39;activation_softshrink&#39;,
              &#39;activation_sparsemax&#39;,&#39;activation_tanhshrink&#39;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
new_k = get_activations(new_keras)
subplot(lapply(1:length(new_k), function(x) new_k[[x]]),nrows = 3, 
        shareX = TRUE, margin = 0.03) %&gt;% layout(showlegend = FALSE)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-screen-inset">
<div id="htmlwidget-1e9c82e1b917bbdb51e5" style="width:624px;height:576px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1e9c82e1b917bbdb51e5">{"x":{"data":[{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.169433653354645,-0.167220130562782,-0.166426628828049,-0.162316590547562,-0.159913405776024,-0.159762024879456,-0.156167849898338,-0.147821858525276,-0.142932772636414,-0.136958584189415,-0.125417709350586,-0.124107040464878,-0.12375470995903,-0.116525210440159,-0.0958162546157837,-0.0867765545845032,-0.0775730758905411,-0.0747273042798042,-0.0645466148853302,-0.0563451871275902,-0.0520770102739334,-0.0418505929410458,-0.0376399718225002,-0.0283310785889626,-0.024738073348999,-0.0243427753448486,-0.0202195569872856,-0.0174161531031132,-0.0121392756700516,-0.00916118919849396,-0.00620960956439376,-0.00596088217571378,-0.00542386248707771,-0.00357617880217731,-0.00174022314604372,-0.00154228892643005,-0.00141155568417162,-0.000432783970609307,-0.000379861245164648,-0.00036204798379913,-0.000132970584672876,-0.000130468033603393,-0.000115347778773867,-0.000105754901596811,-0.000100775665487163,0.0534755028784275,0.0543638616800308,0.0543875806033611,0.0573500730097294,0.0761735588312149,0.311544001102448,0.333600223064423,0.352846771478653,0.460113376379013,0.695002019405365,0.753108501434326,0.755773723125458,0.932148873806,0.947383284568787,0.981009602546692,1.08006000518799,1.17174601554871,1.24390554428101,1.25864839553833,1.32837283611298,1.39932513237,1.50381100177765,1.62690937519073,1.62903594970703,1.75710237026215,1.77864813804626,1.78733944892883,1.8422327041626,1.88354325294495,1.97510719299316,2.1123321056366,2.18637824058533,2.40369939804077,2.54274010658264,2.56124830245972,2.58118104934692,2.60608339309692,2.71600341796875,3.0187873840332,3.14731860160828,3.16077351570129,3.16757750511169,3.23219585418701,3.31744647026062,3.37550568580627,3.38837051391602,3.40724039077759,3.43031311035156,3.48252606391907,3.56807613372803,3.67302012443542,3.69318175315857,3.72989511489868,3.7658531665802,3.81342697143555],"mode":"lines","hovertext":["activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu","activation_gelu"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-4.70541572570801,-4.69287919998169,-4.67049407958984,-4.63861894607544,-4.63343524932861,-4.35527563095093,-4.34110260009766,-4.30295324325562,-3.93156814575195,-3.90168213844299,-3.86055612564087,-3.60159659385681,-3.43986558914185,-3.40179753303528,-3.38514447212219,-3.22108864784241,-3.0953209400177,-2.92388939857483,-2.84917306900024,-2.75268888473511,-2.74411249160767,-2.67053508758545,-2.50749731063843,-2.44309043884277,-2.30296611785889,-2.24968910217285,-2.1536750793457,-2.01384472846985,-1.83422958850861,-1.57200562953949,-1.56866157054901,-1.44325232505798,-1.3276435136795,-1.17266750335693,-1.13435792922974,-1.0538741350174,-1.03414940834045,-0.956180214881897,-0.643003702163696,-0.605154812335968,0,-0,-0,-0,0,-0,0,-0,0,0,0.56750875711441,0.598708808422089,0.62546044588089,0.76776397228241,1.0518387556076,1.11830019950867,1.12132239341736,1.31732499599457,1.33395779132843,1.37054550647736,1.47749626636505,1.57572793960571,1.65274465084076,1.66846227645874,1.74276876449585,1.8184140920639,1.93006801605225,2.06231594085693,2.06460928916931,2.20336246490479,2.22684192657471,2.23632502555847,2.29637956619263,2.34176349639893,2.44295763969421,2.59621500968933,2.67971467971802,2.92789936065674,3.08891630172729,3.11046743392944,3.13370609283447,3.16277956962585,3.29161906242371,3.64997839927673,3.80321097373962,3.81927895545959,3.82740640640259,3.90464735031128,4.00668716430664,4.07625389099121,4.0916748046875,4.11429929733276,4.14196872711182,4.20460987091064,4.30730533599854,4.43336296081543,4.4575891494751,4.50170993804932,4.54492902755737,4.60211706161499],"mode":"lines","hovertext":["activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink","activation_hardshrink"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x2","yaxis":"y2","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[2.27653549700335e-06,1.16997043733136e-05,7.98904075054452e-05,0.000119129690574482,0.000185258439159952,0.000187581972568296,0.000187644327525049,0.000195462198462337,0.000243137328652665,0.00024749746080488,0.000418433919548988,0.000492899853270501,0.00113141420297325,0.0012302587274462,0.00131829909514636,0.00134272151626647,0.00161905621644109,0.00169305317103863,0.00183769327122718,0.00201209355145693,0.00217359745875001,0.00289041665382683,0.00313127669505775,0.00348322698846459,0.00349134998396039,0.0034996741451323,0.00420710910111666,0.00422710180282593,0.00464880419895053,0.00475378427654505,0.00498881284147501,0.00570817850530148,0.00594179937615991,0.00641130656003952,0.00699093053117394,0.00711228838190436,0.0072832852602005,0.00770002929493785,0.00832211971282959,0.00842133723199368,0.009250164963305,0.00928411725908518,0.00972670502960682,0.0104909026995301,0.0105124861001968,0.0110365925356746,0.0116660874336958,0.0118583282455802,0.0120939761400223,0.0121898213401437,0.0128053659573197,0.0132804811000824,0.0133366510272026,0.014126667752862,0.0142201837152243,0.0143705448135734,0.015293512493372,0.0161021016538143,0.0161511041224003,0.0170862376689911,0.0182055719196796,0.0197895374149084,0.0201804395765066,0.0219530146569014,0.0221787262707949,0.0223226975649595,0.0226174257695675,0.0226989854127169,0.0229373816400766,0.0233407523483038,0.02497498691082,0.0251694973558187,0.0288394428789616,0.029478020966053,0.0299463178962469,0.0306084081530571,0.0330912321805954,0.0333569943904877,0.033491849899292,0.034786269068718,0.0360631421208382,0.0365325883030891,0.0367225147783756,0.0369689911603928,0.0377467311918736,0.0380184687674046,0.0384188406169415,0.038911260664463,0.0400370173156261,0.04191605001688,0.041965413838625,0.0420614518225193,0.042654000222683,0.0430726185441017,0.0433077849447727,0.0442787744104862,0.0447399839758873,0.0455858111381531,0.0464215278625488,0.0475387014448643],"mode":"lines","hovertext":["activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht","activation_lisht"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x3","yaxis":"y3","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.308811843395233,-0.308276921510696,-0.306969940662384,-0.306798070669174,-0.305944174528122,-0.302317887544632,-0.300239533185959,-0.297449916601181,-0.297275841236115,-0.293970257043839,-0.290721893310547,-0.290327966213226,-0.289653092622757,-0.285694122314453,-0.281870603561401,-0.280638337135315,-0.272443920373917,-0.265315443277359,-0.265056043863297,-0.260922461748123,-0.254970997571945,-0.253924697637558,-0.25152000784874,-0.250874727964401,-0.248239234089851,-0.241140216588974,-0.237136587500572,-0.224210068583488,-0.221510544419289,-0.219549536705017,-0.195439606904984,-0.193008720874786,-0.192108571529388,-0.180905565619469,-0.174811705946922,-0.174496740102768,-0.172784373164177,-0.172566741704941,-0.171218127012253,-0.17046532034874,-0.148592263460159,-0.123099721968174,-0.111665785312653,-0.0776385888457298,-0.0651210397481918,0.0471151992678642,0.0478128157556057,0.0478314310312271,0.0501525402069092,0.0647227838635445,0.230783239006996,0.245415210723877,0.258104562759399,0.327757984399796,0.476730674505234,0.513287007808685,0.514963269233704,0.62606805562973,0.63569837808609,0.656984150409698,0.719960570335388,0.778701663017273,0.825287759304047,0.834847509860992,0.88026237487793,0.926837384700775,0.996124804019928,1.07886826992035,1.08030831813812,1.16771590709686,1.18255126476288,1.1885461807251,1.22654676437378,1.25529932975769,1.31948721408844,1.41679513454437,1.46980619430542,1.62708508968353,1.72873365879059,1.74230861663818,1.75693798065186,1.77522790431976,1.85610091686249,2.07937479019165,2.17406344413757,2.1839656829834,2.18897223472595,2.23648929595947,2.29908514022827,2.34164667129517,2.35106992721558,2.36488580703735,2.38177037239075,2.41994380950928,2.48237800598145,2.55877304077148,2.57342576980591,2.60008692741394,2.62617444992065,2.6606502532959],"mode":"lines","hovertext":["activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish","activation_mish"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y4","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.245843708515167,-0.23652046918869,-0.229474008083344,-0.22228080034256,-0.218331515789032,-0.197779953479767,-0.181037366390228,-0.170824944972992,-0.16631406545639,-0.16262549161911,-0.160111367702484,-0.148769617080688,-0.132134318351746,-0.119541585445404,-0.118216395378113,-0.115596771240234,-0.0906149744987488,-0.0321914553642273,-0.0111863613128662,-0.0064464807510376,-0.00265783071517944,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00908046960830688,0.029584527015686,0.0563308000564575,0.0590459108352661,0.065251886844635,0.0916192531585693,0.133837878704071,0.140542805194855,0.145415127277374,0.205962479114532,0.212182223796844,0.214492619037628,0.25984138250351,0.260686337947845,0.265882909297943,0.26953262090683,0.271576702594757],"mode":"lines","hovertext":["activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink","activation_softshrink"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x2","yaxis":"y5","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[0.99999988079071,0.99999988079071,0.99999988079071,0.99999988079071,0.999999940395355,0.999999940395355,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1.00000011920929,1.00000011920929],"mode":"lines","hovertext":["activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax","activation_sparsemax"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x3","yaxis":"y6","frame":null},{"x":[-5,-4.9,-4.8,-4.7,-4.6,-4.5,-4.4,-4.3,-4.2,-4.1,-4,-3.9,-3.8,-3.7,-3.6,-3.5,-3.4,-3.3,-3.2,-3.1,-3,-2.9,-2.8,-2.7,-2.6,-2.5,-2.4,-2.3,-2.2,-2.1,-2,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1,-0.899999999999999,-0.8,-0.7,-0.6,-0.5,-0.399999999999999,-0.3,-0.199999999999999,-0.0999999999999996,0,0.100000000000001,0.2,0.300000000000001,0.4,0.5,0.600000000000001,0.7,0.800000000000001,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3,3.1,3.2,3.3,3.4,3.5,3.6,3.7,3.8,3.9,4,4.1,4.2,4.3,4.4,4.5,4.6,4.7,4.8,4.9],"y":[-0.715674161911011,-0.698134303092957,-0.684952616691589,-0.67156308889389,-0.664240598678589,-0.62649130821228,-0.596196830272675,-0.577932476997375,-0.569918274879456,-0.56339019536972,-0.558953762054443,-0.539073586463928,-0.510324120521545,-0.488900780677795,-0.486664414405823,-0.482252836227417,-0.440872311592102,-0.349447250366211,-0.318607985973358,-0.311809301376343,-0.306418657302856,-0.301454484462738,-0.265460789203644,-0.213982284069061,-0.197818636894226,-0.16974288225174,-0.152368724346161,-0.144884467124939,-0.135278284549713,-0.133792519569397,-0.13015079498291,-0.109708845615387,-0.109386622905731,-0.0916715860366821,-0.07804936170578,-0.0695160627365112,-0.0616796016693115,-0.0600910186767578,-0.0526536703109741,-0.0439954400062561,-0.0356049537658691,-0.0329776406288147,-0.0318235456943512,-0.0200647115707397,-0.0199091732501984,-0.0166773796081543,-0.00664147734642029,-0.00362162292003632,-0.00318074226379395,-0.00271278619766235,-8.53836536407471e-05,-4.15705144405365e-05,-3.63513827323914e-05,-3.63178551197052e-05,-3.48277390003204e-05,0.000114008784294128,0.000202566385269165,0.000686630606651306,0.000963181257247925,0.0018891841173172,0.00333006680011749,0.00398370623588562,0.0127514600753784,0.0160054862499237,0.0169038474559784,0.0208960771560669,0.0229853391647339,0.0327368676662445,0.0414235293865204,0.0522652864456177,0.0525749325752258,0.0802440643310547,0.103085696697235,0.12304675579071,0.137841939926147,0.146428644657135,0.170273303985596,0.181834578514099,0.21274071931839,0.227436363697052,0.229178845882416,0.249197483062744,0.265213966369629,0.303587675094604,0.33311003446579,0.373252391815186,0.377425849437714,0.387032151222229,0.42883312702179,0.49885493516922,0.510298311710358,0.518666744232178,0.62605220079422,0.637410521507263,0.641644477844238,0.726212918758392,0.727813541889191,0.737677395343781,0.744623959064484,0.748520731925964],"mode":"lines","hovertext":["activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink","activation_tanhshrink"],"type":"scatter","marker":{"color":"rgba(206,0,2,1)","line":{"color":"rgba(206,0,2,1)"}},"textfont":{"color":"rgba(206,0,2,1)"},"error_y":{"color":"rgba(206,0,2,1)"},"error_x":{"color":"rgba(206,0,2,1)"},"line":{"color":"rgba(206,0,2,1)"},"xaxis":"x","yaxis":"y7","frame":null}],"layout":{"xaxis":{"domain":[0,0.303333333333333],"automargin":true,"title":"x","anchor":"y7"},"xaxis2":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"title":"x","anchor":"y5"},"xaxis3":{"domain":[0.696666666666667,1],"automargin":true,"title":"x","anchor":"y6"},"yaxis7":{"domain":[0,0.303333333333333],"automargin":true,"anchor":"x"},"yaxis6":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x3"},"yaxis5":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x2"},"yaxis4":{"domain":[0.363333333333333,0.636666666666667],"automargin":true,"anchor":"x"},"yaxis3":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x3"},"yaxis2":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x2"},"yaxis":{"domain":[0.696666666666667,1],"automargin":true,"anchor":"x"},"annotations":[{"text":"activation_gelu","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.151666666666667,"y":1,"showarrow":false},{"text":"activation_hardshrink","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.5,"y":1,"showarrow":false},{"text":"activation_lisht","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.848333333333333,"y":1,"showarrow":false},{"text":"activation_mish","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.151666666666667,"y":0.636666666666667,"showarrow":false},{"text":"activation_softshrink","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.5,"y":0.636666666666667,"showarrow":false},{"text":"activation_sparsemax","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.848333333333333,"y":0.636666666666667,"showarrow":false},{"text":"activation_tanhshrink","xref":"paper","yref":"paper","yanchor":"bottom","xanchor":"center","align":"center","x":0.151666666666667,"y":0.303333333333333,"showarrow":false}],"shapes":[],"images":[],"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"attrs":{"67e6bb2b070":{"x":{},"y":{},"mode":"lines","hovertext":"activation_gelu","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e205dc04d":{"x":{},"y":{},"mode":"lines","hovertext":"activation_hardshrink","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e6afc0fd4":{"x":{},"y":{},"mode":"lines","hovertext":"activation_lisht","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e4a735e2b":{"x":{},"y":{},"mode":"lines","hovertext":"activation_mish","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e5c2b7f3c":{"x":{},"y":{},"mode":"lines","hovertext":"activation_softshrink","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e2bae6b6a":{"x":{},"y":{},"mode":"lines","hovertext":"activation_sparsemax","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"},"67e480e128d":{"x":{},"y":{},"mode":"lines","hovertext":"activation_tanhshrink","color":["#CE0002"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"}},"source":"A","config":{"showSendToCloud":false},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"subplot":true,"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
<h3 id="gaussian-error-linear-units-gelus">Gaussian Error Linear Units (GELUs)</h3>
<p>As we already familiar with MNIST, it will be easier to apply the new features from <code>tfaddons</code> to this dataset. Using <a href="https://keras.rstudio.com/articles/sequential_model.html">Sequential API</a> one can consequently add new type of layers and activation functions. For example, below we will choose GELU<span class="citation" data-cites="1606.08415">(Hendrycks and Gimpel <a href="#ref-1606.08415">2016</a>)</span> as an activation function for the 1st layer. But first, we need to understand the GELU.</p>
<p>Gaussian Error Linear Unit (GELU) is defined as:</p>
<p><span class="math display">\[\text{GELU}(x)=xP(X\leq x)=x\Phi(x)\]</span> Where <span class="math inline">\(\Phi\)</span> is the cumulative distribution function of a Gaussian.</p>
<p>GELUs can be approximated as:</p>
<p><span class="math display">\[0.5x(1 + tanh[\sqrt{2/\pi}(x + 0.044715x^3)])\]</span></p>
<p>Unlike the ReLU, the GELU and ELU outputs can be both negative and positive. In addition, GELU has the following differences:</p>
<ul>
<li>it is not linear in the positive domain and exhibits curvature at all points</li>
<li>GELU weights its input depending upon how much greater it is than other inputs</li>
</ul>
<h2 id="layers">Layers</h2>
<h3 id="layer-group-normalization">Layer group normalization</h3>
<p>With traditional Keras, we have just had <code>layer_batch_normalziation</code> which is very effective if our <code>batch_size</code> is <strong>not small</strong>. However, as <code>layer_group_normalization</code><span class="citation" data-cites="1803.08494">(Wu and He <a href="#ref-1803.08494">2018</a>)</span> is batch independent, the small <code>batch_size</code> will not lead to bad performance as in batch normalization case. Therefore, <em>group normalization</em> is more stable and powerful than <em>batch normalization</em> because the first one divides channels into groups and only then normalizes features inside groups. In contrast, batch normalization directly performs normalization by using mean and variance.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<img src="images/group_norm.png" alt="[Normalization methods](https://arxiv.org/pdf/1803.08494.pdf). Each subplot shows a feature map tensor, with N as the batch axis, C as the channel axis, and (H, W) as the spatial axes. The pixels in blue are normalized by the same mean and variance, computed by aggregating the values of these pixels." width="609" class=external />
<p class="caption">
Figure 1: <a href="https://arxiv.org/pdf/1803.08494.pdf">Normalization methods</a>. Each subplot shows a feature map tensor, with N as the batch axis, C as the channel axis, and (H, W) as the spatial axes. The pixels in blue are normalized by the same mean and variance, computed by aggregating the values of these pixels.
</p>
</div>
</div>
<h3 id="layer-multi-head-attention">Layer Multi-Head Attention</h3>
<p>Multi-Head attention operation takes roots from âAttention Is All You Needâ<span class="citation" data-cites="1706.03762">(Vaswani et al. <a href="#ref-1706.03762">2017</a>)</span> paper and defines a multiplication of 3 matrices (dot product), such as:</p>
<ul>
<li>query</li>
<li>key</li>
<li>value</li>
</ul>
<p>The model proposed by this paper is called the Transformer which consists of Encoders and Decoders.</p>
<center>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure">
<img src="images/dino_transformer.jpeg" alt=" " width="364" class=external />
<p class="caption">
</p>
</div>
</div>
</center>
<p>Before going into a brief explanation of Transformers, it is better to visualize the model architecture.</p>
<div class="layout-chunk" data-layout="l-screen-inset">
<pre class="r"><code>
library(DiagrammeR)
grViz(&quot;
digraph Transformer {

  graph [overlap = false, fontsize = 10]

  node [shape = box,
        fontname = Helvetica,
        width = 3,color=darkgreen]
  edge [arrowhead=none]
  Encoder_1, Encoder_2, Encoder_3, Encoder_4, Encoder_5, Encoder_6

  node [shape = box,
        fixedsize = true,
        width = 3,color=red] // sets as circles
  edge [arrowhead=none, arrowtail = none]
  Decoder_6, Decoder_5, Decoder_4, Decoder_3, Decoder_2, Decoder_1
  
  subgraph cluster1 {
  graph [color=red, penwidth=3]
    Decoder_2-&gt;Decoder_1 Decoder_3-&gt;Decoder_2
    Decoder_4-&gt;Decoder_3 Decoder_5-&gt;Decoder_4
    Decoder_6-&gt;Decoder_5
  }
  
  node [shape=egg, fontsize=18,width=4.5]
  subgraph cluster0 {
  graph [color=darkgreen, penwidth=3]
    Encoder_2-&gt;Encoder_1 Encoder_3-&gt;Encoder_2
    Encoder_4-&gt;Encoder_3 Encoder_5-&gt;Encoder_4
    Encoder_6-&gt;Encoder_5
  }
  
  node [color=blue,penwidth=2]
  Multi_Head_Attention [style = filled, fillcolor = gold]
  Feed_Forward_NN [style = filled, fillcolor = grey]
  Add_Norm [style = filled, fillcolor = cornflowerblue,fontcolor=white]
  Add__Norm [style = filled, fillcolor = cornflowerblue,fontcolor=white]
  
    Encoder_1 -&gt;{Add_Norm}
    Add_Norm-&gt;Feed_Forward_NN
    Feed_Forward_NN-&gt;Add__Norm
    Add__Norm-&gt;{Multi_Head_Attention}
    
    node [shape=plaintext, width=6]
    Multi_Head_Attention -&gt; Positional_Embeddings
    Positional_Embeddings -&gt; Input_Embeddings
    node [shape=plaintext, fontsize=30]
    
    Input_Embeddings [style = filled, fillcolor = pink]
    Input_Embeddings -&gt; Inputs
  
  node [color=blue,penwidth=2,shape=egg, fontsize=18,width=4.5]
  Masked_Multi_Head_Attention [style = filled, fillcolor = gold]
  Encoder_Decoder_Attention [style = filled, fillcolor = gold]
  Feed_Forward__NN [style = filled, fillcolor = grey]
  Add_Norm_ [style = filled, fillcolor = cornflowerblue,fontcolor=white]
  Add_Norm__ [style = filled, fillcolor = cornflowerblue,fontcolor=white]
  Add__Norm__ [style = filled, fillcolor = cornflowerblue,fontcolor=white]
    Decoder_1 -&gt;{Add_Norm_}
    Add_Norm_ -&gt; Feed_Forward__NN
    Feed_Forward__NN -&gt;Add__Norm__
    Add__Norm__-&gt;Encoder_Decoder_Attention
    Encoder_Decoder_Attention-&gt; Add_Norm__
    Add_Norm__ -&gt;Masked_Multi_Head_Attention
    
    node [shape=plaintext, width=6]
    Masked_Multi_Head_Attention -&gt; Positional__Embeddings
    Positional__Embeddings -&gt; Output_Embeddings
    node [shape=plaintext, fontsize=30]
    
    Output_Embeddings [style = filled, fillcolor = pink]
    Output_Embeddings -&gt; Output
  
  
  node [color=gold,penwidth=3,shape=egg, fontsize=18,width=4.5]
  Output_probabilites [style = filled, fillcolor = gold]
  Softmax [style = filled, fillcolor = gold]
  Linear [style = filled, fillcolor = gold]
  Output_probabilites-&gt;Softmax
  Softmax-&gt;Linear
  Linear-&gt;Decoder_6
  
  edge [arrowhead=vee]
  node [shape =plaintext,fontsize = 45, fontcolor=blue]
  Transformer-&gt;{Encoder, Decoder}
  Encoder [shape =plaintext,fontsize = 45, fontcolor=darkgreen]
  Encoder-&gt;{Encoder_6}
  Decoder [shape =plaintext,fontsize = 45, fontcolor=red]
  Decoder-&gt;{Decoder_6}

}
&quot;)</code></pre>
<div id="htmlwidget-0f61c23f0a788c1e7f9a" style="width:624px;height:672px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-0f61c23f0a788c1e7f9a">{"x":{"diagram":"\ndigraph Transformer {\n\n  graph [overlap = false, fontsize = 10]\n\n  node [shape = box,\n        fontname = Helvetica,\n        width = 3,color=darkgreen]\n  edge [arrowhead=none]\n  Encoder_1, Encoder_2, Encoder_3, Encoder_4, Encoder_5, Encoder_6\n\n  node [shape = box,\n        fixedsize = true,\n        width = 3,color=red] // sets as circles\n  edge [arrowhead=none, arrowtail = none]\n  Decoder_6, Decoder_5, Decoder_4, Decoder_3, Decoder_2, Decoder_1\n  \n  subgraph cluster1 {\n  graph [color=red, penwidth=3]\n    Decoder_2->Decoder_1 Decoder_3->Decoder_2\n    Decoder_4->Decoder_3 Decoder_5->Decoder_4\n    Decoder_6->Decoder_5\n  }\n  \n  node [shape=egg, fontsize=18,width=4.5]\n  subgraph cluster0 {\n  graph [color=darkgreen, penwidth=3]\n    Encoder_2->Encoder_1 Encoder_3->Encoder_2\n    Encoder_4->Encoder_3 Encoder_5->Encoder_4\n    Encoder_6->Encoder_5\n  }\n  \n  node [color=blue,penwidth=2]\n  Multi_Head_Attention [style = filled, fillcolor = gold]\n  Feed_Forward_NN [style = filled, fillcolor = grey]\n  Add_Norm [style = filled, fillcolor = cornflowerblue,fontcolor=white]\n  Add__Norm [style = filled, fillcolor = cornflowerblue,fontcolor=white]\n  \n    Encoder_1 ->{Add_Norm}\n    Add_Norm->Feed_Forward_NN\n    Feed_Forward_NN->Add__Norm\n    Add__Norm->{Multi_Head_Attention}\n    \n    node [shape=plaintext, width=6]\n    Multi_Head_Attention -> Positional_Embeddings\n    Positional_Embeddings -> Input_Embeddings\n    node [shape=plaintext, fontsize=30]\n    \n    Input_Embeddings [style = filled, fillcolor = pink]\n    Input_Embeddings -> Inputs\n  \n  node [color=blue,penwidth=2,shape=egg, fontsize=18,width=4.5]\n  Masked_Multi_Head_Attention [style = filled, fillcolor = gold]\n  Encoder_Decoder_Attention [style = filled, fillcolor = gold]\n  Feed_Forward__NN [style = filled, fillcolor = grey]\n  Add_Norm_ [style = filled, fillcolor = cornflowerblue,fontcolor=white]\n  Add_Norm__ [style = filled, fillcolor = cornflowerblue,fontcolor=white]\n  Add__Norm__ [style = filled, fillcolor = cornflowerblue,fontcolor=white]\n    Decoder_1 ->{Add_Norm_}\n    Add_Norm_ -> Feed_Forward__NN\n    Feed_Forward__NN ->Add__Norm__\n    Add__Norm__->Encoder_Decoder_Attention\n    Encoder_Decoder_Attention-> Add_Norm__\n    Add_Norm__ ->Masked_Multi_Head_Attention\n    \n    node [shape=plaintext, width=6]\n    Masked_Multi_Head_Attention -> Positional__Embeddings\n    Positional__Embeddings -> Output_Embeddings\n    node [shape=plaintext, fontsize=30]\n    \n    Output_Embeddings [style = filled, fillcolor = pink]\n    Output_Embeddings -> Output\n  \n  \n  node [color=gold,penwidth=3,shape=egg, fontsize=18,width=4.5]\n  Output_probabilites [style = filled, fillcolor = gold]\n  Softmax [style = filled, fillcolor = gold]\n  Linear [style = filled, fillcolor = gold]\n  Output_probabilites->Softmax\n  Softmax->Linear\n  Linear->Decoder_6\n  \n  edge [arrowhead=vee]\n  node [shape =plaintext,fontsize = 45, fontcolor=blue]\n  Transformer->{Encoder, Decoder}\n  Encoder [shape =plaintext,fontsize = 45, fontcolor=darkgreen]\n  Encoder->{Encoder_6}\n  Decoder [shape =plaintext,fontsize = 45, fontcolor=red]\n  Decoder->{Decoder_6}\n\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>Indeed, this seems a bit challenging to understand but we can divide the plot into different sections:</p>
<ul>
<li>Econder</li>
<li>Decoder
<ul>
<li>Feed Forward NN</li>
<li>Layer Normalization</li>
<li>Multi-Head Attention mechanism</li>
<li>Positional Embeddings</li>
<li>Linear &amp; Softmax activation</li>
</ul></li>
</ul>
<p><strong>Where to watch?</strong></p>
<p>Our task is to start from bottom to top.</p>
<ol type="1">
<li>The first thing we see are the inputs. They are our plain <em>Input</em> texts. E.g.: âVery easyâ. Our input consists of 2 words.</li>
<li>Imagine that each word has 512 embeddings<span class="citation" data-cites="1301.3781">(Mikolov et al. <a href="#ref-1301.3781">2013</a>)</span>. Then we have 2 words (rows) with 512 columns (dimensions). Hence, these are your <em>Input Embeddings</em>.</li>
<li>The title <em>Positional Embeddings</em> gives us a clue about the meaning, it simply encodes the position of each word against the other ones.</li>
<li>From the left of the plot, we see 3 unique layers: Multi-Head Attention mechanism, Layer Normalization, Feed Forward NN. What is the purpose of these layers? Before explanation, we can observe that in the middle, on the left side Encoder has so-called sub-encoders (Encoder_1, â¦, Encoder_6). In fact, each of these encoders contains these 4 layers from Multi-head layer up to Layer normalization. From the right of the plot, we have 6 layers. This means that each Decoder has 6 of these layers.</li>
<li>Letâs begin from the <em>Multi-head</em> Attention layer:</li>
</ol>
<p><span class="math display">\[\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V \]</span> As we already mentioned above there is 3 type of matrices in Attention layer: Query, Key, and Value matrices where Q and K matrices are multiplied, then divided by the square root of Key matrix dimensions (in the paper the number of Key dimensions are 64, so sqrt of 64 is 8). Then the softmax activation is applied in order to normalize the outputs. Later, we have to multiply the normalized value by the Value matrix. Note that, these matrices are created by the model during the training process.</p>
<p>Till now, we just covered the attention mechanism but what are the Heads? Attention contains 3 Matrices, Heads consist of multiple Attentions. So, basically the purpose of Heads is to concentrate attention over the multiple Attention mechanisms and then concatenate all of <span class="math inline">\(Q\)</span>, <span class="math inline">\(K\)</span>, <span class="math inline">\(V\)</span> matrices, and multiply with jointly created matrix <span class="math inline">\(W^O\)</span>.</p>
<ol start="6" type="1">
<li><p>The information from Attentions moves to the next Layer - Feed Forward NN. But keep in mind that we never lose the dimensionality of our input vectors, 512. So, all the time inputs go into a certain layer, is updated, and without losing dimension size is transferred to the next layer. Between Attention and Feed Forward NN, there are Normalization Layers.</p></li>
<li><p>After transferring the output to the final Enocder_6, the internal representation of vectors is moved to the stack of decoders. What is on the right side of the diagram?</p></li>
<li><p>We have Masked and Encoder-Decoder Attentions. As we go from bottom to top the first thing we need to do is to analyze Masked Multi-Head Attention Layer. In the decoder, masked Attention prevents positions from attending to subsequent positions. This means that future positions are masked and set to <span class="math inline">\(ââ\)</span>. For example:</p></li>
</ol>
<table>
<thead>
<tr class="header">
<th>English</th>
<th>German</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I love R programming language</td>
<td>Ich liebe R Programmiersprache</td>
</tr>
</tbody>
</table>
<p>In order to predict first 3 words âI love Râ first we encode them like dimensions: â1 2 3â and then German as â4 5 6â. What are we doing here?</p>
<p>We use all 3 inputs from English and parallelly translate sentence, but which parallel computations do we mean? For example:</p>
<p>1 2 3 =&gt; Predict 4th word</p>
<p>1 2 3 + 4 =&gt; Predict 5th word</p>
<p>1 2 3 + 4 + 5 =&gt; Predict 6th word</p>
<ol start="9" type="1">
<li><p>Encoder-Decoder Attention is like a standard Attention Layer however it takes Q matrix from below layer; K, and V matrices are taken from stack of Encoders.</p></li>
<li><p>As a final step, the output from the stack of Decoders are normalized by Softmax and then, by Linear function (logits to probabilities)</p></li>
</ol>
<p>Example of Multi-Head attention layer with <code>tfaddons</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mha = layer_multi_head_attention(head_size = 128, num_heads = 128)
query = tf$random$uniform(list(32L, 20L, 200L)) # (batch_size, query_elements, query_depth)
key = tf$random$uniform(list(32L, 15L, 300L)) # (batch_size, key_elements, key_depth)
value = tf$random$uniform(list(32L, 15L, 400L)) # (batch_size, key_elements, value_depth)
attention = mha(list(query, key, value)) # (batch_size, query_elements, value_depth)</code></pre>
</div>
<h3 id="keras-model-architecture">Keras model architecture</h3>
<p>As mentioned, using Sequential API the Keras model with:</p>
<ul>
<li>activation GELU</li>
<li>layer_group_normalization</li>
</ul>
<p>can be defined as:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Build a sequential model
model = keras_model_sequential() %&gt;% 
  layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
                # put channels to the 3rd axis [rows,columns,channels]
                data_format = &quot;channels_last&quot;,
                #apply activation gelu
                activation = activation_gelu) %&gt;% 
  # apply group normalization layer
  # after convolution split 10 channels into 5 subgroups
  layer_group_normalization(groups = 5, axis = 3) %&gt;% 
  layer_flatten() %&gt;% 
  layer_dense(10, activation = &#39;softmax&#39;)</code></pre>
</div>
<h2 id="losses">Losses</h2>
<p>There are a lot of loss functions in <code>tfaddons</code> as well, for example:</p>
<p>IoU<span class="citation" data-cites="1908.03851">(Zhou et al. <a href="#ref-1908.03851">2019</a>)</span> and GIoU<span class="citation" data-cites="1902.09630">(Rezatofighi et al. <a href="#ref-1902.09630">2019</a>)</span> are widely used for object detection, segmentation, and tracking because they show better performance during the assessment of 2D bounding boxes.</p>
<p>Itersection over Union can be defined as:</p>
<p><span class="math display">\[IoU=\dfrac{\mid{A\cap B\mid}}{\mid{A\cup B\mid}}=\dfrac{\mid I \mid}{\mid U \mid}\]</span></p>
<p>and Generalized Intersection over Union as:</p>
<p><span class="math display">\[GIoU = \dfrac{|A\cap B|}{|A\cup B|} - \dfrac{|C\backslash(A\cup B)|}{|C|} = IoU - \dfrac{|C\backslash(A\cup B)|}{|C|}\]</span></p>
<p>where âAâ and âBâ are actuals and predicted values, division of intersection to union. However, if the intersection is 0, then the IoU score is 0 as well. Therefore, we are not able to assess the loss because it is zero. In contrast, GIoU has an additional argument âCâ which tries to enclose âAâ and âBâ. What does it mean?</p>
<p>Imagine that A and B are operating systems where R has built-in packages from CRAN.</p>
<p>âAâ has {âggplot2â, âdplyrâ, âtidyrâ, âdistillâ}</p>
<p>âBâ has {âdistillâ, âkerasâ, âtensorflowâ, âggplot2â}</p>
<p>From the point of math:</p>
<ul>
<li>What they have in common:<span class="math inline">\(A\cap B = \{ distill,\:ggplot2 \}\)</span></li>
<li>What they have in union: <span class="math inline">\(A\cup B = \{ ggplot2,\:dplyr,\:tidyr, \:distill,\: keras,\:tensorflow \}\)</span></li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(ggplot2)

df = data.frame(pkgs = c(&quot;ggplot2&quot;,&quot;dplyr&quot;,&quot;tidyr&quot;,&quot;distill&quot;,&quot;keras&quot;,&quot;tensorflow&quot;),
                x = c(5,   2,2,  4,8,9),
                y = c(3.2, 3,4, 4,4,2))

ggplot(df, aes(x, y, label = pkgs)) + geom_label() + 
  scale_y_reverse(breaks = seq(1,10,1)) + theme_bw() +
  scale_x_continuous(breaks = seq(1,10,1)) +
  expand_limits(x = c(1, 10), y = c(0, 7)) +
  # prediction
  annotate(&quot;rect&quot;, xmin = 1.2, xmax = 5.9, ymin = 2, ymax = 5,
           alpha = .1, color = &#39;red&#39;) +
  # actual
  annotate(&quot;rect&quot;, xmin = 3, xmax = 10.5, ymin = 1.5, ymax = 4.5,
           alpha = .1, color = &#39;darkgreen&#39;)</code></pre>
<p><img src="tfaddons_files/figure-html5/unnamed-chunk-16-1.png" width="624" /></p>
</div>
<p>As we have bounding boxes we can calculate <code>IoU</code> and <code>GIoU</code> scores:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
iou = loss_giou(mode = &#39;iou&#39;) # or giou
# [y_min, x_min, y_max, x_max]
boxes_actual = tf$constant(list(c(1.5,3,4.5,10.5)))
boxes_predicted = tf$constant(list(c(2,1.2,5,5.9)))
iou_loss = iou(boxes_actual,boxes_predicted)
cat(&#39;IoU Loss: &#39;, as.array(iou_loss)) </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
IoU Loss:  0.7529812</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
giou = loss_giou(mode = &#39;giou&#39;) # or iou
# [y_min, x_min, y_max, x_max]
giou_loss = giou(boxes_actual,boxes_predicted)
cat(&#39;GIoU Loss: &#39;, as.array(giou_loss)) </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
GIoU Loss:  0.8512915</code></pre>
</div>
<p>What if they do not have intersection?</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
df = data.frame(pkgs = c(&quot;dplyr&quot;,&quot;tidyr&quot;,&quot;keras&quot;,&quot;tensorflow&quot;),
                x = c(2,2,8,9),
                y = c(3,4,4,2))

ggplot(df, aes(x, y, label = pkgs)) + geom_label() + 
  scale_y_reverse(breaks = seq(1,10,1)) + theme_bw() +
  scale_x_continuous(breaks = seq(1,10,1)) +
  expand_limits(x = c(1, 10), y = c(0, 7)) +
  annotate(&quot;rect&quot;, xmin = 1.2, xmax = 3, ymin = 2, ymax = 5,
           alpha = .1, color = &#39;red&#39;) +
  annotate(&quot;rect&quot;, xmin = 7, xmax = 10.5, ymin = 1.5, ymax = 4.5,
           alpha = .1, color = &#39;darkgreen&#39;)</code></pre>
<p><img src="tfaddons_files/figure-html5/unnamed-chunk-21-1.png" width="624" /></p>
</div>
<h3 id="iou">IoU</h3>
<p>According to paper, IoU makes a bad prediction. Because loss is 0.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
df = data.frame(pkgs = c(&quot;dplyr&quot;,&quot;tidyr&quot;,&quot;keras&quot;,&quot;tensorflow&quot;),
                x = c(2,2,8,9),
                y = c(3,4,4,2))

ggplot(df, aes(x, y, label = pkgs)) + geom_label() + 
  scale_y_reverse(breaks = seq(1,10,1)) + theme_bw() +
  scale_x_continuous(breaks = seq(1,10,1)) +
  expand_limits(x = c(0, 10), y = c(0, 7)) +
  annotate(&quot;rect&quot;, xmin = 1.2, xmax = 3, ymin = 2, ymax = 5,
           alpha = .1, color = &#39;red&#39;) +
  annotate(&quot;rect&quot;, xmin = 7, xmax = 10.5, ymin = 1.5, ymax = 4.5,
           alpha = .1, color = &#39;darkgreen&#39;) +
  annotate(&quot;rect&quot;, xmin = 0.1, xmax = 11, ymin = 0.1, ymax = 7,
           alpha = .1, color = &#39;yellow&#39;)</code></pre>
<p><img src="tfaddons_files/figure-html5/unnamed-chunk-22-1.png" width="624" /></p>
</div>
<h3 id="giou">GIoU</h3>
<p>However, with GIoU the situation is different. From left and right GIoU does not take the whole bound, as a result the loss will not be 0. Hence, the function performs a better object prediction.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
df = data.frame(pkgs = c(&quot;dplyr&quot;,&quot;tidyr&quot;,&quot;keras&quot;,&quot;tensorflow&quot;),
                x = c(2,2,8,9),
                y = c(3,4,4,2))

ggplot(df, aes(x, y, label = pkgs)) + geom_label() + 
  scale_y_reverse(breaks = seq(1,10,1)) + theme_bw() +
  scale_x_continuous(breaks = seq(1,10,1)) +
  expand_limits(x = c(0, 10), y = c(0, 7)) +
  annotate(&quot;rect&quot;, xmin = 1.2, xmax = 3, ymin = 2, ymax = 5,
           alpha = .1, color = &#39;red&#39;) +
  annotate(&quot;rect&quot;, xmin = 7, xmax = 10.5, ymin = 1.5, ymax = 4.5,
           alpha = .1, color = &#39;darkgreen&#39;) +
  annotate(&quot;rect&quot;, xmin = 3.8, xmax = 10.65, ymin = 0.1, ymax = 7,
           alpha = .1, color = &#39;yellow&#39;) +
  annotate(&quot;rect&quot;, xmin = 4, xmax = 6, ymin = 2, ymax = 4,
           alpha = .1, color = &#39;orange&#39;) +
  annotate(&quot;text&quot;, x = 5, y = 3, label = c(&#39;C argument&#39;),
           size=3,
           color = &#39;black&#39;)</code></pre>
<p><img src="tfaddons_files/figure-html5/unnamed-chunk-23-1.png" width="624" /></p>
</div>
<p>Object detection has already been introduced in this <a href="https://blogs.rstudio.com/ai/posts/2018-12-18-object-detection-concepts/">blog</a>. With <strong>tfaddons</strong> we now can apply this loss function to our object detection model.</p>
<h2 id="optimizers">Optimizers</h2>
<p>Optimizer Rectified_Adam<span class="citation" data-cites="1908.03265">(Liu et al. <a href="#ref-1908.03265">2019</a>)</span> was already mentioned on the RStudio AI blog. However, it was inside âkeras-bertâ library. With <code>tfaddons</code> it is not only possible to apply rectified Adam but also using attention<span class="citation" data-cites="1907.08610">(Zhang et al. <a href="#ref-1907.08610">2019</a>)</span> mechanism to gain more control over weights, and as a result to get a remarkable success during model training.</p>
<aside>
<a href="https://blogs.rstudio.com/ai/posts/2019-09-30-bert-r/">Bidirectional Encoder Representations from Transformers from R</a>
</aside>
<p>Empirical and theoretical evidence shows that without warmup training at early steps get a large amount of variance which therefore leads to bad performance. Nonetheless, a small learning rate for the first epochs and gradual increase of this parameter may accelerate convergence. But, it is not guaranteed that warmup is always effective and can work in different ML applications.</p>
<p>If Adam and SGD use the experience of past accumulated gradients for a better understanding of the next direction, then the Lookahead mechanism runs another optimizer within itself to generate so-called âfast weightsâ. These weights help for an effective update of âslow weightsâ.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-24"></span>
<img src="images/lookahead.png" alt="(Left) [Visualizing Lookahead](https://arxiv.org/pdf/1907.08610v1.pdf) through a ResNet-32 test accuracy surface at epoch 100 on CIFAR-100. We project the weights onto a plane defined by the first, middle, and last fast (inner-loop) weights. The fast weights are along the blue dashed path. All points that lie on the plane are represented as solid, including the entire Lookahead slow weights path (in purple). Lookahead (middle, bottom right) quickly progresses closer to the minima than SGD (middle, top right) is able to. (Right) Pseudocode for Lookahead." width="815" class=external />
<p class="caption">
Figure 2: (Left) <a href="https://arxiv.org/pdf/1907.08610v1.pdf">Visualizing Lookahead</a> through a ResNet-32 test accuracy surface at epoch 100 on CIFAR-100. We project the weights onto a plane defined by the first, middle, and last fast (inner-loop) weights. The fast weights are along the blue dashed path. All points that lie on the plane are represented as solid, including the entire Lookahead slow weights path (in purple). Lookahead (middle, bottom right) quickly progresses closer to the minima than SGD (middle, top right) is able to. (Right) Pseudocode for Lookahead.
</p>
</div>
</div>
<p>According to paper, Lookahead leads to improved convergence over the inner optimizer and often improved generalization performance while being robust to <strong>hyperparameter changes</strong>.</p>
<p>So, we also have a <a href="https://github.com/henry090/kerastuneR">kerastuneR</a> package which is created by <a href="https://keras-team.github.io/keras-tuner/">Keras Team</a> for tuning the hyperparameters of Keras model. Letâs apply this in practice and see what will happen if we apply optimizer Rectified Adam with Lookahead Mechanism and play with hyperparameters.</p>
<ul>
<li>Import and prerocess Iris</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(magrittr)
data(&quot;iris&quot;)
iris$Species =  as.integer(factor(iris$Species))
iris[1:4] = scale(iris[1:4])</code></pre>
</div>
<ul>
<li>Define a model-building function which will be used for generating a model with random defined parameters, such as the number of neurons, learning rates. The function takes an argument <strong>hp</strong> from which one can sample hyperparameters, such as <code>hp$Int('units', min_value = 32, max_value = 512, step = 32)</code> (an integer from a certain range).</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(keras)
library(tensorflow)
library(kerastuneR)
library(tfaddons)

build_model = function(hp) {
  
  model = keras_model_sequential()
  model %&gt;% layer_dense(units = hp$Int(&#39;units&#39;,
                                       min_value = 2,
                                       max_value = 100,
                                       step =  32/8),input_shape = ncol(iris) - 1,
                        activation =  activation_gelu) %&gt;%
    layer_dense(units = 3, activation = &#39;softmax&#39;) %&gt;%
    compile(
      optimizer = tfaddons::lookahead_mechanism(
        tfaddons::optimizer_radam(
        learning_rate = hp$Choice(&#39;learning_rate&#39;,
                  values = c(1e-2, 1e-3, 1e-4, 1e-5))
        )
        ),
      loss = &#39;categorical_crossentropy&#39;,
      metrics = &#39;accuracy&#39;)
  return(model)
}</code></pre>
</div>
<ul>
<li>Create a tuner object with parameter <code>max_trials</code><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> and parameter <code>executions_per_trial</code><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tuner = RandomSearch(
  build_model,
  objective = &#39;val_accuracy&#39;,
  max_trials = 10,
  executions_per_trial = 8,
  directory = &#39;radam&#39;,
  project_name = &#39;lookahead_mechanism&#39;)</code></pre>
</div>
<p>Then, start the search for the best hyperparameter configuration. The call to search has the same signature as <code>model %&gt;% fit()</code>. But here instead of <code>fit()</code> we call <code>fit_tuner()</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tuner %&gt;% fit_tuner(iris[1:4],to_categorical(iris[5])[,1:3],
                    epochs = 2, 
                    validation_split = 0.2)</code></pre>
</div>
<p>Visualize the models for better understanding:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tuner %&gt;% plot_tuner(type = &#39;echarts4r&#39;)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-screen-inset">
<div id="htmlwidget-80288bb2b92ad150b5d3" style="width:100%;height:500px;" class="echarts4r html-widget"></div>
<script type="application/json" data-for="htmlwidget-80288bb2b92ad150b5d3">{"x":{"theme":"","tl":false,"draw":true,"renderer":"canvas","events":[],"buttons":[],"opts":{"series":{"name":null,"type":"parallel","data":[[54,1e-05,0,0.5083333],[74,1e-05,0,0.4125],[6,0.001,0,0.3291667],[62,0.001,0,0.2625],[38,0.0001,0,0.4],[94,0.01,0,0.3708333],[74,0.01,0,0.5625],[90,1e-05,0,0.2125],[14,1e-05,0,0.4291667],[82,1e-05,0,0.3875]]},"parallelAxis":[{"dim":0,"name":"units"},{"dim":1,"name":"learning_rate"},{"dim":2,"name":"best_step"},{"dim":3,"name":"score"}]},"dispose":true},"evals":[],"jsHooks":[]}</script>
</div>
<p>One can observe that the highest accuracy was got by the highest learning rate. The smaller the learning rate the worse the performance. This is because our network is simple and we do not need warmup steps. But, readers can set higher learning rates and even add another dense layer to see how the lookahead mechanism behaves in this case.</p>
<h2 id="metrics">Metrics</h2>
<p>The metrics from <code>tfaddons</code> really come to rescue. Because if one has ever participated in Kaggle competitions, then it is clear that cohen kappa, f1, Matthews Correlation Coefficient are the most well-known and used metrics in this community. So, with TensorFlow Addons, there is no need for custom functions to assess the result of the Keras model.</p>
<p>How to apply?</p>
<h2 id="example-of-tf-addons-with-keras">Example of TF Addons with Keras</h2>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(keras)
library(tfaddons)

mnist = dataset_mnist()

x_train &lt;- mnist$train$x
y_train &lt;- mnist$train$y

# reshape the dataset
x_train &lt;- array_reshape(x_train, c(nrow(x_train), 28, 28, 1))

# Transform RGB values into [0,1] range
x_train &lt;- x_train / 255

# One-hot encoding
y_train &lt;- to_categorical(y_train, 10)

# Build a sequential model
model = keras_model_sequential() %&gt;% 
  layer_conv_2d(filters = 10, kernel_size = c(3,3),input_shape = c(28,28,1),
                #apply activation gelu
                activation = activation_gelu) %&gt;% 
  # apply group normalization layer
  layer_group_normalization(groups = 5, axis = 3) %&gt;% 
  layer_flatten() %&gt;% 
  layer_dense(10, activation=&#39;softmax&#39;)

# Compile
model %&gt;% compile(
  # apply rectified adam
  optimizer = optimizer_radam(),
  # apply sparse max loss
  loss = loss_sparsemax(),
  # choose cohen kappa metric
  metrics = metric_cohen_kappa(10)
)

model %&gt;% fit(
  x_train, y_train,
  batch_size = 128,
  epochs = 1,
  validation_split = 0.2
)</code></pre>
</div>
<p>And here is the result:</p>
<pre><code>
Train on 48000 samples, validate on 12000 samples
48000/48000 [==============================] - 24s 510us/sample - loss: 0.1193 - 
cohen_kappa: 0.8074 - val_loss: 0.0583 - val_cohen_kappa: 0.9104</code></pre>
<h2 id="callbacks">Callbacks</h2>
<p>We almost have forgotten to mention the new callbacks! Now it is possible to stop training after a certain time and even get a progress bar while training a model. Just pass callbacks as usual into <code>fit</code> function:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model %&gt;% fit(
  x_train, y_train,
  batch_size = 128,
  epochs = 4,
  validation_split = 0.2,
  verbose = 0,
  callbacks = callback_time_stopping(seconds = 6, verbose = 1)
)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
Timed stopping at epoch 1 after training for 0:00:06</code></pre>
</div>
<h2 id="end-notes">End notes</h2>
<p>In fact, we have just covered a lot of interesting features from TensorFlow Addons. However, there are a giant number of operations which is not possible to introduce in this post, such as:</p>
<ul>
<li>image ops</li>
<li>text ops</li>
<li>rnn ops</li>
<li>attention mechanisms, e.g: attention Bahdanau, Luong, Monotonic, and many more.</li>
</ul>
<p><a href="https://blogs.rstudio.com/ai/posts/2018-07-30-attention-layer/">Neural machine translation</a> was already explained. One can apply new methods from <em>tfaddons</em> to the same case or even directly find a new example <a href="https://github.com/henry090/tfaddons/blob/master/vignettes/neural%20machine%20translation.R">here</a>.</p>
<p>We encourage readers to experiment with TensforFlow Addons and share their perspectives on RStudio AI Blog!</p>
<p>Thanks for reading!</p>
<div id="refs" class="references">
<div id="ref-1606.08415">
<p>Hendrycks, Dan, and Kevin Gimpel. 2016. âGaussian Error Linear Units (Gelus).â <a href="https://arxiv.org/abs/1606.08415">https://arxiv.org/abs/1606.08415</a>.</p>
</div>
<div id="ref-1908.03265">
<p>Liu, Liyuan, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. 2019. âOn the Variance of the Adaptive Learning Rate and Beyond.â <a href="https://arxiv.org/pdf/1908.03265v1.pdf">https://arxiv.org/pdf/1908.03265v1.pdf</a>.</p>
</div>
<div id="ref-1301.3781">
<p>Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. âEfficient Estimation of Word Representations in Vector Space.â <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a>.</p>
</div>
<div id="ref-1902.09630">
<p>Rezatofighi, Hamid, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese. 2019. âGeneralized Intersection over Union: A Metric and a Loss for Bounding Box Regression.â <a href="https://arxiv.org/pdf/1902.09630.pdf">https://arxiv.org/pdf/1902.09630.pdf</a>.</p>
</div>
<div id="ref-1706.03762">
<p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. âAttention Is All You Need.â <a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a>.</p>
</div>
<div id="ref-1803.08494">
<p>Wu, Yuxin, and Kaiming He. 2018. âGroup Normalization.â <a href="https://arxiv.org/pdf/1803.08494.pdf">https://arxiv.org/pdf/1803.08494.pdf</a>.</p>
</div>
<div id="ref-1907.08610">
<p>Zhang, Michael R., James Lucas, Geoffrey Hinton, and Jimmy Ba. 2019. âLookahead Optimizer: K Steps Forward, 1 Step Back.â <a href="https://arxiv.org/pdf/1907.08610v1.pdf">https://arxiv.org/pdf/1907.08610v1.pdf</a>.</p>
</div>
<div id="ref-1908.03851">
<p>Zhou, Dingfu, Jin Fang, Xibin Song, Chenye Guan, Junbo Yin, Yuchao Dai, and Ruigang Yang. 2019. âIoU Loss for 2D/3D Object Detection.â <a href="https://arxiv.org/abs/1908.03851">https://arxiv.org/abs/1908.03851</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>the total number of trials to test<a href="#fnref1" class="footnote-back">â©</a></p></li>
<li id="fn2"><p>the number of models that should be built and fit for each trial<a href="#fnref2" class="footnote-back">â©</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-05-15-tfaddons/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=TensorFlow%20Addons%20and%20classic%20Keras&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-05-15-tfaddons%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-05-15-tfaddons%2F&amp;title=TensorFlow%20Addons%20and%20classic%20Keras">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/';
  this.page.identifier = 'posts/2020-05-15-tfaddons/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    document.querySelector(".sidebar-section.categories a[href='#R']").parentNode.style.display = "None";
  });
</script></div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="updates-and-corrections">Corrections</h3>
  <p>If you see mistakes or want to suggest changes, please <a href="https://github.com/henry090/tfaddons_intro/issues/new">create an issue</a> on the source repository.</p>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. Source code is available at <a href="https://github.com/henry090/tfaddons_intro">https://github.com/henry090/tfaddons_intro</a>, unless otherwise noted. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Abdullayev (2020, May 16). RStudio AI Blog: TensorFlow Addons and classic Keras. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{abdullayev2020tensorflow,
  author = {Abdullayev, Turgut},
  title = {RStudio AI Blog: TensorFlow Addons and classic Keras},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-05-15-tfaddons/},
  year = {2020}
}</pre>
</div>
<script id="distill-bibliography" type="text/bibtex">
@misc{1606.08415,
 Author = {Dan Hendrycks and Kevin Gimpel},
 Title = {Gaussian Error Linear Units (GELUs)},
 Url    = "https://arxiv.org/abs/1606.08415",
 Year = {2016},
 Eprint = {arXiv:1606.08415},
}

@misc{1803.08494,
 Author = {Yuxin Wu and Kaiming He},
 Title = {Group Normalization},
 Url = "https://arxiv.org/pdf/1803.08494.pdf",
 Year = {2018},
 Eprint = {arXiv:1803.08494},
}

@misc{1902.09630,
 Author = {Hamid Rezatofighi and Nathan Tsoi and JunYoung Gwak and Amir Sadeghian and Ian Reid and Silvio Savarese},
 Title = {Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression},
 Url = "https://arxiv.org/pdf/1902.09630.pdf",
 Year = {2019},
 Eprint = {arXiv:1902.09630},
}

@misc{1908.03851,
 Author = {Dingfu Zhou and Jin Fang and Xibin Song and Chenye Guan and Junbo Yin and Yuchao Dai and Ruigang Yang},
 Title = {IoU Loss for 2D/3D Object Detection},
 Url = "https://arxiv.org/abs/1908.03851",
 Year = {2019},
 Eprint = {arXiv:1908.03851},
}

@misc{1908.03265,
 Author = {Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
 Title = {On the Variance of the Adaptive Learning Rate and Beyond},
 Url = "https://arxiv.org/pdf/1908.03265v1.pdf",
 Year = {2019},
 Eprint = {arXiv:1908.03265},
}


@misc{1907.08610,
 Author = {Michael R. Zhang and James Lucas and Geoffrey Hinton and Jimmy Ba},
 Title = {Lookahead Optimizer: k steps forward, 1 step back},
 Url = "https://arxiv.org/pdf/1907.08610v1.pdf",
 Year = {2019},
 Eprint = {arXiv:1907.08610},
}

@misc{1706.03762,
 Author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
 Title = {Attention Is All You Need},
 Url = "https://arxiv.org/pdf/1706.03762.pdf",
 Year = {2017},
 Eprint = {arXiv:1706.03762},
}

@misc{1301.3781,
 Author = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
 Title = {Efficient Estimation of Word Representations in Vector Space},
 Url = "https://arxiv.org/abs/1301.3781",
 Year = {2013},
 Eprint = {arXiv:1301.3781},
}


</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
