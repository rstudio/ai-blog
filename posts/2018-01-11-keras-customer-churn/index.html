<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn</title>

<meta property="description" itemprop="description" content="Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2018-01-11"/>
<meta property="article:created" itemprop="dateCreated" content="2018-01-11"/>
<meta name="article:author" content="Matt Dancho"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/images/customer_churn_analysis_corrr.png"/>
<meta property="og:image:width" content="2696"/>
<meta property="og:image:height" content="1696"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn"/>
<meta property="twitter:description" content="Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/images/customer_churn_analysis_corrr.png"/>
<meta property="twitter:image:width" content="2696"/>
<meta property="twitter:image:height" content="1696"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"/>
<meta name="citation_online_date" content="2018/01/11"/>
<meta name="citation_publication_date" content="2018/01/11"/>
<meta name="citation_author" content="Matt Dancho"/>
<meta name="citation_author_institution" content="Business Science"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","categories","preview","creative_commons","output","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Deep Learning With Keras To Predict Customer Churn"]},{"type":"character","attributes":{},"value":["Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Matt Dancho"]},{"type":"character","attributes":{},"value":["https://github.com/mdancho84"]},{"type":"character","attributes":{},"value":["Business Science"]},{"type":"character","attributes":{},"value":["https://www.business-science.io/"]}]}]},{"type":"character","attributes":{},"value":["01-11-2018"]},{"type":"character","attributes":{},"value":["TensorFlow/Keras","Tabular Data","Explainability"]},{"type":"character","attributes":{},"value":["images/customer_churn_analysis_corrr.png"]},{"type":"NULL"},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["images/Artificial-Neural-Network-Architecture.jpg","images/customer_churn_analysis_corrr.png","images/customer_churn_analysis_lime.png","images/customer_churn_analysis.png","images/figure-html/unnamed-chunk-10-1.png","images/figure-html/unnamed-chunk-11-1.png","images/figure-html/unnamed-chunk-12-1.png","images/figure-html/unnamed-chunk-14-1.png","images/figure-html/unnamed-chunk-23-1.png","images/figure-html/unnamed-chunk-41-1.png","images/figure-html/unnamed-chunk-42-1.png","images/figure-html/unnamed-chunk-44-1.png","images/figure-html/unnamed-chunk-45-1.png","images/figure-html/unnamed-chunk-46-1.png","images/figure-html/unnamed-chunk-47-1.png","images/figure-html/unnamed-chunk-48-1.png","images/figure-html/unnamed-chunk-49-1.png","images/figure-html/unnamed-chunk-50-1.png","images/figure-html/unnamed-chunk-9-1.png","images/shiny-application.png","keras-customer-churn_files/bowser-1.9.3/bowser.min.js","keras-customer-churn_files/distill-2.2.21/template.v2.js","keras-customer-churn_files/jquery-1.11.3/jquery.min.js","keras-customer-churn_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.6/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Deep Learning With Keras To Predict Customer Churn","description":"Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics.","authors":[{"author":"Matt Dancho","authorURL":"https://github.com/mdancho84","affiliation":"Business Science","affiliationURL":"https://www.business-science.io/","orcidID":""}],"publishedDate":"2018-01-11T00:00:00.000+00:00","citationText":"Dancho, 2018"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Deep Learning With Keras To Predict Customer Churn</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
  <a href="../../index.html#category:Tabular_Data" class="dt-tag">Tabular Data</a>
  <a href="../../index.html#category:Explainability" class="dt-tag">Explainability</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics.</p></p>
</div>

<div class="d-byline">
  Matt Dancho <a href="https://github.com/mdancho84" class="uri">https://github.com/mdancho84</a> (Business Science)<a href="https://www.business-science.io/" class="uri">https://www.business-science.io/</a>
  
<br/>01-11-2018
</div>

<div class="d-article">
<div class="layout-chunk" data-layout="l-body">
<style type="text/css">
strong {
  font-weight: normal;
}
</style>
</div>
<h2 id="introduction">Introduction</h2>
<p><strong>Customer churn is a problem that all companies need to monitor, especially those that depend on subscription-based revenue streams</strong>. The simple fact is that most organizations have data that can be used to target these individuals and to understand the key drivers of churn, and <strong>we now have Keras for Deep Learning available in R (Yes, in R!!), which predicted customer churn with 82% accuracy</strong>.</p>
<p>Were super excited for this article because we are using the new <a href="https://tensorflow.rstudio.com/keras/">keras</a> package to produce an <strong>Artificial Neural Network (ANN)</strong> model on the <a href="https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/">IBM Watson Telco Customer Churn Data Set</a>! As with most business problems, its equally important to <strong>explain what features drive the model</strong>, which is why well use the <a href="https://github.com/thomasp85/lime">lime</a> package for explainability. We cross-checked the LIME results with a Correlation Analysis using the <a href="https://github.com/drsimonj/corrr">corrr</a> package.</p>
<p>In addition, we use <strong>three new packages to assist with Machine Learning (ML)</strong>: <a href="https://topepo.github.io/recipes">recipes</a> for preprocessing, <a href="https://topepo.github.io/rsample/">rsample</a> for sampling data and <a href="https://github.com/topepo/yardstick">yardstick</a> for model metrics. These are relatively new additions to CRAN developed by <a href="https://github.com/topepo">Max Kuhn</a> at RStudio (creator of the <a href="http://topepo.github.io/caret/index.html">caret</a> package). It seems that <em>R is quickly developing ML tools that rival Python</em>. Good news if youre interested in applying Deep Learning in R! We are so lets get going!!</p>
<h2 id="customer-churn-hurts-sales-hurts-company">Customer Churn: Hurts Sales, Hurts Company</h2>
<p>Customer churn refers to the situation when a customer ends their relationship with a company, and its a costly problem. Customers are the fuel that powers a business. Loss of customers impacts sales. Further, its much more difficult and costly to gain new customers than it is to retain existing customers. As a result, <strong>organizations need to focus on reducing customer churn</strong>.</p>
<p>The good news is that <strong>machine learning can help</strong>. For many businesses that offer subscription based services, its critical to both predict customer churn and explain what features relate to customer churn. Older techniques such as logistic regression can be less accurate than newer techniques such as deep learning, which is why <strong>we are going to show you how to model an ANN in R with the <a href="https://tensorflow.rstudio.com/keras/">keras</a> package</strong>.</p>
<h2 id="churn-modeling-with-artificial-neural-networks-keras">Churn Modeling With Artificial Neural Networks (Keras)</h2>
<p>Artificial Neural Networks (ANN) are now a staple within the sub-field of Machine Learning called Deep Learning. <strong>Deep learning algorithms can be vastly superior to traditional regression and classification methods</strong> (e.g.linear and logistic regression) because of the ability to model interactions between features that would otherwise go undetected. The challenge becomes explainability, which is often needed to support the business case. The good news is we get the best of both worlds with <code>keras</code> and <code>lime</code>.</p>
<h3 id="ibm-watson-dataset-where-we-got-the-data">IBM Watson Dataset (Where We Got The Data)</h3>
<p>The dataset used for this tutorial is <a href="https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/">IBM Watson Telco Dataset</a>. According to IBM, the business challenge is</p>
<blockquote>
<p>A telecommunications company [Telco] is concerned about the number of customers leaving their landline business for cable competitors. They need to understand who is leaving. Imagine that youre an analyst at this company and you have to find out who is leaving and why.</p>
</blockquote>
<p>The dataset includes information about:</p>
<ul>
<li><strong>Customers who left within the last month</strong>: The column is called Churn</li>
<li><strong>Services that each customer has signed up for</strong>: phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies</li>
<li><strong>Customer account information</strong>: how long theyve been a customer, contract, payment method, paperless billing, monthly charges, and total charges</li>
<li><strong>Demographic info about customers</strong>: gender, age range, and if they have partners and dependents</li>
</ul>
<h3 id="deep-learning-with-keras-what-we-did-with-the-data">Deep Learning With Keras (What We Did With The Data)</h3>
<p>In this example we show you how to use <a href="https://tensorflow.rstudio.com/keras/">keras</a> to develop a sophisticated and highly accurate deep learning model in R. We walk you through the preprocessing steps, investing time into how to format the data for Keras. We inspect the various classification metrics, and show that <strong>an un-tuned ANN model can easily get 82% accuracy on the unseen data</strong>. Heres the deep learning training history visualization.</p>
<p><img src="images/customer_churn_analysis.png" /></p>
<p>We have some fun with preprocessing the data (<em>yes, preprocessing can actually be fun and easy!</em>). We use the new <a href="https://topepo.github.io/recipes">recipes</a> package to simplify the preprocessing workflow.</p>
<p>We end by showing you how to explain the ANN with the <a href="https://github.com/thomasp85/lime">lime</a> package. <strong>Neural networks used to be frowned upon because of the black box nature</strong> meaning these sophisticated models (ANNs are highly accurate) are difficult to explain using traditional methods. <strong>Not any more with LIME!</strong> Heres the feature importance visualization.</p>
<p><img src="images/customer_churn_analysis_lime.png" /></p>
<p>We also cross-checked the LIME results with a <strong>Correlation Analysis</strong> using the <a href="https://github.com/drsimonj/corrr">corrr</a> package. Heres the correlation visualization.</p>
<div class="l-body-outset">
<p><img src="images/customer_churn_analysis_corrr.png" style="width:100.0%" /></p>
</div>
<p>We even built a <strong>Shiny Application</strong> with a <strong>Customer Scorecard</strong> to monitor customer churn risk and to make recommendations on how to improve customer health! Feel free to take it for a spin.</p>
<div class="l-body-outset">
<p><a href="https://jjallaire.shinyapps.io/keras-customer-churn/"><img src="images/shiny-application.png" class="illustration" width="100%"/></a></p>
</div>
<h3 id="credits">Credits</h3>
<p>We saw that just last week the same Telco customer churn dataset was used in the article, <a href="https://datascienceplus.com/predict-customer-churn-logistic-regression-decision-tree-and-random-forest/">Predict Customer Churn  Logistic Regression, Decision Tree and Random Forest</a>. We thought the article was excellent.</p>
<p>This article takes a different approach with Keras, LIME, Correlation Analysis, and a few other cutting edge packages. We encourage the readers to check out both articles because, although the problem is the same, both solutions are beneficial to those learning data science and advanced modeling.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>We use the following libraries in this tutorial:</p>
<ul>
<li><a href="https://tensorflow.rstudio.com/keras/">keras</a>: Library that ports Keras from Python enabling deep learning in R. Visit the <a href="https://tensorflow.rstudio.com/keras/">documentation</a> for more information.</li>
<li><a href="https://github.com/thomasp85/lime">lime</a>: Used to explain the predictions of black box classifiers. Deep Learning falls into this category.</li>
<li><a href="https://business-science.github.io/tidyquant/">tidyquant</a>: Loads the <a href="https://www.tidyverse.org/">tidyverse</a> (<a href="http://dplyr.tidyverse.org">dplyr</a>, <a href="http://ggplot2.tidyverse.org">ggplot2</a>, etc) and has nice visualization functions with <a href="https://business-science.github.io/tidyquant/reference/theme_tq.html">theme_tq()</a>. Visit the <a href="https://business-science.github.io/tidyquant/">tidyquant documentation</a> and the <a href="https://www.tidyverse.org/">tidyverse documentation</a> for more information on the individual packages.</li>
<li><a href="https://topepo.github.io/rsample/">rsample</a>: New package for generating resamples. Visit the <a href="https://topepo.github.io/rsample/">documentation</a> for more information.</li>
<li><a href="https://topepo.github.io/recipes">recipes</a>: New package for preprocessing machine learning data sets. Visit the <a href="https://topepo.github.io/recipes/">documentation</a> for more information.</li>
<li><a href="https://github.com/topepo/yardstick">yardstick</a>: Tidy methods for measuring model performance. Visit the <a href="https://github.com/topepo/yardstick">GitHub Page</a> for more information.</li>
<li><a href="https://github.com/drsimonj/corrr">corrr</a>: Tidy methods for correlation. Visit the <a href="https://github.com/drsimonj/corrr">GitHub Page</a> for more information.</li>
</ul>
<p>Install the following packages with <code>install.packages()</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>pkgs</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"keras"</span>, <span class='st'>"lime"</span>, <span class='st'>"tidyquant"</span>, <span class='st'>"rsample"</span>, <span class='st'>"recipes"</span>, <span class='st'>"yardstick"</span>, <span class='st'>"corrr"</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/install.packages.html'>install.packages</a></span><span class='op'>(</span><span class='va'>pkgs</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="load-libraries">Load Libraries</h2>
<p>Load the libraries.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Load libraries</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>keras</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>lime</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tidyquant</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>rsample</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>recipes</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>yardstick</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>corrr</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>If you have not previously run Keras in R, you will need to install Keras using the <code>install_keras()</code> function.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Install Keras if you have not installed before</span>
<span class='fu'>install_keras</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="import-data">Import Data</h2>
<p>Download the <a href="https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/">IBM Watson Telco Data Set here</a>. Next, use <code>read_csv()</code> to import the data into a nice tidy data frame. We use the <code>glimpse()</code> function to quickly inspect the data. We have the target Churn and all other variables are potential predictors. The raw data set needs to be cleaned and preprocessed for ML.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>churn_data_raw</span> <span class='op'>&lt;-</span> <span class='fu'>read_csv</span><span class='op'>(</span><span class='st'>"WA_Fn-UseC_-Telco-Customer-Churn.csv"</span><span class='op'>)</span>

<span class='fu'><a href='https://tibble.tidyverse.org/reference/glimpse.html'>glimpse</a></span><span class='op'>(</span><span class='va'>churn_data_raw</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>Observations: 7,043
Variables: 21
$ customerID       &lt;chr&gt; &quot;7590-VHVEG&quot;, &quot;5575-GNVDE&quot;, &quot;3668-QPYBK&quot;, &quot;77...
$ gender           &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;...
$ SeniorCitizen    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
$ Partner          &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N...
$ Dependents       &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;N...
$ tenure           &lt;int&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 5...
$ PhoneService     &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;...
$ MultipleLines    &lt;chr&gt; &quot;No phone service&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No phone ser...
$ InternetService  &lt;chr&gt; &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;Fiber optic&quot;, &quot;F...
$ OnlineSecurity   &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, ...
$ OnlineBackup     &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, ...
$ DeviceProtection &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, ...
$ TechSupport      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N...
$ StreamingTV      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;...
$ StreamingMovies  &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;N...
$ Contract         &lt;chr&gt; &quot;Month-to-month&quot;, &quot;One year&quot;, &quot;Month-to-month...
$ PaperlessBilling &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;...
$ PaymentMethod    &lt;chr&gt; &quot;Electronic check&quot;, &quot;Mailed check&quot;, &quot;Mailed c...
$ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89....
$ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820....
$ Churn            &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, ...</code></pre>
<h2 id="preprocess-data">Preprocess Data</h2>
<p>Well go through a few steps to preprocess the data for ML. First, we prune the data, which is nothing more than removing unnecessary columns and rows. Then we split into training and testing sets. After that we explore the training set to uncover transformations that will be needed for deep learning. We save the best for last. We end by preprocessing the data with the new <a href="https://topepo.github.io/recipes">recipes</a> package.</p>
<h3 id="prune-the-data">Prune The Data</h3>
<p>The data has a few columns and rows wed like to remove:</p>
<ul>
<li>The customerID column is a unique identifier for each observation that isnt needed for modeling. We can de-select this column.</li>
<li>The data has 11 <code>NA</code> values all in the TotalCharges column. Because its such a small percentage of the total population (99.8% complete cases), we can drop these observations with the <code>drop_na()</code> function from <a href="http://tidyr.tidyverse.org">tidyr</a>. Note that these may be customers that have not yet been charged, and therefore an alternative is to replace with zero or -99 to segregate this population from the rest.</li>
<li>My preference is to have the target in the first column so well include a final select() ooperation to do so.</li>
</ul>
<p>Well perform the cleaning operation with one tidyverse pipe (%&gt;%) chain.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Remove unnecessary data</span>
<span class='va'>churn_data_tbl</span> <span class='op'>&lt;-</span> <span class='va'>churn_data_raw</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='op'>-</span><span class='va'>customerID</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>drop_na</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='va'>Churn</span>, <span class='fu'><a href='https://tidyselect.r-lib.org/reference/everything.html'>everything</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
    
<span class='fu'><a href='https://tibble.tidyverse.org/reference/glimpse.html'>glimpse</a></span><span class='op'>(</span><span class='va'>churn_data_tbl</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>Observations: 7,032
Variables: 20
$ Churn            &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, ...
$ gender           &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;...
$ SeniorCitizen    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...
$ Partner          &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N...
$ Dependents       &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;N...
$ tenure           &lt;int&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 5...
$ PhoneService     &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;...
$ MultipleLines    &lt;chr&gt; &quot;No phone service&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No phone ser...
$ InternetService  &lt;chr&gt; &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;Fiber optic&quot;, &quot;F...
$ OnlineSecurity   &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, ...
$ OnlineBackup     &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, ...
$ DeviceProtection &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, ...
$ TechSupport      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N...
$ StreamingTV      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;...
$ StreamingMovies  &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;N...
$ Contract         &lt;chr&gt; &quot;Month-to-month&quot;, &quot;One year&quot;, &quot;Month-to-month...
$ PaperlessBilling &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;...
$ PaymentMethod    &lt;chr&gt; &quot;Electronic check&quot;, &quot;Mailed check&quot;, &quot;Mailed c...
$ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89....
$ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820..</code></pre>
<h3 id="split-into-traintest-sets">Split Into Train/Test Sets</h3>
<p>We have a new package, <a href="https://topepo.github.io/rsample/">rsample</a>, which is very useful for sampling methods. It has the <code>initial_split()</code> function for splitting data sets into training and testing sets. The return is a special <code>rsplit</code> object.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Split test/training sets</span>
<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>100</span><span class='op'>)</span>
<span class='va'>train_test_split</span> <span class='op'>&lt;-</span> <span class='fu'>initial_split</span><span class='op'>(</span><span class='va'>churn_data_tbl</span>, prop <span class='op'>=</span> <span class='fl'>0.8</span><span class='op'>)</span>
<span class='va'>train_test_split</span>
</code></pre>
</div>
</div>
<pre><code>&lt;5626/1406/7032&gt;</code></pre>
<p>We can retrieve our training and testing sets using <code>training()</code> and <code>testing()</code> functions.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Retrieve train and test sets</span>
<span class='va'>train_tbl</span> <span class='op'>&lt;-</span> <span class='fu'>training</span><span class='op'>(</span><span class='va'>train_test_split</span><span class='op'>)</span>
<span class='va'>test_tbl</span>  <span class='op'>&lt;-</span> <span class='fu'>testing</span><span class='op'>(</span><span class='va'>train_test_split</span><span class='op'>)</span> 
</code></pre>
</div>
</div>
<h3 id="exploration-what-transformation-steps-are-needed-for-ml">Exploration: What Transformation Steps Are Needed For ML?</h3>
<p>This phase of the analysis is often called exploratory analysis, but basically <strong>we are trying to answer the question, What steps are needed to prepare for ML? The key concept is knowing what transformations are needed to run the algorithm most effectively</strong>. Artificial Neural Networks are best when the data is one-hot encoded, scaled and centered. In addition, other transformations may be beneficial as well to make relationships easier for the algorithm to identify. A full exploratory analysis is not practical in this article. With that said well cover a few tips on transformations that can help as they relate to this dataset. In the next section, we will implement the preprocessing techniques.</p>
<h4 id="discretize-the-tenure-feature">Discretize The tenure Feature</h4>
<p>Numeric features like age, years worked, length of time in a position can generalize a group (or cohort). We see this in marketing a lot (think millennials, which identifies a group born in a certain timeframe). The tenure feature falls into this category of numeric features that can be discretized into groups.</p>
<p><img src="images/figure-html/unnamed-chunk-9-1.png" /></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>We can split into six cohorts that divide up the user base by tenure in roughly one year (12 month) increments. This should help the ML algorithm detect if a group is more/less susceptible to customer churn.</p>
<p><img src="images/figure-html/unnamed-chunk-10-1.png" /></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="transform-the-totalcharges-feature">Transform The TotalCharges Feature</h4>
<p>What we dont like to see is when a lot of observations are bunched within a small part of the range.</p>
<p><img src="images/figure-html/unnamed-chunk-11-1.png" /></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>We can use a log transformation to even out the data into more of a normal distribution. Its not perfect, but its quick and easy to get our data spread out a bit more.</p>
<p><img src="images/figure-html/unnamed-chunk-12-1.png" /></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p><strong>Pro Tip: A quick test is to see if the log transformation increases the magnitude of the correlation</strong> between TotalCharges and Churn. Well use a few <a href="http://dplyr.tidyverse.org/">dplyr</a> operations along with the <a href="https://github.com/drsimonj/corrr">corrr</a> package to perform a quick correlation.</p>
<ul>
<li><code>correlate()</code>: Performs tidy correlations on numeric data</li>
<li><code>focus()</code>: Similar to <code>select()</code>. Takes columns and focuses on only the rows/columns of importance.</li>
<li><code>fashion()</code>: Makes the formatting aesthetically easier to read.</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Determine if log transformation improves correlation </span>
<span class='co'># between TotalCharges and Churn</span>
<span class='va'>train_tbl</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='va'>Churn</span>, <span class='va'>TotalCharges</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>
      Churn <span class='op'>=</span> <span class='va'>Churn</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>as.factor</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='op'>)</span>,
      LogTotalCharges <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>TotalCharges</span><span class='op'>)</span>
      <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>correlate</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>focus</span><span class='op'>(</span><span class='va'>Churn</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>fashion</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>          rowname Churn
1    TotalCharges  -.20
2 LogTotalCharges  -.25</code></pre>
<p>The correlation between Churn and LogTotalCharges is greatest in magnitude indicating the log transformation should improve the accuracy of the ANN model we build. Therefore, we should perform the log transformation.</p>
<h4 id="one-hot-encoding">One-Hot Encoding</h4>
<p>One-hot encoding is the process of converting categorical data to sparse data, which has columns of only zeros and ones (this is also called creating dummy variables or a design matrix). All non-numeric data will need to be converted to dummy variables. This is simple for binary Yes/No data because we can simply convert to 1s and 0s. It becomes slightly more complicated with multiple categories, which requires creating new columns of 1s and 0`s for each category (actually one less). We have four features that are multi-category: Contract, Internet Service, Multiple Lines, and Payment Method.</p>
<p><img src="images/figure-html/unnamed-chunk-14-1.png" /></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<h4 id="feature-scaling">Feature Scaling</h4>
<p>ANNs typically perform faster and often times with higher accuracy when the features are scaled and/or normalized (aka centered and scaled, also known as standardizing). Because ANNs use gradient descent, weights tend to update faster. According to <a href="https://sebastianraschka.com/"><em>Sebastian Raschka</em></a>, an expert in the field of Deep Learning, several examples when feature scaling is important are:</p>
<blockquote>
<ul>
<li>k-nearest neighbors with an Euclidean distance measure if want all features to contribute equally</li>
<li>k-means (see k-nearest neighbors)</li>
<li>logistic regression, SVMs, perceptrons, neural networks etc. if you are using gradient descent/ascent-based optimization, otherwise some weights will update much faster than others</li>
<li>linear discriminant analysis, principal component analysis, kernel principal component analysis since you want to find directions of maximizing the variance (under the constraints that those directions/eigenvectors/principal components are orthogonal); you want to have features on the same scale since youd emphasize variables on larger measurement scales more. There are many more cases than I can possibly list here  I always recommend you to think about the algorithm and what its doing, and then it typically becomes obvious whether we want to scale your features or not.</li>
</ul>
</blockquote>
<p>The interested reader can read <a href="http://sebastianraschka.com/Articles/2014_about_feature_scaling.html">Sebastian Raschkas article</a> for a full discussion on the scaling/normalization topic. <strong>Pro Tip: When in doubt, standardize the data</strong>.</p>
<h3 id="preprocessing-with-recipes">Preprocessing With Recipes</h3>
<p>Lets implement the preprocessing steps/transformations uncovered during our exploration. Max Kuhn (creator of <a href="http://topepo.github.io/caret/index.html">caret</a>) has been putting some work into <em>Rlang ML tools</em> lately, and the payoff is beginning to take shape. <strong>A new package, <a href="https://topepo.github.io/recipes">recipes</a>, makes creating ML data preprocessing workflows a breeze</strong>! It takes a little getting used to, but Ive found that it really helps manage the preprocessing steps. Well go over the nitty gritty as it applies to this problem.</p>
<h4 id="step-1-create-a-recipe">Step 1: Create A Recipe</h4>
<p>A recipe is nothing more than a series of steps you would like to perform on the training, testing and/or validation sets. Think of preprocessing data like baking a cake (Im not a baker but stay with me). The recipe is our steps to make the cake. It doesnt do anything other than create the playbook for baking.</p>
<p>We use the <code>recipe()</code> function to implement our preprocessing steps. The function takes a familiar <code>object</code> argument, which is a modeling function such as <code>object = Churn ~ .</code> meaning Churn is the outcome (aka response, predictor, target) and all other features are predictors. The function also takes the <code>data</code> argument, which gives the recipe steps perspective on how to apply during baking (next).</p>
<p>A recipe is not very useful until we add steps, which are used to transform the data during baking. The package contains a number of useful step functions that can be applied. The entire list of <a href="https://topepo.github.io/recipes/reference/index.html">Step Functions</a> can be viewed here. For our model, we use:</p>
<ol type="1">
<li><code>step_discretize()</code> with the <code>option = list(cuts = 6)</code> to cut the continuous variable for tenure (number of years as a customer) to group customers into cohorts.</li>
<li><code>step_log()</code> to log transform TotalCharges.</li>
<li><code>step_dummy()</code> to one-hot encode the categorical data. Note that this adds columns of one/zero for categorical data with three or more categories.</li>
<li><code>step_center()</code> to mean-center the data.</li>
<li><code>step_scale()</code> to scale the data.</li>
</ol>
<p>The last step is to prepare the recipe with the <code>prep()</code> function. This step is used to estimate the required parameters from a training set that can later be applied to other data sets. This is important for centering and scaling and other functions that use parameters defined from the training set.</p>
<p><strong>Heres how simple it is to implement the preprocessing steps that we went over!</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Create recipe</span>
<span class='va'>rec_obj</span> <span class='op'>&lt;-</span> <span class='fu'>recipe</span><span class='op'>(</span><span class='va'>Churn</span> <span class='op'>~</span> <span class='va'>.</span>, data <span class='op'>=</span> <span class='va'>train_tbl</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_discretize</span><span class='op'>(</span><span class='va'>tenure</span>, options <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>cuts <span class='op'>=</span> <span class='fl'>6</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_log</span><span class='op'>(</span><span class='va'>TotalCharges</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_dummy</span><span class='op'>(</span><span class='fu'>all_nominal</span><span class='op'>(</span><span class='op'>)</span>, <span class='op'>-</span><span class='fu'>all_outcomes</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_center</span><span class='op'>(</span><span class='fu'>all_predictors</span><span class='op'>(</span><span class='op'>)</span>, <span class='op'>-</span><span class='fu'>all_outcomes</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_scale</span><span class='op'>(</span><span class='fu'>all_predictors</span><span class='op'>(</span><span class='op'>)</span>, <span class='op'>-</span><span class='fu'>all_outcomes</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>prep</span><span class='op'>(</span>data <span class='op'>=</span> <span class='va'>train_tbl</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We can print the recipe object if we ever forget what steps were used to prepare the data. <strong>Pro Tip: We can save the recipe object as an RDS file using <code>saveRDS()</code>, and then use it to <code>bake()</code> (discussed next) future raw data into ML-ready data in production!</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Print the recipe object</span>
<span class='va'>rec_obj</span>
</code></pre>
</div>
</div>
<pre><code>Data Recipe

Inputs:

      role #variables
   outcome          1
 predictor         19

Training data contained 5626 data points and no missing data.

Steps:

Dummy variables from tenure [trained]
Log transformation on TotalCharges [trained]
Dummy variables from ~gender, ~Partner, ... [trained]
Centering for SeniorCitizen, ... [trained]
Scaling for SeniorCitizen, ... [trained]</code></pre>
<h4 id="step-2-baking-with-your-recipe">Step 2: Baking With Your Recipe</h4>
<p>Now for the fun part! We can apply the recipe to any data set with the <code>bake()</code> function, and it processes the data following our recipe steps. Well apply to our training and testing data to convert from raw data to a machine learning dataset. Check our training set out with <code>glimpse()</code>. <strong>Now thats an ML-ready dataset prepared for ANN modeling!!</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Predictors</span>
<span class='va'>x_train_tbl</span> <span class='op'>&lt;-</span> <span class='fu'>bake</span><span class='op'>(</span><span class='va'>rec_obj</span>, newdata <span class='op'>=</span> <span class='va'>train_tbl</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='op'>-</span><span class='va'>Churn</span><span class='op'>)</span>
<span class='va'>x_test_tbl</span>  <span class='op'>&lt;-</span> <span class='fu'>bake</span><span class='op'>(</span><span class='va'>rec_obj</span>, newdata <span class='op'>=</span> <span class='va'>test_tbl</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='op'>-</span><span class='va'>Churn</span><span class='op'>)</span>

<span class='fu'><a href='https://tibble.tidyverse.org/reference/glimpse.html'>glimpse</a></span><span class='op'>(</span><span class='va'>x_train_tbl</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>Observations: 5,626
Variables: 35
$ SeniorCitizen                         &lt;dbl&gt; -0.4351959, -0.4351...
$ MonthlyCharges                        &lt;dbl&gt; -1.1575972, -0.2601...
$ TotalCharges                          &lt;dbl&gt; -2.275819130, 0.389...
$ gender_Male                           &lt;dbl&gt; -1.0016900, 0.99813...
$ Partner_Yes                           &lt;dbl&gt; 1.0262054, -0.97429...
$ Dependents_Yes                        &lt;dbl&gt; -0.6507747, -0.6507...
$ tenure_bin1                           &lt;dbl&gt; 2.1677790, -0.46121...
$ tenure_bin2                           &lt;dbl&gt; -0.4389453, -0.4389...
$ tenure_bin3                           &lt;dbl&gt; -0.4481273, -0.4481...
$ tenure_bin4                           &lt;dbl&gt; -0.4509837, 2.21698...
$ tenure_bin5                           &lt;dbl&gt; -0.4498419, -0.4498...
$ tenure_bin6                           &lt;dbl&gt; -0.4337508, -0.4337...
$ PhoneService_Yes                      &lt;dbl&gt; -3.0407367, 0.32880...
$ MultipleLines_No.phone.service        &lt;dbl&gt; 3.0407367, -0.32880...
$ MultipleLines_Yes                     &lt;dbl&gt; -0.8571364, -0.8571...
$ InternetService_Fiber.optic           &lt;dbl&gt; -0.8884255, -0.8884...
$ InternetService_No                    &lt;dbl&gt; -0.5272627, -0.5272...
$ OnlineSecurity_No.internet.service    &lt;dbl&gt; -0.5272627, -0.5272...
$ OnlineSecurity_Yes                    &lt;dbl&gt; -0.6369654, 1.56966...
$ OnlineBackup_No.internet.service      &lt;dbl&gt; -0.5272627, -0.5272...
$ OnlineBackup_Yes                      &lt;dbl&gt; 1.3771987, -0.72598...
$ DeviceProtection_No.internet.service  &lt;dbl&gt; -0.5272627, -0.5272...
$ DeviceProtection_Yes                  &lt;dbl&gt; -0.7259826, 1.37719...
$ TechSupport_No.internet.service       &lt;dbl&gt; -0.5272627, -0.5272...
$ TechSupport_Yes                       &lt;dbl&gt; -0.6358628, -0.6358...
$ StreamingTV_No.internet.service       &lt;dbl&gt; -0.5272627, -0.5272...
$ StreamingTV_Yes                       &lt;dbl&gt; -0.7917326, -0.7917...
$ StreamingMovies_No.internet.service   &lt;dbl&gt; -0.5272627, -0.5272...
$ StreamingMovies_Yes                   &lt;dbl&gt; -0.797388, -0.79738...
$ Contract_One.year                     &lt;dbl&gt; -0.5156834, 1.93882...
$ Contract_Two.year                     &lt;dbl&gt; -0.5618358, -0.5618...
$ PaperlessBilling_Yes                  &lt;dbl&gt; 0.8330334, -1.20021...
$ PaymentMethod_Credit.card..automatic. &lt;dbl&gt; -0.5231315, -0.5231...
$ PaymentMethod_Electronic.check        &lt;dbl&gt; 1.4154085, -0.70638...
$ PaymentMethod_Mailed.check            &lt;dbl&gt; -0.5517013, 1.81225...</code></pre>
<h4 id="step-3-dont-forget-the-target">Step 3: Dont Forget The Target</h4>
<p>One last step, we need to store the actual values (truth) as <code>y_train_vec</code> and <code>y_test_vec</code>, which are needed for modeling our ANN. We convert to a series of numeric ones and zeros which can be accepted by the Keras ANN modeling functions. We add vec to the name so we can easily remember the class of the object (its easy to get confused when working with tibbles, vectors, and matrix data types).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Response variables for training and testing sets</span>
<span class='va'>y_train_vec</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>train_tbl</span>, <span class='va'>Churn</span><span class='op'>)</span> <span class='op'>==</span> <span class='st'>"Yes"</span>, <span class='fl'>1</span>, <span class='fl'>0</span><span class='op'>)</span>
<span class='va'>y_test_vec</span>  <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>test_tbl</span>, <span class='va'>Churn</span><span class='op'>)</span> <span class='op'>==</span> <span class='st'>"Yes"</span>, <span class='fl'>1</span>, <span class='fl'>0</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="model-customer-churn-with-keras-deep-learning">Model Customer Churn With Keras (Deep Learning)</h2>
<p><strong>This is super exciting!! Finally, Deep Learning with Keras in R!</strong> The team at RStudio has done fantastic work recently to create the <a href="https://tensorflow.rstudio.com/keras/">keras</a> package, which implements <a href="https://keras.io/">Keras</a> in R. Very cool!</p>
<h3 id="background-on-artifical-neural-networks">Background On Artifical Neural Networks</h3>
<p>For those unfamiliar with Neural Networks (and those that need a refresher), <a href="https://www.xenonstack.com/blog/overview-of-artificial-neural-networks-and-its-applications">read this article</a>. Its very comprehensive, and youll leave with a general understanding of the types of deep learning and how they work.</p>
<p><img src="images/Artificial-Neural-Network-Architecture.jpg" /></p>
<p class="text-center date">
Source: <a href="https://www.xenonstack.com/blog/overview-of-artificial-neural-networks-and-its-applications">Xenon Stack</a>
</p>
<p>Deep Learning has been available in R for some time, but the primary packages used in the wild have not (this includes Keras, Tensor Flow, Theano, etc, which are all Python libraries). Its worth mentioning that a number of other Deep Learning packages exist in R including <code>h2o</code>, <code>mxnet</code>, and others. The interested reader can check out <a href="http://www.rblog.uni-freiburg.de/2017/02/07/deep-learning-in-r/">this blog post for a comparison of deep learning packages in R</a>.</p>
<h3 id="building-a-deep-learning-model">Building A Deep Learning Model</h3>
<p>Were going to build a special class of ANN called a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">Multi-Layer Perceptron (MLP)</a>. MLPs are one of the simplest forms of deep learning, but they are both highly accurate and serve as a jumping-off point for more complex algorithms. MLPs are quite versatile as they can be used for regression, binary and multi classification (and are typically quite good at classification problems).</p>
<p>Well build a three layer MLP with Keras. Lets walk-through the steps before we implement in R.</p>
<ol type="1">
<li><p><strong>Initialize a sequential model</strong>: The first step is to initialize a sequential model with <code>keras_model_sequential()</code>, which is the beginning of our Keras model. The sequential model is composed of a linear stack of layers.</p></li>
<li><p><strong>Apply layers to the sequential model</strong>: Layers consist of the input layer, hidden layers and an output layer. The input layer is the data and provided its formatted correctly theres nothing more to discuss. The hidden layers and output layers are what controls the ANN inner workings.</p>
<ul>
<li><p><strong>Hidden Layers</strong>: Hidden layers form the neural network nodes that enable non-linear activation using weights. The hidden layers are created using <code>layer_dense()</code>. Well add two hidden layers. Well apply <code>units = 16</code>, which is the number of nodes. Well select <code>kernel_initializer = "uniform"</code> and <code>activation = "relu"</code> for both layers. The first layer needs to have the <code>input_shape = 35</code>, which is the number of columns in the training set. <strong>Key Point: While we are arbitrarily selecting the number of hidden layers, units, kernel initializers and activation functions, these parameters can be optimized through a process called hyperparameter tuning that is discussed in <a href="#next-steps">Next Steps</a></strong>.</p></li>
<li><p><strong>Dropout Layers</strong>: Dropout layers are used to control overfitting. This eliminates weights below a cutoff threshold to prevent low weights from overfitting the layers. We use the <code>layer_dropout()</code> function add two drop out layers with <code>rate = 0.10</code> to remove weights below 10%.</p></li>
<li><p><strong>Output Layer</strong>: The output layer specifies the shape of the output and the method of assimilating the learned information. The output layer is applied using the <code>layer_dense()</code>. For binary values, the shape should be <code>units = 1</code>. For multi-classification, the <code>units</code> should correspond to the number of classes. We set the <code>kernel_initializer = "uniform"</code> and the <code>activation = "sigmoid"</code> (common for binary classification).</p></li>
</ul></li>
<li><p><strong>Compile the model</strong>: The last step is to compile the model with <code>compile()</code>. Well use <code>optimizer = "adam"</code>, which is one of the most popular optimization algorithms. We select <code>loss = "binary_crossentropy"</code> since this is a binary classification problem. Well select <code>metrics = c("accuracy")</code> to be evaluated during training and testing. <strong>Key Point: The optimizer is often included in the tuning process</strong>.</p></li>
</ol>
<p>Lets codify the discussion above to build our Keras MLP-flavored ANN model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Building our Artificial Neural Network</span>
<span class='va'>model_keras</span> <span class='op'>&lt;-</span> <span class='fu'>keras_model_sequential</span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>model_keras</span> <span class='op'>%&gt;%</span> 
  
  <span class='co'># First hidden layer</span>
  <span class='fu'>layer_dense</span><span class='op'>(</span>
    units              <span class='op'>=</span> <span class='fl'>16</span>, 
    kernel_initializer <span class='op'>=</span> <span class='st'>"uniform"</span>, 
    activation         <span class='op'>=</span> <span class='st'>"relu"</span>, 
    input_shape        <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>ncol</a></span><span class='op'>(</span><span class='va'>x_train_tbl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  
  <span class='co'># Dropout to prevent overfitting</span>
  <span class='fu'>layer_dropout</span><span class='op'>(</span>rate <span class='op'>=</span> <span class='fl'>0.1</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  
  <span class='co'># Second hidden layer</span>
  <span class='fu'>layer_dense</span><span class='op'>(</span>
    units              <span class='op'>=</span> <span class='fl'>16</span>, 
    kernel_initializer <span class='op'>=</span> <span class='st'>"uniform"</span>, 
    activation         <span class='op'>=</span> <span class='st'>"relu"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  
  <span class='co'># Dropout to prevent overfitting</span>
  <span class='fu'>layer_dropout</span><span class='op'>(</span>rate <span class='op'>=</span> <span class='fl'>0.1</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  
  <span class='co'># Output layer</span>
  <span class='fu'>layer_dense</span><span class='op'>(</span>
    units              <span class='op'>=</span> <span class='fl'>1</span>, 
    kernel_initializer <span class='op'>=</span> <span class='st'>"uniform"</span>, 
    activation         <span class='op'>=</span> <span class='st'>"sigmoid"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  
  <span class='co'># Compile ANN</span>
  <span class='fu'>compile</span><span class='op'>(</span>
    optimizer <span class='op'>=</span> <span class='st'>'adam'</span>,
    loss      <span class='op'>=</span> <span class='st'>'binary_crossentropy'</span>,
    metrics   <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'accuracy'</span><span class='op'>)</span>
  <span class='op'>)</span>

<span class='va'>keras_model</span>
</code></pre>
</div>
</div>
<pre><code>Model
___________________________________________________________________________________________________
Layer (type)                                Output Shape                            Param #        
===================================================================================================
dense_1 (Dense)                             (None, 16)                              576            
___________________________________________________________________________________________________
dropout_1 (Dropout)                         (None, 16)                              0              
___________________________________________________________________________________________________
dense_2 (Dense)                             (None, 16)                              272            
___________________________________________________________________________________________________
dropout_2 (Dropout)                         (None, 16)                              0              
___________________________________________________________________________________________________
dense_3 (Dense)                             (None, 1)                               17             
===================================================================================================
Total params: 865
Trainable params: 865
Non-trainable params: 0
___________________________________________________________________________________________________</code></pre>
<p>We use the <code>fit()</code> function to run the ANN on our training data. The <code>object</code> is our model, and <code>x</code> and <code>y</code> are our training data in matrix and numeric vector forms, respectively. The <code>batch_size = 50</code> sets the number samples per gradient update within each epoch. We set <code>epochs = 35</code> to control the number training cycles. Typically we want to keep the batch size high since this decreases the error within each training cycle (epoch). We also want epochs to be large, which is important in visualizing the training history (discussed below). We set <code>validation_split = 0.30</code> to include 30% of the data for model validation, which prevents overfitting. The training process should complete in 15 seconds or so.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Fit the keras model to the training data</span>
<span class='va'>history</span> <span class='op'>&lt;-</span> <span class='fu'>fit</span><span class='op'>(</span>
  object           <span class='op'>=</span> <span class='va'>model_keras</span>, 
  x                <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>x_train_tbl</span><span class='op'>)</span>, 
  y                <span class='op'>=</span> <span class='va'>y_train_vec</span>,
  batch_size       <span class='op'>=</span> <span class='fl'>50</span>, 
  epochs           <span class='op'>=</span> <span class='fl'>35</span>,
  validation_split <span class='op'>=</span> <span class='fl'>0.30</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>We can inspect the training history. We want to make sure there is minimal difference between the validation accuracy and the training accuracy.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Print a summary of the training history</span>
<span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span><span class='va'>history</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>Trained on 3,938 samples, validated on 1,688 samples (batch_size=50, epochs=35)
Final epoch (plot to see history):
val_loss: 0.4215
 val_acc: 0.8057
    loss: 0.399
     acc: 0.8101</code></pre>
<p>We can visualize the Keras training history using the <code>plot()</code> function. What we want to see is the validation accuracy and loss leveling off, which means the model has completed training. We see that there is some divergence between training loss/accuracy and validation loss/accuracy. This model indicates we can possibly stop training at an earlier epoch. <strong>Pro Tip: Only use enough epochs to get a high validation accuracy. Once validation accuracy curve begins to flatten or decrease, its time to stop training.</strong></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Plot the training/validation history of our Keras model</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>history</span><span class='op'>)</span> 
</code></pre>
</div>
</div>
<p><img src="images/figure-html/unnamed-chunk-23-1.png" /></p>
<h3 id="making-predictions">Making Predictions</h3>
<p>Weve got a good model based on the validation accuracy. Now lets make some predictions from our <a href="https://tensorflow.rstudio.com/keras/">keras</a> model on the test data set, which was unseen during modeling (we use this for the true performance assessment). We have two functions to generate predictions:</p>
<ul>
<li><code>predict_classes()</code>: Generates class values as a matrix of ones and zeros. Since we are dealing with binary classification, well convert the output to a vector.</li>
<li><code>predict_proba()</code>: Generates the class probabilities as a numeric matrix indicating the probability of being a class. Again, we convert to a numeric vector because there is only one column output.</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Predicted Class</span>
<span class='va'>yhat_keras_class_vec</span> <span class='op'>&lt;-</span> <span class='fu'>predict_classes</span><span class='op'>(</span>object <span class='op'>=</span> <span class='va'>model_keras</span>, x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>x_test_tbl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/r/base/vector.html'>as.vector</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='co'># Predicted Class Probability</span>
<span class='va'>yhat_keras_prob_vec</span>  <span class='op'>&lt;-</span> <span class='fu'>predict_proba</span><span class='op'>(</span>object <span class='op'>=</span> <span class='va'>model_keras</span>, x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>x_test_tbl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/r/base/vector.html'>as.vector</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="inspect-performance-with-yardstick">Inspect Performance With Yardstick</h2>
<p>The <code>yardstick</code> package has a collection of handy functions for measuring performance of machine learning models. Well overview some metrics we can use to understand the performance of our model.</p>
<p>First, lets get the data formatted for <code>yardstick</code>. We create a data frame with the truth (actual values as factors), estimate (predicted values as factors), and the class probability (probability of yes as numeric). We use the <code>fct_recode()</code> function from the <a href="http://forcats.tidyverse.org">forcats</a> package to assist with recoding as Yes/No values.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Format test data and predictions for yardstick metrics</span>
<span class='va'>estimates_keras_tbl</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://tibble.tidyverse.org/reference/tibble.html'>tibble</a></span><span class='op'>(</span>
  truth      <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>as.factor</a></span><span class='op'>(</span><span class='va'>y_test_vec</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>fct_recode</span><span class='op'>(</span>yes <span class='op'>=</span> <span class='st'>"1"</span>, no <span class='op'>=</span> <span class='st'>"0"</span><span class='op'>)</span>,
  estimate   <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>as.factor</a></span><span class='op'>(</span><span class='va'>yhat_keras_class_vec</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>fct_recode</span><span class='op'>(</span>yes <span class='op'>=</span> <span class='st'>"1"</span>, no <span class='op'>=</span> <span class='st'>"0"</span><span class='op'>)</span>,
  class_prob <span class='op'>=</span> <span class='va'>yhat_keras_prob_vec</span>
<span class='op'>)</span>

<span class='va'>estimates_keras_tbl</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 1,406 x 3
    truth estimate  class_prob
   &lt;fctr&gt;   &lt;fctr&gt;       &lt;dbl&gt;
 1    yes       no 0.328355074
 2    yes      yes 0.633630514
 3     no       no 0.004589651
 4     no       no 0.007402068
 5     no       no 0.049968336
 6     no       no 0.116824441
 7     no      yes 0.775479317
 8     no       no 0.492996633
 9     no       no 0.011550998
10     no       no 0.004276015
# ... with 1,396 more rows</code></pre>
<p>Now that we have the data formatted, we can take advantage of the <code>yardstick</code> package. The only other thing we need to do is to set <code>options(yardstick.event_first = FALSE)</code>. As pointed out by <a href="https://github.com/ad1729">ad1729</a> in <a href="options(yardstick.event_first%20=%20FALSE)">GitHub Issue 13</a>, the default is to classify 0 as the positive class instead of 1.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/options.html'>options</a></span><span class='op'>(</span>yardstick.event_first <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h4 id="confusion-table">Confusion Table</h4>
<p>We can use the <code>conf_mat()</code> function to get the confusion table. We see that the model was by no means perfect, but it did a decent job of identifying customers likely to churn.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Confusion Table</span>
<span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>conf_mat</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>estimate</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>          Truth
Prediction  no yes
       no  950 161
       yes  99 196</code></pre>
<h4 id="accuracy">Accuracy</h4>
<p>We can use the <code>metrics()</code> function to get an accuracy measurement from the test set. We are getting roughly 82% accuracy.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Accuracy</span>
<span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>metrics</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>estimate</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 1 x 1
   accuracy
      &lt;dbl&gt;
1 0.8150782</code></pre>
<h4 id="auc">AUC</h4>
<p>We can also get the ROC Area Under the Curve (AUC) measurement. AUC is often a good metric used to compare different classifiers and to compare to randomly guessing (AUC_random = 0.50). Our model has AUC = 0.85, which is much better than randomly guessing. Tuning and testing different classification algorithms may yield even better results.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># AUC</span>
<span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>roc_auc</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>class_prob</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>[1] 0.8523951</code></pre>
<h4 id="precision-and-recall">Precision And Recall</h4>
<p>Precision is when the model predicts yes, how often is it actually yes. Recall (also true positive rate or specificity) is when the actual value is yes how often is the model correct. We can get <code>precision()</code> and <code>recall()</code> measurements using <code>yardstick</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Precision</span>
<span class='fu'><a href='https://tibble.tidyverse.org/reference/tibble.html'>tibble</a></span><span class='op'>(</span>
  precision <span class='op'>=</span> <span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>precision</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>estimate</span><span class='op'>)</span>,
  recall    <span class='op'>=</span> <span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>recall</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>estimate</span><span class='op'>)</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 1 x 2
  precision    recall
      &lt;dbl&gt;     &lt;dbl&gt;
1 0.6644068 0.5490196</code></pre>
<p>Precision and recall are very important to the business case: The organization is concerned with <strong>balancing the cost of targeting and retaining customers at risk of leaving with the cost of inadvertently targeting customers that are not planning to leave</strong> (and potentially decreasing revenue from this group). The threshold above which to predict Churn = Yes can be adjusted to optimize for the business problem. This becomes an <strong>Customer Lifetime Value optimization problem</strong> that is discussed further in <a href="#next-steps">Next Steps</a>.</p>
<h4 id="f1-score">F1 Score</h4>
<p>We can also get the F1-score, which is a weighted average between the precision and recall. Machine learning classifier thresholds are often adjusted to maximize the F1-score. However, this is often not the optimal solution to the business problem.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># F1-Statistic</span>
<span class='va'>estimates_keras_tbl</span> <span class='op'>%&gt;%</span> <span class='fu'>f_meas</span><span class='op'>(</span><span class='va'>truth</span>, <span class='va'>estimate</span>, beta <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>[1] 0.601227</code></pre>
<h2 id="explain-the-model-with-lime">Explain The Model With LIME</h2>
<p>LIME stands for <em>Local Interpretable Model-agnostic Explanations</em>, and is a method for explaining black-box machine learning model classifiers. For those new to LIME, this YouTube video does a really nice job explaining how LIME helps to identify feature importance with black box machine learning models (e.g.deep learning, stacked ensembles, random forest).</p>
<div class="l-body-outset">
<iframe height="500" width="100%" align="center" src="https://www.youtube.com/embed/hUnRCxnydCc" frameborder="1" allowfullscreen>
</iframe>
</div>
<h4 id="setup">Setup</h4>
<p>The <a href="https://github.com/thomasp85/lime">lime</a> package implements <a href="https://github.com/marcotcr/lime">LIME</a> in R. One thing to note is that its not setup out-of-the-box to work with <code>keras</code>. The good news is with a few functions we can get everything working properly. Well need to make two custom functions:</p>
<ul>
<li><p><code>model_type</code>: Used to tell <code>lime</code> what type of model we are dealing with. It could be classification, regression, survival, etc.</p></li>
<li><p><code>predict_model</code>: Used to allow <code>lime</code> to perform predictions that its algorithm can interpret.</p></li>
</ul>
<p>The first thing we need to do is identify the class of our model object. We do this with the <code>class()</code> function.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/class.html'>class</a></span><span class='op'>(</span><span class='va'>model_keras</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>[1] &quot;keras.models.Sequential&quot;        
[2] &quot;keras.engine.training.Model&quot;    
[3] &quot;keras.engine.topology.Container&quot;
[4] &quot;keras.engine.topology.Layer&quot;    
[5] &quot;python.builtin.object&quot;</code></pre>
<p>Next we create our <code>model_type()</code> function. Its only input is <code>x</code> the keras model. The function simply returns classification, which tells LIME we are classifying.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Setup lime::model_type() function for keras</span>
<span class='va'>model_type.keras.models.Sequential</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>...</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='st'>"classification"</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>Now we can create our <code>predict_model()</code> function, which wraps <code>keras::predict_proba()</code>. The trick here is to realize that its inputs must be <code>x</code> a model, <code>newdata</code> a dataframe object (this is important), and <code>type</code> which is not used but can be use to switch the output type. The output is also a little tricky because it <em>must be in the format of probabilities by classification</em> (this is important; shown next).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Setup lime::predict_model() function for keras</span>
<span class='va'>predict_model.keras.models.Sequential</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>newdata</span>, <span class='va'>type</span>, <span class='va'>...</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='va'>pred</span> <span class='op'>&lt;-</span> <span class='fu'>predict_proba</span><span class='op'>(</span>object <span class='op'>=</span> <span class='va'>x</span>, x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>newdata</span><span class='op'>)</span><span class='op'>)</span>
  <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>Yes <span class='op'>=</span> <span class='va'>pred</span>, No <span class='op'>=</span> <span class='fl'>1</span> <span class='op'>-</span> <span class='va'>pred</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>Run this next script to show you what the output looks like and to test our <code>predict_model()</code> function. See how its the probabilities by classification. It must be in this form for <code>model_type = "classification"</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Test our predict_model() function</span>
<span class='fu'>predict_model</span><span class='op'>(</span>x <span class='op'>=</span> <span class='va'>model_keras</span>, newdata <span class='op'>=</span> <span class='va'>x_test_tbl</span>, type <span class='op'>=</span> <span class='st'>'raw'</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>tibble</span><span class='fu'>::</span><span class='fu'><a href='https://tibble.tidyverse.org/reference/as_tibble.html'>as_tibble</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 1,406 x 2
           Yes        No
         &lt;dbl&gt;     &lt;dbl&gt;
 1 0.328355074 0.6716449
 2 0.633630514 0.3663695
 3 0.004589651 0.9954103
 4 0.007402068 0.9925979
 5 0.049968336 0.9500317
 6 0.116824441 0.8831756
 7 0.775479317 0.2245207
 8 0.492996633 0.5070034
 9 0.011550998 0.9884490
10 0.004276015 0.9957240
# ... with 1,396 more rows</code></pre>
<p>Now the fun part, we create an explainer using the <code>lime()</code> function. Just pass the training data set without the Attribution column. The form must be a data frame, which is OK since our <code>predict_model</code> function will switch it to an <code>keras</code> object. Set <code>model = automl_leader</code> our leader model, and <code>bin_continuous = FALSE</code>. We could tell the algorithm to bin continuous variables, but this may not make sense for categorical numeric data that we didnt change to factors.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Run lime() on training set</span>
<span class='va'>explainer</span> <span class='op'>&lt;-</span> <span class='fu'>lime</span><span class='fu'>::</span><span class='fu'>lime</span><span class='op'>(</span>
  x              <span class='op'>=</span> <span class='va'>x_train_tbl</span>, 
  model          <span class='op'>=</span> <span class='va'>model_keras</span>, 
  bin_continuous <span class='op'>=</span> <span class='cn'>FALSE</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Now we run the <code>explain()</code> function, which returns our <code>explanation</code>. This can take a minute to run so we limit it to just the first ten rows of the test data set. We set <code>n_labels = 1</code> because we care about explaining a single class. Setting <code>n_features = 4</code> returns the top four features that are critical to each case. Finally, setting <code>kernel_width = 0.5</code> allows us to increase the model_r2 value by shrinking the localized evaluation.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Run explain() on explainer</span>
<span class='va'>explanation</span> <span class='op'>&lt;-</span> <span class='fu'>lime</span><span class='fu'>::</span><span class='fu'>explain</span><span class='op'>(</span>
  <span class='va'>x_test_tbl</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>, <span class='op'>]</span>, 
  explainer    <span class='op'>=</span> <span class='va'>explainer</span>, 
  n_labels     <span class='op'>=</span> <span class='fl'>1</span>, 
  n_features   <span class='op'>=</span> <span class='fl'>4</span>,
  kernel_width <span class='op'>=</span> <span class='fl'>0.5</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<h4 id="feature-importance-visualization">Feature Importance Visualization</h4>
<p>The payoff for the work we put in using LIME is this <strong>feature importance plot</strong>. This allows us to visualize each of the first ten cases (observations) from the test data. The top four features for each case are shown. Note that they are not the same for each case. The green bars mean that the feature supports the model conclusion, and the red bars contradict. A few important features based on frequency in first ten cases:</p>
<ul>
<li>Tenure (7 cases)</li>
<li>Senior Citizen (5 cases)</li>
<li>Online Security (4 cases)</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>plot_features</span><span class='op'>(</span><span class='va'>explanation</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>labs</span><span class='op'>(</span>title <span class='op'>=</span> <span class='st'>"LIME Feature Importance Visualization"</span>,
       subtitle <span class='op'>=</span> <span class='st'>"Hold Out (Test) Set, First 10 Cases Shown"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p><img src="images/figure-html/unnamed-chunk-41-1.png" /></p>
<p>Another excellent visualization can be performed using <code>plot_explanations()</code>, which produces a facetted heatmap of all case/label/feature combinations. Its a more condensed version of <code>plot_features()</code>, but we need to be careful because it does not provide exact statistics and it makes it less easy to investigate binned features (Notice that tenure would not be identified as a contributor even though it shows up as a top feature in 7 of 10 cases).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>plot_explanations</span><span class='op'>(</span><span class='va'>explanation</span><span class='op'>)</span> <span class='op'>+</span>
    <span class='fu'>labs</span><span class='op'>(</span>title <span class='op'>=</span> <span class='st'>"LIME Feature Importance Heatmap"</span>,
         subtitle <span class='op'>=</span> <span class='st'>"Hold Out (Test) Set, First 10 Cases Shown"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-42-1.png" style="width:100.0%" /></p>
</div>
<h2 id="check-explanations-with-correlation-analysis">Check Explanations With Correlation Analysis</h2>
<p>One thing we need to be careful with the LIME visualization is that we are only doing a sample of the data, in our case the first 10 test observations. Therefore, we are gaining a very localized understanding of how the ANN works. However, we also want to know on from a global perspective what drives feature importance.</p>
<p>We can perform a <strong>correlation analysis</strong> on the training set as well to help glean what features correlate globally to Churn. Well use the <code>corrr</code> package, which performs tidy correlations with the function <code>correlate()</code>. We can get the correlations as follows.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># Feature correlations to Churn</span>
<span class='va'>corrr_analysis</span> <span class='op'>&lt;-</span> <span class='va'>x_train_tbl</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>Churn <span class='op'>=</span> <span class='va'>y_train_vec</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>correlate</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>focus</span><span class='op'>(</span><span class='va'>Churn</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/rename.html'>rename</a></span><span class='op'>(</span>feature <span class='op'>=</span> <span class='va'>rowname</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/arrange.html'>arrange</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span><span class='op'>(</span><span class='va'>Churn</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>feature <span class='op'>=</span> <span class='fu'>as_factor</span><span class='op'>(</span><span class='va'>feature</span><span class='op'>)</span><span class='op'>)</span> 
<span class='va'>corrr_analysis</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 35 x 2
                          feature        Churn
                           &lt;fctr&gt;        &lt;dbl&gt;
 1                    gender_Male -0.006690899
 2                    tenure_bin3 -0.009557165
 3 MultipleLines_No.phone.service -0.016950072
 4               PhoneService_Yes  0.016950072
 5              MultipleLines_Yes  0.032103354
 6                StreamingTV_Yes  0.066192594
 7            StreamingMovies_Yes  0.067643871
 8           DeviceProtection_Yes -0.073301197
 9                    tenure_bin4 -0.073371838
10     PaymentMethod_Mailed.check -0.080451164
# ... with 25 more rows</code></pre>
<p>The correlation visualization helps in distinguishing which features are relavant to Churn.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true"></a><span class="co"># Correlation visualization</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true"></a>corrr_analysis <span class="op">%&gt;%</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Churn, <span class="dt">y =</span> <span class="kw">fct_reorder</span>(feature, <span class="kw">desc</span>(Churn)))) <span class="op">+</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true"></a><span class="st">  </span><span class="co"># Positive Correlations - Contribute to churn</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">xend =</span> <span class="dv">0</span>, <span class="dt">yend =</span> feature), </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true"></a>               <span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">2</span>]], </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true"></a>               <span class="dt">data =</span> corrr_analysis <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Churn <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">2</span>]], </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true"></a>             <span class="dt">data =</span> corrr_analysis <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Churn <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true"></a><span class="st">  </span><span class="co"># Negative Correlations - Prevent churn</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">xend =</span> <span class="dv">0</span>, <span class="dt">yend =</span> feature), </span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true"></a>               <span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">1</span>]], </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true"></a>               <span class="dt">data =</span> corrr_analysis <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Churn <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">1</span>]], </span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true"></a>             <span class="dt">data =</span> corrr_analysis <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(Churn <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true"></a><span class="st">  </span><span class="co"># Vertical lines</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">5</span>]], <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">-0.25</span>, <span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">5</span>]], <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="fl">0.25</span>, <span class="dt">color =</span> <span class="kw">palette_light</span>()[[<span class="dv">5</span>]], <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true"></a><span class="st">  </span><span class="co"># Aesthetics</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true"></a><span class="st">  </span><span class="kw">theme_tq</span>() <span class="op">+</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Churn Correlation Analysis&quot;</span>,</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true"></a>       <span class="dt">subtitle =</span> <span class="kw">paste</span>(<span class="st">&quot;Positive Correlations (contribute to churn),&quot;</span>,</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true"></a>                        <span class="st">&quot;Negative Correlations (prevent churn)&quot;</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true"></a>       <span class="dt">y =</span> <span class="st">&quot;Feature Importance&quot;</span>)</span></code></pre></div>
</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-44-1.png" style="width:100.0%" /></p>
</div>
<p>The correlation analysis helps us quickly disseminate which features that the LIME analysis may be excluding. We can see that the following features are highly correlated (magnitude &gt; 0.25):</p>
<p><strong>Increases Likelihood of Churn (Red)</strong>: - Tenure = Bin 1 (&lt;12 Months) - Internet Service = Fiber Optic - Payment Method = Electronic Check</p>
<p><strong>Decreases Likelihood of Churn (Blue)</strong>: - Contract = Two Year - Total Charges (Note that this may be a biproduct of additional services such as Online Security)</p>
<h2 id="feature-investigation">Feature Investigation</h2>
<p>We can investigate features that are <strong>most frequent</strong> in the LIME feature importance visualization along with those that the <strong>correlation analysis shows an above normal magnitude</strong>. Well investigate:</p>
<ul>
<li>Tenure (7/10 LIME Cases, Highly Correlated)</li>
<li>Contract (Highly Correlated)</li>
<li>Internet Service (Highly Correlated)</li>
<li>Payment Method (Highly Correlated)</li>
<li>Senior Citizen (5/10 LIME Cases)</li>
<li>Online Security (4/10 LIME Cases)</li>
</ul>
<h4 id="tenure-710-lime-cases-highly-correlated">Tenure (7/10 LIME Cases, Highly Correlated)</h4>
<p>LIME cases indicate that the ANN model is using this feature frequently and high correlation agrees that this is important. Investigating the feature distribution, it appears that customers with lower tenure (bin 1) are more likely to leave. <strong>Opportunity: Target customers with less than 12 month tenure.</strong></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-45-1.png" style="width:100.0%" /></p>
</div>
<h4 id="contract-highly-correlated">Contract (Highly Correlated)</h4>
<p>While LIME did not indicate this as a primary feature in the first 10 cases, the feature is clearly correlated with those electing to stay. Customers with one and two year contracts are much less likely to churn. <strong>Opportunity: Offer promotion to switch to long term contracts.</strong></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-46-1.png" style="width:100.0%" /></p>
</div>
<h4 id="internet-service-highly-correlated">Internet Service (Highly Correlated)</h4>
<p>While LIME did not indicate this as a primary feature in the first 10 cases, the feature is clearly correlated with those electing to stay. Customers with fiber optic service are more likely to churn while those with no internet service are less likely to churn. <strong>Improvement Area: Customers may be dissatisfied with fiber optic service.</strong></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-47-1.png" style="width:100.0%" /></p>
</div>
<h4 id="payment-method-highly-correlated">Payment Method (Highly Correlated)</h4>
<p>While LIME did not indicate this as a primary feature in the first 10 cases, the feature is clearly correlated with those electing to stay. Customers with electronic check are more likely to leave. <strong>Opportunity: Offer customers a promotion to switch to automatic payments</strong>.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-48-1.png" style="width:100.0%" /></p>
</div>
<h4 id="senior-citizen-510-lime-cases">Senior Citizen (5/10 LIME Cases)</h4>
<p>Senior citizen appeared in several of the LIME cases indicating it was important to the ANN for the 10 samples. However, it was not highly correlated to Churn, which may indicate that the ANN is using in an more sophisticated manner (e.g.as an interaction). Its difficult to say that senior citizens are more likely to leave, but non-senior citizens appear less at risk of churning. <strong>Opportunity: Target users in the lower age demographic.</strong></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-49-1.png" style="width:100.0%" /></p>
</div>
<h4 id="online-security-410-lime-cases">Online Security (4/10 LIME Cases)</h4>
<p>Customers that did not sign up for online security were more likely to leave while customers with no internet service or online security were less likely to leave. <strong>Opportunity: Promote online security and other packages that increase retention rates.</strong></p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="l-body-outset">
<p><img src="images/figure-html/unnamed-chunk-50-1.png" style="width:100.0%" /></p>
</div>
<h2 id="next-steps-business-science-university">Next Steps: Business Science University</h2>
<p>Weve just scratched the surface with the solution to this problem, but unfortunately theres only so much ground we can cover in an article. Here are a few next steps that Im pleased to announce will be covered in a <a href="https://university.business-science.io/"><strong>Business Science University</strong></a> course coming in 2018!</p>
<h3 id="customer-lifetime-value">Customer Lifetime Value</h3>
<p><strong>Your organization needs to see the financial benefit so always tie your analysis to sales, profitability or ROI.</strong> <a href="https://en.wikipedia.org/wiki/Customer_lifetime_value">Customer Lifetime Value (<em>CLV</em>)</a> is a methodology that ties the business profitability to the retention rate. While we did not implement the CLV methodology herein, a full customer churn analysis would tie the churn to an classification cutoff (threshold) optimization to maximize the CLV with the predictive ANN model.</p>
<p>The simplified CLV model is:</p>
<p><span class="math display">\[ 
CLV=GC*\frac{1}{1+d-r} 
\]</span></p>
<p>Where,</p>
<ul>
<li><em>GC</em> is the gross contribution per customer</li>
<li><em>d</em> is the annual discount rate</li>
<li><em>r</em> is the retention rate</li>
</ul>
<h3 id="ann-performance-evaluation-and-improvement">ANN Performance Evaluation and Improvement</h3>
<p>The ANN model we built is good, but it could be better. How we understand our model accuracy and improve on it is through the combination of two techniques:</p>
<ul>
<li><strong>K-Fold Cross-Fold Validation</strong>: Used to obtain bounds for accuracy estimates.</li>
<li><strong>Hyper Parameter Tuning</strong>: Used to improve model performance by searching for the best parameters possible.</li>
</ul>
<p>We need to implement <em>K-Fold Cross Validation</em> and <em>Hyper Parameter Tuning</em> if we want a best-in-class model.</p>
<h3 id="distributing-analytics">Distributing Analytics</h3>
<p><strong>Its critical to communicate data science insights to decision makers in the organization</strong>. Most decision makers in organizations are not data scientists, but these individuals make important decisions on a day-to-day basis. The Shiny application below includes a <strong>Customer Scorecard</strong> to monitor customer health (risk of churn).</p>
<div class="l-body-outset">
<p><a href="https://jjallaire.shinyapps.io/keras-customer-churn/"><img src="images/shiny-application.png" class="illustration" width="100%"/></a></p>
</div>
<h3 id="business-science-university">Business Science University</h3>
<p>Youre probably wondering why we are going into so much detail on next steps. We are happy to announce a new project for 2018: <a href="https://university.business-science.io/"><strong>Business Science University</strong></a>, an online school dedicated to helping data science learners.</p>
<p>Benefits to learners:</p>
<ul>
<li>Build your own <strong>online GitHub portfolio</strong> of data science projects to market your skills to future employers!</li>
<li>Learn <strong>real-world applications</strong> in People Analytics (HR), Customer Analytics, Marketing Analytics, Social Media Analytics, Text Mining and Natural Language Processing (NLP), Financial and Time Series Analytics, and more!</li>
<li>Use <strong>advanced machine learning techniques</strong> for both high accuracy modeling and explaining features that have an effect on the outcome!</li>
<li>Create <strong>ML-powered web-applications</strong> that can be distributed throughout an organization, enabling non-data scientists to benefit from algorithms in a user-friendly way!</li>
</ul>
<p><strong>Enrollment is open</strong> so please signup for special perks. Just go to <a href="https://university.business-science.io/"><strong>Business Science University</strong></a> and select enroll.</p>
<h2 id="conclusions">Conclusions</h2>
<p><strong>Customer churn is a costly problem</strong>. The good news is that <strong>machine learning can solve churn problems</strong>, making the organization more profitable in the process. In this article, we saw how <strong>Deep Learning can be used to predict customer churn</strong>. We built an ANN model using the new <a href="https://tensorflow.rstudio.com/keras/">keras</a> package that achieved <strong>82% predictive accuracy</strong> (without tuning)! We used three new machine learning packages to help with preprocessing and measuring performance: <a href="https://topepo.github.io/recipes">recipes</a>, <a href="https://topepo.github.io/rsample/">rsample</a> and <a href="https://github.com/topepo/yardstick">yardstick</a>. Finally we used <a href="https://github.com/thomasp85/lime">lime</a> to explain the Deep Learning model, which <strong>traditionally was impossible</strong>! We checked the LIME results with a <strong>Correlation Analysis</strong>, which brought to light other features to investigate. For the IBM Telco dataset, tenure, contract type, internet service type, payment menthod, senior citizen status, and online security status were useful in diagnosing customer churn. We hope you enjoyed this article!</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2018-01-11-keras-customer-churn/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Deep%20Learning%20With%20Keras%20To%20Predict%20Customer%20Churn&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-01-11-keras-customer-churn%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-01-11-keras-customer-churn%2F&amp;title=Deep%20Learning%20With%20Keras%20To%20Predict%20Customer%20Churn">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/';
  this.page.identifier = 'posts/2018-01-11-keras-customer-churn/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Dancho (2018, Jan. 11). RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{dancho2018deep,
  author = {Dancho, Matt},
  title = {RStudio AI Blog: Deep Learning With Keras To Predict Customer Churn},
  url = {https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/},
  year = {2018}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
