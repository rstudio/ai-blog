<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks</title>

<meta property="description" itemprop="description" content="In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2018-11-12"/>
<meta property="article:created" itemprop="dateCreated" content="2018-11-12"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/images/thumb.png"/>
<meta property="og:image:width" content="2046"/>
<meta property="og:image:height" content="872"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks"/>
<meta property="twitter:description" content="In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/images/thumb.png"/>
<meta property="twitter:image:width" content="2046"/>
<meta property="twitter:image:height" content="872"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2018/11/12"/>
<meta name="citation_publication_date" content="2018/11/12"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Leveraging uncertainty information from deep neural networks for disease detection;citation_publication_date=2017;citation_publisher=Cold Spring Harbor Laboratory;citation_doi=10.1101/084210;citation_author=Christian Leibig;citation_author=Vaneeda Allken;citation_author=Murat Seckin Ayhan;citation_author=Philipp Berens;citation_author=Siegfried Wahl"/>
  <meta name="citation_reference" content="citation_title=Concrete dropout;citation_publication_date=2017;citation_author=Y. Gal;citation_author=J. Hron;citation_author=A. Kendall"/>
  <meta name="citation_reference" content="citation_title=Dropout as a bayesian approximation: Representing model uncertainty in deep learning;citation_publication_date=2016;citation_author=Yarin Gal;citation_author=Zoubin Ghahramani"/>
  <meta name="citation_reference" content="citation_title=What uncertainties do we need in bayesian deep learning for computer vision?;citation_publication_date=2017;citation_publisher=Curran Associates, Inc.;citation_author=Alex Kendall;citation_author=Yarin Gal"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","bibliography","slug","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks"]},{"type":"character","attributes":{},"value":["In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["keydana2018dropoutuncertainty"]},{"type":"character","attributes":{},"value":["11-12-2018"]},{"type":"character","attributes":{},"value":["Image Recognition & Image Processing","Probabilistic ML/DL","TensorFlow/Keras"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/thumb.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","images/1000.png","images/aleatoric_1000.png","images/epistemic_1000.png","images/overall_1000.png","images/retinopathy.png","images/scattermat.png","images/thumb.png","images/uc_4.png","images/uc_AP.png","images/uc_AT.png","images/uc_RH.png","images/uc_V.png","uncertainty_estimates_dropout_files/bowser-1.9.3/bowser.min.js","uncertainty_estimates_dropout_files/distill-2.2.21/template.v2.js","uncertainty_estimates_dropout_files/jquery-1.11.3/jquery.min.js","uncertainty_estimates_dropout_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createIndex() {
  var options = {
    keys: [
      "title",
      "categories",
      "description",
      "contents"
    ]
  };
  return new window.Fuse([],options);
}

function createFuseIndex() {

  // create fuse index
  var options = { keys: ["title", "description", "contents"] };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
            keys: [
              { name: 'title', weight: 20 },
              { name: 'categories', weight: 15 },
              { name: 'description', weight: 10 },
              { name: 'contents', weight: 5 },
            ],
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
            .filter(function(item) { return !!item.description; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description}
                </div>
                <div class="search-item-preview">
                  <img src="${suggestion.preview ? offsetURL(suggestion.preview) : ''}"</img>
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: hidden;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks","description":"In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2018-11-12T00:00:00.000+00:00","citationText":"Keydana, 2018"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks</h1>
<p><p>In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al.Â 2017) that has the network itself learn how uncertain it is.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>11-12-2018
</div>

<div class="d-article">
<p>If there were a set of survival rules for data scientists, among them would have to be this: <em>Always report uncertainty estimates with your predictions</em>. However, here we are, working with neural networks, and unlike <code>lm</code>, a Keras model does not conveniently output something like a <em>standard error</em> for the weights. We might try to think of rolling your own uncertainty measure - for example, averaging predictions from networks trained from different random weight initializations, for different numbers of epochs, or on different subsets of the data. But we might still be worried that our method is quite a bit, well â¦ <em>ad hoc</em>.</p>
<p>In this post, weâll see a both practical as well as theoretically grounded approach to obtaining uncertainty estimates from neural networks. First, however, letâs quickly talk about why uncertainty is that important - over and above its potential to save a data scientistâs job.</p>
<h2 id="why-uncertainty">Why uncertainty?</h2>
<p>In a society where automated algorithms are - and will be - entrusted with more and more life-critical tasks, one answer immediately jumps to mind: If the algorithm correctly quantifies its uncertainty, we may have human experts inspect the more uncertain predictions and potentially revise them.</p>
<p>This will only work if the networkâs self-indicated uncertainty really is indicative of a higher probability of misclassification. Leibig et al.<span class="citation" data-cites="Leibig084210">(Leibig et al. <a href="#ref-Leibig084210" role="doc-biblioref">2017</a>)</span> used a predecessor of the method described below to assess neural network uncertainty in detecting <em>diabetic retinopathy</em>. They found that indeed, the distributions of uncertainty were different depending on whether the answer was correct or not:</p>
<figure>
<img src="images/retinopathy.png" class="external" style="width:100.0%" alt="" /><figcaption>Figure from Leibig et al.Â 2017 <span class="citation" data-cites="Leibig084210">(Leibig et al. <a href="#ref-Leibig084210" role="doc-biblioref">2017</a>)</span>. Green: uncertainty estimates for wrong predictions. Blue: uncertainty estimates for correct predictions.</figcaption>
</figure>
<p>In addition to quantifying uncertainty, it can make sense to <em>qualify</em> it. In the Bayesian deep learning literature, a distinction is commonly made between <em>epistemic uncertainty</em> and <em>aleatoric uncertainty</em> <span class="citation" data-cites="NIPS2017_7141">(Kendall and Gal <a href="#ref-NIPS2017_7141" role="doc-biblioref">2017</a>)</span>. Epistemic uncertainty refers to imperfections in the model - in the limit of infinite data, this kind of uncertainty should be reducible to 0. Aleatoric uncertainty is due to data sampling and measurement processes and does not depend on the size of the dataset.</p>
<p>Say we train a model for object detection. With more data, the model should become more sure about what makes a unicycle different from a mountainbike. However, letâs assume all thatâs visible of the mountainbike is the front wheel, the fork and the head tube. Then it doesnât look so different from a unicycle any more!</p>
<p>What would be the consequences if we could distinguish both types of uncertainty? If epistemic uncertainty is high, we can try to get more training data. The remaining aleatoric uncertainty should then keep us cautioned to factor in safety margins in our application.</p>
<p>Probably no further justifications are required of why we might want to assess model uncertainty - but how can we do this?</p>
<h2 id="uncertainty-estimates-through-bayesian-deep-learning">Uncertainty estimates through Bayesian deep learning</h2>
<p>In a Bayesian world, in principle, uncertainty is for free as we donât just get point estimates (the maximum aposteriori) but the full posterior distribution. Strictly speaking, in Bayesian deep learning, priors should be put over the weights, and the posterior be determined according to Bayesâ rule. To the deep learning practitioner, this sounds pretty arduous - and how do you do it using Keras?</p>
<p>In 2016 though, Gal and Ghahramani <span class="citation" data-cites="GalG16">(Gal and Ghahramani <a href="#ref-GalG16" role="doc-biblioref">2016</a>)</span> showed that when viewing a neural network as an approximation to a Gaussian process, uncertainty estimates can be obtained in a theoretically grounded yet very practical way: by training a network with dropout and then, using dropout at test time too. At test time, dropout lets us extract Monte Carlo samples from the posterior, which can then be used to approximate the true posterior distribution.</p>
<aside>
Yarin Gal has a nice writeup of the why and how on his <a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html">blog</a>.
</aside>
<p>This is already good news, but it leaves one question open: How do we choose an appropriate dropout rate? The answer is: let the network learn it.</p>
<h2 id="learning-dropout-and-uncertainty">Learning dropout and uncertainty</h2>
<p>In several 2017 papers <span class="citation" data-cites="2017arXiv170507832G">(Gal, Hron, and Kendall <a href="#ref-2017arXiv170507832G" role="doc-biblioref">2017</a>)</span>,<span class="citation" data-cites="NIPS2017_7141">(Kendall and Gal <a href="#ref-NIPS2017_7141" role="doc-biblioref">2017</a>)</span>, Gal and his coworkers demonstrated how a network can be trained to dynamically adapt the dropout rate so it is adequate for the amount and characteristics of the data given.</p>
<p>Besides the predictive mean of the target variable, it can additionally be made to learn the variance. This means we can calculate both types of uncertainty, epistemic and aleatoric, independently, which is useful in the light of their different implications. We then add them up to obtain the overall predictive uncertainty.</p>
<p>Letâs make this concrete and see how we can implement and test the intended behavior on simulated data. In the implementation, there are three things warranting our special attention:</p>
<ul>
<li>The wrapper class used to add learnable-dropout behavior to a Keras layer;</li>
<li>The loss function designed to minimize aleatoric uncertainty; and</li>
<li>The ways we can obtain both uncertainties at test time.</li>
</ul>
<p>Letâs start with the wrapper.</p>
<h3 id="a-wrapper-for-learning-dropout">A wrapper for learning dropout</h3>
<p>In this example, weâll restrict ourselves to learning dropout for <em>dense</em> layers. Technically, weâll add a weight and a loss to every dense layer we want to use dropout with. This means weâll create a <a href="https://github.com/rstudio/keras/blob/master/vignettes/custom_wrappers.Rmd">custom wrapper</a> class that has access to the underlying layer and can modify it.</p>
<p>The logic implemented in the wrapper is derived mathematically in the <em>Concrete Dropout</em> paper <span class="citation" data-cites="2017arXiv170507832G">(Gal, Hron, and Kendall <a href="#ref-2017arXiv170507832G" role="doc-biblioref">2017</a>)</span>. The below code is a port to R of the Python Keras version found in the <a href="https://github.com/yaringal/ConcreteDropout">paperâs companion github repo</a>.</p>
<p>So first, here is the wrapper class - weâll see how to use it in just a second:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(keras)

# R6 wrapper class, a subclass of KerasWrapper
ConcreteDropout &lt;- R6::R6Class(&quot;ConcreteDropout&quot;,
  
  inherit = KerasWrapper,
  
  public = list(
    weight_regularizer = NULL,
    dropout_regularizer = NULL,
    init_min = NULL,
    init_max = NULL,
    is_mc_dropout = NULL,
    supports_masking = TRUE,
    p_logit = NULL,
    p = NULL,
    
    initialize = function(weight_regularizer,
                          dropout_regularizer,
                          init_min,
                          init_max,
                          is_mc_dropout) {
      self$weight_regularizer &lt;- weight_regularizer
      self$dropout_regularizer &lt;- dropout_regularizer
      self$is_mc_dropout &lt;- is_mc_dropout
      self$init_min &lt;- k_log(init_min) - k_log(1 - init_min)
      self$init_max &lt;- k_log(init_max) - k_log(1 - init_max)
    },
    
    build = function(input_shape) {
      super$build(input_shape)
      
      self$p_logit &lt;- super$add_weight(
        name = &quot;p_logit&quot;,
        shape = shape(1),
        initializer = initializer_random_uniform(self$init_min, self$init_max),
        trainable = TRUE
      )

      self$p &lt;- k_sigmoid(self$p_logit)

      input_dim &lt;- input_shape[[2]]

      weight &lt;- private$py_wrapper$layer$kernel
      
      kernel_regularizer &lt;- self$weight_regularizer * 
                            k_sum(k_square(weight)) / 
                            (1 - self$p)
      
      dropout_regularizer &lt;- self$p * k_log(self$p)
      dropout_regularizer &lt;- dropout_regularizer +  
                             (1 - self$p) * k_log(1 - self$p)
      dropout_regularizer &lt;- dropout_regularizer * 
                             self$dropout_regularizer * 
                             k_cast(input_dim, k_floatx())

      regularizer &lt;- k_sum(kernel_regularizer + dropout_regularizer)
      super$add_loss(regularizer)
    },
    
    concrete_dropout = function(x) {
      eps &lt;- k_cast_to_floatx(k_epsilon())
      temp &lt;- 0.1
      
      unif_noise &lt;- k_random_uniform(shape = k_shape(x))
      
      drop_prob &lt;- k_log(self$p + eps) - 
                   k_log(1 - self$p + eps) + 
                   k_log(unif_noise + eps) - 
                   k_log(1 - unif_noise + eps)
      drop_prob &lt;- k_sigmoid(drop_prob / temp)
      
      random_tensor &lt;- 1 - drop_prob
      
      retain_prob &lt;- 1 - self$p
      x &lt;- x * random_tensor
      x &lt;- x / retain_prob
      x
    },

    call = function(x, mask = NULL, training = NULL) {
      if (self$is_mc_dropout) {
        super$call(self$concrete_dropout(x))
      } else {
        k_in_train_phase(
          function()
            super$call(self$concrete_dropout(x)),
          super$call(x),
          training = training
        )
      }
    }
  )
)

# function for instantiating custom wrapper
layer_concrete_dropout &lt;- function(object, 
                                   layer,
                                   weight_regularizer = 1e-6,
                                   dropout_regularizer = 1e-5,
                                   init_min = 0.1,
                                   init_max = 0.1,
                                   is_mc_dropout = TRUE,
                                   name = NULL,
                                   trainable = TRUE) {
  create_wrapper(ConcreteDropout, object, list(
    layer = layer,
    weight_regularizer = weight_regularizer,
    dropout_regularizer = dropout_regularizer,
    init_min = init_min,
    init_max = init_max,
    is_mc_dropout = is_mc_dropout,
    name = name,
    trainable = trainable
  ))
}</code></pre>
</div>
<p>The wrapper instantiator has default arguments, but two of them should be adapted to the data: <code>weight_regularizer</code> and <code>dropout_regularizer</code>. Following the authorsâ recommendations, they should be set as follows.</p>
<p>First, choose a value for hyperparameter <span class="math inline">\(l\)</span>. In this view of a neural network as an approximation to a Gaussian process, <span class="math inline">\(l\)</span> is the <em>prior length-scale</em>, our a priori assumption about the frequency characteristics of the data. Here, we follow Galâs demo in setting <code>l := 1e-4</code>. Then the initial values for <code>weight_regularizer</code> and <code>dropout_regularizer</code> are derived from the length-scale and the sample size.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# sample size (training data)
n_train &lt;- 1000
# sample size (validation data)
n_val &lt;- 1000
# prior length-scale
l &lt;- 1e-4
# initial value for weight regularizer 
wd &lt;- l^2/n_train
# initial value for dropout regularizer
dd &lt;- 2/n_train</code></pre>
</div>
<p>Now letâs see how to use the wrapper in a model.</p>
<h3 id="dropout-model">Dropout model</h3>
<p>In our demonstration, weâll have a model with three hidden dense layers, each of which will have its dropout rate calculated by a dedicated wrapper.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# we use one-dimensional input data here, but this isn&#39;t a necessity
input_dim &lt;- 1
# this too could be &gt; 1 if we wanted
output_dim &lt;- 1
hidden_dim &lt;- 1024

input &lt;- layer_input(shape = input_dim)

output &lt;- input %&gt;% layer_concrete_dropout(
  layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
  weight_regularizer = wd,
  dropout_regularizer = dd
  ) %&gt;% layer_concrete_dropout(
  layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
  weight_regularizer = wd,
  dropout_regularizer = dd
  ) %&gt;% layer_concrete_dropout(
  layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
  weight_regularizer = wd,
  dropout_regularizer = dd
)</code></pre>
</div>
<p>Now, model output is interesting: We have the model yielding not just the <em>predictive (conditional) mean</em>, but also the <em>predictive variance</em> (<span class="math inline">\(\tau^{-1}\)</span> in Gaussian process parlance):</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
mean &lt;- output %&gt;% layer_concrete_dropout(
  layer = layer_dense(units = output_dim),
  weight_regularizer = wd,
  dropout_regularizer = dd
)

log_var &lt;- output %&gt;% layer_concrete_dropout(
  layer_dense(units = output_dim),
  weight_regularizer = wd,
  dropout_regularizer = dd
)

output &lt;- layer_concatenate(list(mean, log_var))

model &lt;- keras_model(input, output)</code></pre>
</div>
<p>The significant thing here is that we learn <em>different variances for different data points</em>. We thus hope to be able to account for <em>heteroscedasticity</em> (different degrees of variability) in the data.</p>
<h3 id="heteroscedastic-loss">Heteroscedastic loss</h3>
<p>Accordingly, instead of mean squared error we use a cost function that does not treat all estimates alike<span class="citation" data-cites="NIPS2017_7141">(Kendall and Gal <a href="#ref-NIPS2017_7141" role="doc-biblioref">2017</a>)</span>:</p>
<p><span class="math display">\[\frac{1}{N} \sum_i{\frac{1}{2 \hat{\sigma}^2_i} \ (\mathbf{y}_i - \mathbf{\hat{y}}_i)^2 + \frac{1}{2} log \ \hat{\sigma}^2_i}\]</span></p>
<p>In addition to the obligatory target vs.Â prediction check, this cost function contains two regularization terms:</p>
<ul>
<li>First, <span class="math inline">\(\frac{1}{2 \hat{\sigma}^2_i}\)</span> downweights the high-uncertainty predictions in the loss function. Put plainly: The model is encouraged to indicate high uncertainty when its predictions are false.</li>
<li>Second, <span class="math inline">\(\frac{1}{2} log \ \hat{\sigma}^2_i\)</span> makes sure the network does not simply indicate high uncertainty everywhere.</li>
</ul>
<p>This logic maps directly to the code (except that as usual, weâre calculating with the log of the variance, for reasons of numerical stability):</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
heteroscedastic_loss &lt;- function(y_true, y_pred) {
    mean &lt;- y_pred[, 1:output_dim]
    log_var &lt;- y_pred[, (output_dim + 1):(output_dim * 2)]
    precision &lt;- k_exp(-log_var)
    k_sum(precision * (y_true - mean) ^ 2 + log_var, axis = 2)
  }</code></pre>
</div>
<h3 id="training-on-simulated-data">Training on simulated data</h3>
<p>Now we generate some test data and train the model.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
gen_data_1d &lt;- function(n) {
  sigma &lt;- 1
  X &lt;- matrix(rnorm(n))
  w &lt;- 2
  b &lt;- 8
  Y &lt;- matrix(X %*% w + b + sigma * rnorm(n))
  list(X, Y)
}

c(X, Y) %&lt;-% gen_data_1d(n_train + n_val)

c(X_train, Y_train) %&lt;-% list(X[1:n_train], Y[1:n_train])
c(X_val, Y_val) %&lt;-% list(X[(n_train + 1):(n_train + n_val)], 
                          Y[(n_train + 1):(n_train + n_val)])

model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = heteroscedastic_loss,
  metrics = c(custom_metric(&quot;heteroscedastic_loss&quot;, heteroscedastic_loss))
)

history &lt;- model %&gt;% fit(
  X_train,
  Y_train,
  epochs = 30,
  batch_size = 10
)</code></pre>
</div>
<p>With training finished, we turn to the validation set to obtain estimates on unseen data - including those uncertainty measures this is all about!</p>
<h3 id="obtain-uncertainty-estimates-via-monte-carlo-sampling">Obtain uncertainty estimates via Monte Carlo sampling</h3>
<p>As often in a Bayesian setup, we construct the posterior (and thus, the posterior predictive) via Monte Carlo sampling. Unlike in traditional use of dropout, there is no change in behavior between training and test phases: Dropout stays âonâ.</p>
<p>So now we get an ensemble of model predictions on the validation set:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
num_MC_samples &lt;- 20

MC_samples &lt;- array(0, dim = c(num_MC_samples, n_val, 2 * output_dim))
for (k in 1:num_MC_samples) {
  MC_samples[k, , ] &lt;- (model %&gt;% predict(X_val))
}</code></pre>
</div>
<p>Remember, our model predicts the mean as well as the variance. Weâll use the former for calculating epistemic uncertainty, while aleatoric uncertainty is obtained from the latter.</p>
<p>First, we determine the predictive mean as an average of the MC samplesâ <em>mean</em> output:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# the means are in the first output column
means &lt;- MC_samples[, , 1:output_dim]  
# average over the MC samples
predictive_mean &lt;- apply(means, 2, mean) </code></pre>
</div>
<p>To calculate epistemic uncertainty, we again use the <em>mean</em> output, but this time weâre interested in the variance of the MC samples:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
epistemic_uncertainty &lt;- apply(means, 2, var) </code></pre>
</div>
<p>Then aleatoric uncertainty is the average over the MC samples of the <em>variance</em> output.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
logvar &lt;- MC_samples[, , (output_dim + 1):(output_dim * 2)]
aleatoric_uncertainty &lt;- exp(colMeans(logvar))</code></pre>
</div>
<p>Note how this procedure gives us uncertainty estimates individually for every prediction. How do they look?</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
df &lt;- data.frame(
  x = X_val,
  y_pred = predictive_mean,
  e_u_lower = predictive_mean - sqrt(epistemic_uncertainty),
  e_u_upper = predictive_mean + sqrt(epistemic_uncertainty),
  a_u_lower = predictive_mean - sqrt(aleatoric_uncertainty),
  a_u_upper = predictive_mean + sqrt(aleatoric_uncertainty),
  u_overall_lower = predictive_mean - 
                    sqrt(epistemic_uncertainty) - 
                    sqrt(aleatoric_uncertainty),
  u_overall_upper = predictive_mean + 
                    sqrt(epistemic_uncertainty) + 
                    sqrt(aleatoric_uncertainty)
)</code></pre>
</div>
<p>Here, first, is epistemic uncertainty, with shaded bands indicating one standard deviation above resp. below the predicted mean:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
ggplot(df, aes(x, y_pred)) + 
  geom_point() + 
  geom_ribbon(aes(ymin = e_u_lower, ymax = e_u_upper), alpha = 0.3)</code></pre>
</div>
<figure>
<img src="images/epistemic_1000.png" style="width:100.0%" alt="" /><figcaption>Epistemic uncertainty on the validation set, train size = 1000.</figcaption>
</figure>
<p>This is interesting. The training data (as well as the validation data) were generated from a standard normal distribution, so the model has encountered many more examples close to the mean than outside two, or even three, standard deviations. So it correctly tells us that in those more exotic regions, it feels pretty unsure about its predictions.</p>
<p>This is exactly the behavior we want: Risk in automatically applying machine learning methods arises due to unanticipated differences between the training and test (<em>real world</em>) distributions. If the model were to tell us âehm, not really seen anything like that before, donât really know what to doâ thatâd be an enormously valuable outcome.</p>
<p>So while epistemic uncertainty has the algorithm reflecting on its model of the world - potentially admitting its shortcomings - aleatoric uncertainty, by definition, is irreducible. Of course, that doesnât make it any less valuable - weâd know we <em>always</em> have to factor in a safety margin. So how does it look here?</p>
<figure>
<img src="images/aleatoric_1000.png" style="width:100.0%" alt="" /><figcaption>Aleatoric uncertainty on the validation set, train size = 1000.</figcaption>
</figure>
<p>Indeed, the extent of uncertainty does not depend on the amount of data seen at training time.</p>
<p>Finally, we add up both types to obtain the overall uncertainty when making predictions.</p>
<figure>
<img src="images/overall_1000.png" style="width:100.0%" alt="" /><figcaption>Overall predictive uncertainty on the validation set, train size = 1000.</figcaption>
</figure>
<p>Now letâs try this method on a real-world dataset.</p>
<h2 id="combined-cycle-power-plant-electrical-energy-output-estimation">Combined cycle power plant electrical energy output estimation</h2>
<p>This dataset is available from the <a href="http://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant">UCI Machine Learning Repository</a>. We explicitly chose a regression task with continuous variables exclusively, to make for a smooth transition from the simulated data.</p>
<p>In the dataset providersâ <a href="http://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant">own words</a></p>
<blockquote>
<p>The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant.</p>
</blockquote>
<blockquote>
<p>A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is collected from and has effect on the Steam Turbine, the other three of the ambient variables effect the GT performance.</p>
</blockquote>
<p>We thus have four predictors and one target variable. Weâll train five models: four single-variable regressions and one making use of all four predictors. It probably goes without saying that our goal here is to inspect uncertainty information, not to fine-tune the model.</p>
<h3 id="setup">Setup</h3>
<p>Letâs quickly inspect those five variables. Here <code>PE</code> is energy output, the target variable.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(readxl)
library(dplyr)
library(GGally)

df &lt;- read_xlsx(&quot;CCPP/Folds5x2_pp.xlsx&quot;)
ggscatmat(df)</code></pre>
</div>
<p><img src="images/scattermat.png" style="width:100.0%" /></p>
<p>We scale and divide up the data</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
df_scaled &lt;- scale(df)

X &lt;- df_scaled[, 1:4]
train_samples &lt;- sample(1:nrow(df_scaled), 0.8 * nrow(X))
X_train &lt;- X[train_samples,]
X_val &lt;- X[-train_samples,]

y &lt;- df_scaled[, 5] %&gt;% as.matrix()
y_train &lt;- y[train_samples,]
y_val &lt;- y[-train_samples,]</code></pre>
</div>
<p>and get ready for training a few models.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
n &lt;- nrow(X_train)
n_epochs &lt;- 100
batch_size &lt;- 100
output_dim &lt;- 1
num_MC_samples &lt;- 20
l &lt;- 1e-4
wd &lt;- l^2/n
dd &lt;- 2/n

get_model &lt;- function(input_dim, hidden_dim) {
  
  input &lt;- layer_input(shape = input_dim)
  output &lt;-
    input %&gt;% layer_concrete_dropout(
      layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
      weight_regularizer = wd,
      dropout_regularizer = dd
    ) %&gt;% layer_concrete_dropout(
      layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
      weight_regularizer = wd,
      dropout_regularizer = dd
    ) %&gt;% layer_concrete_dropout(
      layer = layer_dense(units = hidden_dim, activation = &quot;relu&quot;),
      weight_regularizer = wd,
      dropout_regularizer = dd
    )
  
  mean &lt;-
    output %&gt;% layer_concrete_dropout(
      layer = layer_dense(units = output_dim),
      weight_regularizer = wd,
      dropout_regularizer = dd
    )
  
  log_var &lt;-
    output %&gt;% layer_concrete_dropout(
      layer_dense(units = output_dim),
      weight_regularizer = wd,
      dropout_regularizer = dd
    )
  
  output &lt;- layer_concatenate(list(mean, log_var))
  
  model &lt;- keras_model(input, output)
  
  heteroscedastic_loss &lt;- function(y_true, y_pred) {
    mean &lt;- y_pred[, 1:output_dim]
    log_var &lt;- y_pred[, (output_dim + 1):(output_dim * 2)]
    precision &lt;- k_exp(-log_var)
    k_sum(precision * (y_true - mean) ^ 2 + log_var, axis = 2)
  }
  
  model %&gt;% compile(optimizer = &quot;adam&quot;,
                    loss = heteroscedastic_loss,
                    metrics = c(&quot;mse&quot;))
  model
}</code></pre>
</div>
<p>Weâll train each of the five models with a <code>hidden_dim</code> of 64. We then obtain 20 Monte Carlo sample from the posterior predictive distribution and calculate the uncertainties as before.</p>
<p>Here we show the code for the first predictor, âATâ. It is similar for all other cases.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model &lt;- get_model(1, 64)
hist &lt;- model %&gt;% fit(
  X_train[ ,1],
  y_train,
  validation_data = list(X_val[ , 1], y_val),
  epochs = n_epochs,
  batch_size = batch_size
)

MC_samples &lt;- array(0, dim = c(num_MC_samples, nrow(X_val), 2 * output_dim))
for (k in 1:num_MC_samples) {
  MC_samples[k, ,] &lt;- (model %&gt;% predict(X_val[ ,1]))
}

means &lt;- MC_samples[, , 1:output_dim]  
predictive_mean &lt;- apply(means, 2, mean) 
epistemic_uncertainty &lt;- apply(means, 2, var) 
logvar &lt;- MC_samples[, , (output_dim + 1):(output_dim * 2)]
aleatoric_uncertainty &lt;- exp(colMeans(logvar))

preds &lt;- data.frame(
  x1 = X_val[, 1],
  y_true = y_val,
  y_pred = predictive_mean,
  e_u_lower = predictive_mean - sqrt(epistemic_uncertainty),
  e_u_upper = predictive_mean + sqrt(epistemic_uncertainty),
  a_u_lower = predictive_mean - sqrt(aleatoric_uncertainty),
  a_u_upper = predictive_mean + sqrt(aleatoric_uncertainty),
  u_overall_lower = predictive_mean - 
                    sqrt(epistemic_uncertainty) - 
                    sqrt(aleatoric_uncertainty),
  u_overall_upper = predictive_mean + 
                    sqrt(epistemic_uncertainty) + 
                    sqrt(aleatoric_uncertainty)
)</code></pre>
</div>
<h3 id="result">Result</h3>
<p>Now letâs see the uncertainty estimates for all five models!</p>
<p>First, the single-predictor setup. Ground truth values are displayed in cyan, posterior predictive estimates are black, and the grey bands extend up resp. down by the square root of the calculated uncertainties.</p>
<p>Weâre starting with <em>ambient temperature</em>, a low-variance predictor. We are surprised how confident the model is that itâs gotten the process logic correct, but high aleatoric uncertainty makes up for this (more or less).</p>
<figure>
<img src="images/uc_AT.png" style="width:100.0%" alt="" /><figcaption>Uncertainties on the validation set using <em>ambient temperature</em> as a single predictor.</figcaption>
</figure>
<p>Now looking at the other predictors, where variance is much higher in the ground truth, it <em>does</em> get a bit difficult to feel comfortable with the modelâs confidence. Aleatoric uncertainty is high, but not high enough to capture the true variability in the data. And we certaintly would hope for higher epistemic uncertainty, especially in places where the model introduces arbitrary-looking deviations from linearity.</p>
<figure>
<img src="images/uc_V.png" style="width:100.0%" alt="" /><figcaption>Uncertainties on the validation set using <em>exhaust vacuum</em> as a single predictor.</figcaption>
</figure>
<figure>
<img src="images/uc_AP.png" style="width:100.0%" alt="" /><figcaption>Uncertainties on the validation set using <em>ambient pressure</em> as a single predictor.</figcaption>
</figure>
<figure>
<img src="images/uc_RH.png" style="width:100.0%" alt="" /><figcaption>Uncertainties on the validation set using <em>relative humidity</em> as a single predictor.</figcaption>
</figure>
<p>Now letâs see uncertainty output when we use all four predictors. We see that now, the Monte Carlo estimates vary a lot more, and accordingly, epistemic uncertainty is a lot higher. Aleatoric uncertainty, on the other hand, got a lot lower. Overall, predictive uncertainty captures the range of ground truth values pretty well.</p>
<figure>
<img src="images/uc_4.png" style="width:100.0%" alt="" /><figcaption>Uncertainties on the validation set using all 4 predictors.</figcaption>
</figure>
<h2 id="conclusion">Conclusion</h2>
<p>Weâve introduced a method to obtain theoretically grounded uncertainty estimates from neural networks. We find the approach intuitively attractive for several reasons: For one, the separation of different types of uncertainty is convincing and practically relevant. Second, uncertainty depends on the amount of data seen in the respective ranges. This is especially relevant when thinking of differences between training and test-time distributions. Third, the idea of having the network âbecome aware of its own uncertaintyâ is seductive.</p>
<p>In practice though, there are open questions as to how to apply the method. From our real-world test above, we immediately ask: Why is the model so confident<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> when the ground truth data has high variance? And, thinking experimentally: How would that vary with different data sizes (rows), dimensionality (columns), and hyperparameter settings (including neural network hyperparameters like capacity, number of epochs trained, and activation functions, but also the Gaussian process prior length-scale <span class="math inline">\(\tau\)</span>)?</p>
<p>For practical use, more experimentation with different datasets and hyperparameter settings is certainly warranted. Another direction to follow up is application to tasks in image recognition, such as semantic segmentation. Here weâd be interested in not just quantifying, but also localizing uncertainty, to see which visual aspects of a scene (occlusion, illumination, uncommon shapes) make objects hard to identify.</p>
<aside>
This would require a slightly different wrapper class but again, an R implementation could follow the <a href="https://github.com/yaringal/ConcreteDropout/blob/master/spatial-concrete-dropout-keras.ipynb">Python example in Yarin Galâs repository</a>.
</aside>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-GalG16">
<p>Gal, Yarin, and Zoubin Ghahramani. 2016. âDropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning.â In <em>Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, Ny, Usa, June 19-24, 2016</em>, 1050â9. <a href="http://jmlr.org/proceedings/papers/v48/gal16.html">http://jmlr.org/proceedings/papers/v48/gal16.html</a>.</p>
</div>
<div id="ref-2017arXiv170507832G">
<p>Gal, Y., J. Hron, and A. Kendall. 2017. âConcrete Dropout.â <em>ArXiv E-Prints</em>, May. <a href="http://arxiv.org/abs/1705.07832">http://arxiv.org/abs/1705.07832</a>.</p>
</div>
<div id="ref-NIPS2017_7141">
<p>Kendall, Alex, and Yarin Gal. 2017. âWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?â In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 5574â84. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision.pdf">http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision.pdf</a>.</p>
</div>
<div id="ref-Leibig084210">
<p>Leibig, Christian, Vaneeda Allken, Murat Seckin Ayhan, Philipp Berens, and Siegfried Wahl. 2017. âLeveraging Uncertainty Information from Deep Neural Networks for Disease Detection.â <em>bioRxiv</em>. <a href="https://doi.org/10.1101/084210">https://doi.org/10.1101/084210</a>.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>exponentiated because weâve really been working with the log of the variance<a href="#fnref1" class="footnote-back" role="doc-backlink">â©ï¸</a></p></li>
<li id="fn2" role="doc-endnote"><p>talking epistemic uncertainty<a href="#fnref2" class="footnote-back" role="doc-backlink">â©ï¸</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2018-11-12-uncertainty_estimates_dropout/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=You%20sure%3F%20A%20Bayesian%20approach%20to%20obtaining%20uncertainty%20estimates%20from%20neural%20networks&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-11-12-uncertainty_estimates_dropout%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-11-12-uncertainty_estimates_dropout%2F&amp;title=You%20sure%3F%20A%20Bayesian%20approach%20to%20obtaining%20uncertainty%20estimates%20from%20neural%20networks">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/';
  this.page.identifier = 'posts/2018-11-12-uncertainty_estimates_dropout/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    document.querySelector("a[href='#category:R']").parentNode.style.display = "None";
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerText == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2018, Nov. 12). RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydana2018dropoutuncertainty,
  author = {Keydana, Sigrid},
  title = {RStudio AI Blog: You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks},
  url = {https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/},
  year = {2018}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
