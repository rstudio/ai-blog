<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: BERT from R</title>

<meta property="description" itemprop="description" content="A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2019-09-30"/>
<meta property="article:created" itemprop="dateCreated" content="2019-09-30"/>
<meta name="article:author" content="Turgut Abdullayev"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: BERT from R"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/images/bert.png"/>
<meta property="og:image:width" content="437"/>
<meta property="og:image:height" content="367"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: BERT from R"/>
<meta property="twitter:description" content="A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/images/bert.png"/>
<meta property="twitter:image:width" content="437"/>
<meta property="twitter:image:height" content="367"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: BERT from R"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2019/09/30"/>
<meta name="citation_publication_date" content="2019/09/30"/>
<meta name="citation_author" content="Turgut Abdullayev"/>
<meta name="citation_author_institution" content="AccessBank Azerbaijan"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","categories","creative_commons","repository_url","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["BERT from R"]},{"type":"character","attributes":{},"value":["A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Turgut Abdullayev"]},{"type":"character","attributes":{},"value":["https://github.com/henry090"]},{"type":"character","attributes":{},"value":["AccessBank Azerbaijan"]},{"type":"character","attributes":{},"value":["https://www.accessbank.az/en/"]}]}]},{"type":"character","attributes":{},"value":["09-30-2019"]},{"type":"character","attributes":{},"value":["Natural Language Processing","TensorFlow/Keras"]},{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["https://github.com/henry090/BERT-from-R"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/bert.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bert_r_files/bowser-1.9.3/bowser.min.js","bert_r_files/distill-2.2.21/template.v2.js","bert_r_files/jquery-1.11.3/jquery.min.js","bert_r_files/webcomponents-2.0.0/webcomponents.js","images/bert.png","images/emb.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.7/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"BERT from R","description":"A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras.","authors":[{"author":"Turgut Abdullayev","authorURL":"https://github.com/henry090","affiliation":"AccessBank Azerbaijan","affiliationURL":"https://www.accessbank.az/en/","orcidID":""}],"publishedDate":"2019-09-30T00:00:00.000+00:00","citationText":"Abdullayev, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>BERT from R</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:Natural_Language_Processing" class="dt-tag">Natural Language Processing</a>
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras.</p></p>
</div>

<div class="d-byline">
  Turgut Abdullayev <a href="https://github.com/henry090" class="uri">https://github.com/henry090</a> (AccessBank Azerbaijan)<a href="https://www.accessbank.az/en/" class="uri">https://www.accessbank.az/en/</a>
  
<br/>09-30-2019
</div>

<div class="d-article">
<p><em>Today, were happy to feature a guest post written by Turgut Abdullayev, showing how to use BERT from R. Turgut is a data scientist at AccessBank Azerbaijan. Currently, he is pursuing a Ph.D.in economics at Baku State University, Azerbaijan.</em></p>
<p><a href="https://blogs.rstudio.com/tensorflow/posts/2019-08-29-using-tf-from-r/">In the previous post, Sigrid Keydana</a> explained the logic behind the <a href="https://rstudio.github.io/reticulate/">reticulate package</a> and how it enables interoperability between Python and R. So, this time we will build a classification model with <a href="https://github.com/google-research/bert">BERT</a>, taking into account one of the powerful capabilities of the reticulate package  calling Python from R via importing Python modules.</p>
<p>Before we start, make sure that the Python version used is 3, as Python 2 can introduce lots of difficulties while working with BERT, such as Unicode issues related to the input text.</p>
<blockquote>
<p>Note: The R implementation presupposes TF Keras while by default, keras-bert does not use it. So, adding that environment variable makes it work.</p>
</blockquote>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/Sys.setenv.html'>Sys.setenv</a></span><span class='op'>(</span>TF_KERAS<span class='op'>=</span><span class='fl'>1</span><span class='op'>)</span> 
<span class='co'># make sure we use python 3</span>
<span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/use_python.html'>use_python</a></span><span class='op'>(</span><span class='st'>'C:/Users/turgut.abdullayev/AppData/Local/Continuum/anaconda3/python.exe'</span>,
                       required<span class='op'>=</span><span class='cn'>T</span><span class='op'>)</span>
<span class='co'># to see python version</span>
<span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/py_config.html'>py_config</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>python<span class="op">:</span><span class="st">         </span>C<span class="op">:</span><span class="er">/</span>Users<span class="op">/</span>turgut.abdullayev<span class="op">/</span>AppData<span class="op">/</span>Local<span class="op">/</span>Continuum<span class="op">/</span>anaconda3<span class="op">/</span>python.exe</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>libpython<span class="op">:</span><span class="st">      </span>C<span class="op">:</span><span class="er">/</span>Users<span class="op">/</span>turgut.abdullayev<span class="op">/</span>AppData<span class="op">/</span>Local<span class="op">/</span>Continuum<span class="op">/</span>anaconda3<span class="op">/</span>python37.dll</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>pythonhome<span class="op">:</span><span class="st">     </span>C<span class="op">:</span>\Users\TURGUT<span class="op">~</span><span class="fl">1.</span>ABD\AppData\Local\CONTIN<span class="op">~</span><span class="dv">1</span>\ANACON<span class="op">~</span><span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>version<span class="op">:</span><span class="st">        </span><span class="dv">3</span>.<span class="fl">7.3</span> (default, Mar <span class="dv">27</span> <span class="dv">2019</span>, <span class="dv">17</span><span class="op">:</span><span class="dv">13</span><span class="op">:</span><span class="dv">21</span>) [MSC v<span class="fl">.1915</span> <span class="dv">64</span> <span class="kw">bit</span> (AMD64)]</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>Architecture<span class="op">:</span><span class="st">   </span>64bit</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>numpy<span class="op">:</span><span class="st">          </span>C<span class="op">:</span>\Users\TURGUT<span class="op">~</span><span class="fl">1.</span>ABD\AppData\Local\CONTIN<span class="op">~</span><span class="dv">1</span>\ANACON<span class="op">~</span><span class="dv">1</span>\lib\site<span class="op">-</span>packages\numpy</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>numpy_version<span class="op">:</span><span class="st">  </span><span class="dv">1</span>.<span class="fl">16.4</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>NOTE<span class="op">:</span><span class="st"> </span>Python version was forced by use_python <span class="cf">function</span></span></code></pre></div>
</div>
<p>Luckily for us, a convenient way of importing BERT with Keras was created by Zhao HG. It is called <a href="https://github.com/CyberZHG/keras-bert">Keras-bert</a>. For us, this means that importing that same python library with <code>reticulate</code> will allow us to build a popular state-of-the-art model within R.</p>
<p>There are several methods to install keras-bert in Python.</p>
<ul>
<li>in Jupyter Notebook, run:</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="op">!</span>pip install keras<span class="op">-</span>bert</span></code></pre></div>
</div>
<ul>
<li>in Terminal (Linux, Mac OS), run:</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a>python3 <span class="op">-</span>m pip install keras<span class="op">-</span>bert</span></code></pre></div>
</div>
<ul>
<li>in Anaconda prompt (Windows), run:</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>conda install keras<span class="op">-</span>bert</span></code></pre></div>
</div>
<p>After this procedure, you can check whether keras-bert is installed or not.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/py_module_available.html'>py_module_available</a></span><span class='op'>(</span><span class='st'>'keras_bert'</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>[<span class="dv">1</span>] <span class="ot">TRUE</span></span></code></pre></div>
</div>
<p>Finally, the TensorFlow version used should be 1.14/1.15. You can check it in the following form:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>tensorflow</span><span class='fu'>::</span><span class='fu'>tf_version</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>[<span class="dv">1</span>] <span class="fl">1.14</span></span></code></pre></div>
</div>
<p>In a nutshell:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a>pip install keras<span class="op">-</span>bert</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a>tensorflow<span class="op">::</span><span class="kw">install_tensorflow</span>(<span class="dt">version =</span> <span class="st">&quot;1.15&quot;</span>)</span></code></pre></div>
</div>
<h2 id="what-is-bert">What is BERT?</h2>
<p>BERT<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> is a pre-trained deep learning model introduced by Google AI Research which has been trained on Wikipedia and BooksCorpus. It has a unique way to understand the structure of a given text. Instead of reading the text from left to right or from right to left, BERT, using an attention mechanism which is called Transformer encoder<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, reads the entire word sequences at once. So, it allows to understanding a word based on its surroundings. There are different kind of pre-trained BERT models but the main difference between them is trained parameters. In our case, <a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip">BERT</a> with 12 encoder layers (Transformer Blocks), 768-hidden hidden units, 12-heads<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, and 110M parameters will be used to create a text classification model.</p>
<h2 id="model-structure">Model structure</h2>
<p>Loading a pre-trained BERT model is straightforward. The <a href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip">downloaded zip file</a> contains:</p>
<ul>
<li><em>bert_model.ckpt</em>, which is for loading the weights from the TensorFlow checkpoint</li>
<li><em>bert_config.json</em>, which is a configuration file</li>
<li><em>vocab.txt</em>, which is for text tokenization</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>pretrained_path</span> <span class='op'>=</span> <span class='st'>'/Users/turgutabdullayev/Downloads/uncased_L-12_H-768_A-12'</span>
<span class='va'>config_path</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>pretrained_path</span>, <span class='st'>'bert_config.json'</span><span class='op'>)</span>
<span class='va'>checkpoint_path</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>pretrained_path</span>, <span class='st'>'bert_model.ckpt'</span><span class='op'>)</span>
<span class='va'>vocab_path</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>pretrained_path</span>, <span class='st'>'vocab.txt'</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="import-keras-bert-module-via-reticulate">Import Keras-Bert module via reticulate</h2>
<p>Lets load keras-bert via <code>reticulate</code> and prepare a tokenizer object. The BERT tokenizer will help us to turn words into indices.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/reticulate'>reticulate</a></span><span class='op'>)</span>
<span class='va'>k_bert</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/import.html'>import</a></span><span class='op'>(</span><span class='st'>'keras_bert'</span><span class='op'>)</span>
<span class='va'>token_dict</span> <span class='op'>=</span> <span class='va'>k_bert</span><span class='op'>$</span><span class='fu'>load_vocabulary</span><span class='op'>(</span><span class='va'>vocab_path</span><span class='op'>)</span>
<span class='va'>tokenizer</span> <span class='op'>=</span> <span class='va'>k_bert</span><span class='op'>$</span><span class='fu'>Tokenizer</span><span class='op'>(</span><span class='va'>token_dict</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h3 id="how-does-the-tokenizer-work">How does the tokenizer work?</h3>
<p>BERT uses a WordPiece tokenization strategy. If a word is Out-of-vocabulary (OOV), then BERT will break it down into subwords. (eating =&gt; eat, ##ing).</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<img src="images/emb.png" alt="[BERT input representation. The input embeddings are the sum of the token embeddings, the segmentation embeddings, and the position embeddings](https://arxiv.org/pdf/1810.04805.pdf)" width="549" />
<p class="caption">
Figure 1: <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT input representation. The input embeddings are the sum of the token embeddings, the segmentation embeddings, and the position embeddings</a>
</p>
</div>
</div>
<h2 id="embedding-layers-in-bert">Embedding Layers in BERT</h2>
<p>There are 3 types of embedding layers in BERT:</p>
<ul>
<li><strong>Token Embeddings</strong> help to transform words into vector representations. In our model dimension size is 768.</li>
<li><strong>Segment Embeddings</strong> help to understand the semantic similarity of different pieces of the text.</li>
<li><strong>Position Embeddings</strong> mean that identical words at different positions will not have the same output representation.</li>
</ul>
<h2 id="define-model-parameters-and-column-names">Define model parameters and column names</h2>
<p>As usual with keras, the batch size, number of epochs and the learning rate should be defined for training BERT. Additionally, the <em>sequence length</em> is needed.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>seq_length</span> <span class='op'>=</span> <span class='fl'>50L</span>
<span class='va'>bch_size</span> <span class='op'>=</span> <span class='fl'>70</span>
<span class='va'>epochs</span> <span class='op'>=</span> <span class='fl'>1</span>
<span class='va'>learning_rate</span> <span class='op'>=</span> <span class='fl'>1e-4</span>

<span class='va'>DATA_COLUMN</span> <span class='op'>=</span> <span class='st'>'comment_text'</span>
<span class='va'>LABEL_COLUMN</span> <span class='op'>=</span> <span class='st'>'target'</span>
</code></pre>
</div>
</div>
<blockquote>
<p>Note: the max input length is 512, and the model is extremely compute intensive even on GPU.</p>
</blockquote>
<h2 id="load-bert-model-into-r">Load BERT model into R</h2>
<p>We can load the BERT model and automatically pad sequences with <code>seq_len</code> function. Keras-bert<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> makes the loading process very easy and comfortable.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model</span> <span class='op'>=</span> <span class='va'>k_bert</span><span class='op'>$</span><span class='fu'>load_trained_model_from_checkpoint</span><span class='op'>(</span>
  <span class='va'>config_path</span>,
  <span class='va'>checkpoint_path</span>,
  training<span class='op'>=</span><span class='cn'>T</span>,
  trainable<span class='op'>=</span><span class='cn'>T</span>,
  seq_len<span class='op'>=</span><span class='va'>seq_length</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="data-structure-reading-preparation">Data structure, reading, preparation</h2>
<p>The dataset for this post is taken from the <a href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification">Kaggle Jigsaw Unintended Bias in Toxicity Classification competition</a>.</p>
<p>In order to prepare the dataset, we write a preprocessing function which will read and tokenize data simultaneously. Then, we feed the outputs of the function as input for BERT model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># tokenize text</span>
<span class='va'>tokenize_fun</span> <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>indices</span>, <span class='va'>target</span>, <span class='va'>segments</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='op'>)</span>,<span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='op'>)</span>,<span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  <span class='kw'>for</span> <span class='op'>(</span> <span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>indices_tok</span>, <span class='va'>segments_tok</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>tokenizer</span><span class='op'>$</span><span class='fu'>encode</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='va'>DATA_COLUMN</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span>, 
                                                       max_len<span class='op'>=</span><span class='va'>seq_length</span><span class='op'>)</span>
    <span class='va'>indices</span> <span class='op'>=</span> <span class='va'>indices</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/append.html'>append</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>indices_tok</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
    <span class='va'>target</span> <span class='op'>=</span> <span class='va'>target</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/append.html'>append</a></span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='va'>LABEL_COLUMN</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span>
    <span class='va'>segments</span> <span class='op'>=</span> <span class='va'>segments</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/append.html'>append</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>segments_tok</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>}</span>
  <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>indices</span>,<span class='va'>segments</span>, <span class='va'>target</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># read data</span>
<span class='va'>dt_data</span> <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>dir</span>, <span class='va'>rows_to_read</span><span class='op'>)</span><span class='op'>{</span>
  <span class='va'>data</span> <span class='op'>=</span> <span class='fu'>data.table</span><span class='fu'>::</span><span class='fu'><a href='https://Rdatatable.gitlab.io/data.table/reference/fread.html'>fread</a></span><span class='op'>(</span><span class='va'>dir</span>, nrows<span class='op'>=</span><span class='va'>rows_to_read</span><span class='op'>)</span>
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>x_train</span>, <span class='va'>x_segment</span>, <span class='va'>y_train</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>tokenize_fun</span><span class='op'>(</span><span class='va'>data</span><span class='op'>)</span>
  <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>x_train</span>, <span class='va'>x_segment</span>, <span class='va'>y_train</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<h2 id="load-dataset">Load dataset</h2>
<p>The way we have written the preprocess function, at first, it will read data, then add zeros and encode words into indices. Hence, we will have 3 output files:</p>
<ul>
<li><strong>x_train</strong> is input matrix for BERT</li>
<li><strong>x_segment</strong> contains zeros for segment embeddings</li>
<li><strong>y_train</strong> is the output target which we should predict</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>x_train</span>,<span class='va'>x_segment</span>, <span class='va'>y_train</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> 
<span class='fu'>dt_data</span><span class='op'>(</span><span class='st'>'~/Downloads/jigsaw-unintended-bias-in-toxicity-classification/train.csv'</span>,<span class='fl'>2000</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="matrix-format-for-keras-bert">Matrix format for Keras-Bert</h2>
<p>The input data are in list format. They need to be extracted and transposed. Then, the train and segment matrices should be placed into the list.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>train</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>cbind</span>,<span class='va'>x_train</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='va'>segments</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>cbind</span>,<span class='va'>x_segment</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='va'>targets</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>cbind</span>,<span class='va'>y_train</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>concat</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>train</span> <span class='op'>)</span>,<span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>segments</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="calculate-decay-and-warmup-steps">Calculate decay and warmup steps</h2>
<p>Using the Adam optimizer with warmup helps to lower the learning rate at the beginning of the training process. After certain training steps, the learning rate will gradually be increased, because learning new data without warmup can negatively affect a BERT model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>decay_steps</span>, <span class='va'>warmup_steps</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>k_bert</span><span class='op'>$</span><span class='fu'>calc_train_steps</span><span class='op'>(</span>
  <span class='va'>targets</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='op'>)</span>,
  batch_size<span class='op'>=</span><span class='va'>bch_size</span>,
  epochs<span class='op'>=</span><span class='va'>epochs</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="determine-inputs-and-outputs-then-concatenate-them">Determine inputs and outputs, then concatenate them</h2>
<p>In order to build a binary classification model, the output of the BERT model should contain 1 unit. Therefore, first of all, we should get input and output layers. Then, adding an additional dense layer to the output can perfectly meet our needs.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>keras</span><span class='op'>)</span>

<span class='va'>input_1</span> <span class='op'>=</span> <span class='fu'>get_layer</span><span class='op'>(</span><span class='va'>model</span>,name <span class='op'>=</span> <span class='st'>'Input-Token'</span><span class='op'>)</span><span class='op'>$</span><span class='va'>input</span>
<span class='va'>input_2</span> <span class='op'>=</span> <span class='fu'>get_layer</span><span class='op'>(</span><span class='va'>model</span>,name <span class='op'>=</span> <span class='st'>'Input-Segment'</span><span class='op'>)</span><span class='op'>$</span><span class='va'>input</span>
<span class='va'>inputs</span> <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>input_1</span>,<span class='va'>input_2</span><span class='op'>)</span>

<span class='va'>dense</span> <span class='op'>=</span> <span class='fu'>get_layer</span><span class='op'>(</span><span class='va'>model</span>,name <span class='op'>=</span> <span class='st'>'NSP-Dense'</span><span class='op'>)</span><span class='op'>$</span><span class='va'>output</span>

<span class='va'>outputs</span> <span class='op'>=</span> <span class='va'>dense</span> <span class='op'>%&gt;%</span> <span class='fu'>layer_dense</span><span class='op'>(</span>units<span class='op'>=</span><span class='fl'>1L</span>, activation<span class='op'>=</span><span class='st'>'sigmoid'</span>,
                         kernel_initializer<span class='op'>=</span><span class='fu'>initializer_truncated_normal</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.02</span><span class='op'>)</span>,
                         name <span class='op'>=</span> <span class='st'>'output'</span><span class='op'>)</span>

<span class='va'>model</span> <span class='op'>=</span> <span class='fu'>keras_model</span><span class='op'>(</span>inputs <span class='op'>=</span> <span class='va'>inputs</span>,outputs <span class='op'>=</span> <span class='va'>outputs</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>This is how the model architecture looks like after adding a dense layer and padding input sequences.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a>Model</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a><span class="kw">Layer</span> (type)                 Output Shape        Param <span class="co">#    Connected to                  </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a><span class="op">==</span><span class="er">========================================================================================</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>Input<span class="op">-</span><span class="kw">Token</span> (InputLayer)     (None, <span class="dv">50</span>)          <span class="dv">0</span>                                        </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a>Input<span class="op">-</span><span class="kw">Segment</span> (InputLayer)   (None, <span class="dv">50</span>)          <span class="dv">0</span>                                        </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a>Embedding<span class="op">-</span><span class="kw">Token</span> (TokenEmbedd [(None, <span class="dv">50</span>, <span class="dv">768</span>), ( <span class="dv">23440896</span>   Input<span class="op">-</span>Token[<span class="dv">0</span>][<span class="dv">0</span>]             </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a>Embedding<span class="op">-</span><span class="kw">Segment</span> (<span class="kw">Embedding</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Input<span class="op">-</span>Segment[<span class="dv">0</span>][<span class="dv">0</span>]           </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a>Embedding<span class="op">-</span>Token<span class="op">-</span><span class="kw">Segment</span> (<span class="kw">Add</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Embedding<span class="op">-</span>Token[<span class="dv">0</span>][<span class="dv">0</span>]         </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a>                                                            Embedding<span class="op">-</span>Segment[<span class="dv">0</span>][<span class="dv">0</span>]       </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true"></a>Embedding<span class="op">-</span><span class="kw">Position</span> (<span class="kw">Position</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">38400</span>      Embedding<span class="op">-</span>Token<span class="op">-</span>Segment[<span class="dv">0</span>][<span class="dv">0</span>] </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true"></a>Embedding<span class="op">-</span><span class="kw">Dropout</span> (Dropout)  (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Embedding<span class="op">-</span>Position[<span class="dv">0</span>][<span class="dv">0</span>]      </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true"></a>Embedding<span class="op">-</span><span class="kw">Norm</span> (<span class="kw">LayerNormali</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Embedding<span class="op">-</span>Dropout[<span class="dv">0</span>][<span class="dv">0</span>]       </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Embedding<span class="op">-</span>Norm[<span class="dv">0</span>][<span class="dv">0</span>]          </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-1</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Embedding<span class="op">-</span>Norm[<span class="dv">0</span>][<span class="dv">0</span>]          </span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true"></a>                                                            Encoder<span class="dv">-1</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-1</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-1</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-1</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true"></a>                                                            Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true"></a>Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-2</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-1</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true"></a>                                                            Encoder<span class="dv">-2</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-2</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-2</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-2</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true"></a>                                                            Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true"></a>Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-3</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-2</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true"></a>                                                            Encoder<span class="dv">-3</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-3</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-3</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-3</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true"></a>                                                            Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true"></a>Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-4</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-3</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true"></a>                                                            Encoder<span class="dv">-4</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-4</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-4</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-4</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true"></a>                                                            Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true"></a>Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-5</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-4</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true"></a>                                                            Encoder<span class="dv">-5</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-5</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-5</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-5</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true"></a>                                                            Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true"></a>Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-6</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-5</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true"></a>                                                            Encoder<span class="dv">-6</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-6</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-6</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-6</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true"></a>                                                            Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true"></a>Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-7</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-6</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true"></a>                                                            Encoder<span class="dv">-7</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-7</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-7</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-7</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true"></a>                                                            Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true"></a>Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-8</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-7</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true"></a>                                                            Encoder<span class="dv">-8</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-8</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-8</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-8</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true"></a>                                                            Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true"></a>Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-9</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-8</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true"></a>                                                            Encoder<span class="dv">-9</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span><span class="kw">MultiHeadSelfAtten</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-9</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">FeedF</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-9</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-176"><a href="#cb8-176" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-177"><a href="#cb8-177" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropou</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]   </span>
<span id="cb8-178"><a href="#cb8-178" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-179"><a href="#cb8-179" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> (<span class="kw">A</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-9</span><span class="op">-</span>MultiHeadSelfAttenti</span>
<span id="cb8-180"><a href="#cb8-180" aria-hidden="true"></a>                                                            Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout[</span>
<span id="cb8-181"><a href="#cb8-181" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-182"><a href="#cb8-182" aria-hidden="true"></a>Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][<span class="dv">0</span></span>
<span id="cb8-183"><a href="#cb8-183" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-184"><a href="#cb8-184" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-185"><a href="#cb8-185" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-186"><a href="#cb8-186" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-10</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-187"><a href="#cb8-187" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-188"><a href="#cb8-188" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-9</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>][</span>
<span id="cb8-189"><a href="#cb8-189" aria-hidden="true"></a>                                                            Encoder<span class="dv">-10</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-190"><a href="#cb8-190" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-191"><a href="#cb8-191" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-10</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-192"><a href="#cb8-192" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-193"><a href="#cb8-193" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">Feed</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-10</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-194"><a href="#cb8-194" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-195"><a href="#cb8-195" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropo</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]  </span>
<span id="cb8-196"><a href="#cb8-196" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-197"><a href="#cb8-197" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-10</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-198"><a href="#cb8-198" aria-hidden="true"></a>                                                            Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout</span>
<span id="cb8-199"><a href="#cb8-199" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-200"><a href="#cb8-200" aria-hidden="true"></a>Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span>  (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][</span>
<span id="cb8-201"><a href="#cb8-201" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-202"><a href="#cb8-202" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>]</span>
<span id="cb8-203"><a href="#cb8-203" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-204"><a href="#cb8-204" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-11</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-205"><a href="#cb8-205" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-206"><a href="#cb8-206" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-10</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>]</span>
<span id="cb8-207"><a href="#cb8-207" aria-hidden="true"></a>                                                            Encoder<span class="dv">-11</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-208"><a href="#cb8-208" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-209"><a href="#cb8-209" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-11</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-210"><a href="#cb8-210" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-211"><a href="#cb8-211" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">Feed</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-11</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-212"><a href="#cb8-212" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-213"><a href="#cb8-213" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropo</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]  </span>
<span id="cb8-214"><a href="#cb8-214" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-215"><a href="#cb8-215" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-11</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-216"><a href="#cb8-216" aria-hidden="true"></a>                                                            Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout</span>
<span id="cb8-217"><a href="#cb8-217" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-218"><a href="#cb8-218" aria-hidden="true"></a>Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span>  (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][</span>
<span id="cb8-219"><a href="#cb8-219" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-220"><a href="#cb8-220" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">2362368</span>    Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>]</span>
<span id="cb8-221"><a href="#cb8-221" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-222"><a href="#cb8-222" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-12</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-223"><a href="#cb8-223" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-224"><a href="#cb8-224" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-11</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>]</span>
<span id="cb8-225"><a href="#cb8-225" aria-hidden="true"></a>                                                            Encoder<span class="dv">-12</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-226"><a href="#cb8-226" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-227"><a href="#cb8-227" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span><span class="kw">MultiHeadSelfAtte</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-12</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-228"><a href="#cb8-228" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-229"><a href="#cb8-229" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span><span class="kw">FeedForward</span> (<span class="kw">Feed</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">4722432</span>    Encoder<span class="dv">-12</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-230"><a href="#cb8-230" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-231"><a href="#cb8-231" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Dropo</span> (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward[<span class="dv">0</span>][<span class="dv">0</span>]  </span>
<span id="cb8-232"><a href="#cb8-232" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-233"><a href="#cb8-233" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Add</span> ( (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">0</span>          Encoder<span class="dv">-12</span><span class="op">-</span>MultiHeadSelfAttent</span>
<span id="cb8-234"><a href="#cb8-234" aria-hidden="true"></a>                                                            Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span>Dropout</span>
<span id="cb8-235"><a href="#cb8-235" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-236"><a href="#cb8-236" aria-hidden="true"></a>Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span><span class="kw">Norm</span>  (None, <span class="dv">50</span>, <span class="dv">768</span>)     <span class="dv">1536</span>       Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span>Add[<span class="dv">0</span>][</span>
<span id="cb8-237"><a href="#cb8-237" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-238"><a href="#cb8-238" aria-hidden="true"></a><span class="kw">Extract</span> (Extract)            (None, <span class="dv">768</span>)         <span class="dv">0</span>          Encoder<span class="dv">-12</span><span class="op">-</span>FeedForward<span class="op">-</span>Norm[<span class="dv">0</span>]</span>
<span id="cb8-239"><a href="#cb8-239" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-240"><a href="#cb8-240" aria-hidden="true"></a>NSP<span class="op">-</span><span class="kw">Dense</span> (Dense)            (None, <span class="dv">768</span>)         <span class="dv">590592</span>     Extract[<span class="dv">0</span>][<span class="dv">0</span>]                 </span>
<span id="cb8-241"><a href="#cb8-241" aria-hidden="true"></a>__________________________________________________________________________________________</span>
<span id="cb8-242"><a href="#cb8-242" aria-hidden="true"></a><span class="kw">output</span> (Dense)               (None, <span class="dv">1</span>)           <span class="dv">769</span>        NSP<span class="op">-</span>Dense[<span class="dv">0</span>][<span class="dv">0</span>]               </span>
<span id="cb8-243"><a href="#cb8-243" aria-hidden="true"></a><span class="op">==</span><span class="er">========================================================================================</span></span>
<span id="cb8-244"><a href="#cb8-244" aria-hidden="true"></a>Total params<span class="op">:</span><span class="st"> </span><span class="dv">109</span>,<span class="dv">128</span>,<span class="dv">193</span></span>
<span id="cb8-245"><a href="#cb8-245" aria-hidden="true"></a>Trainable params<span class="op">:</span><span class="st"> </span><span class="dv">109</span>,<span class="dv">128</span>,<span class="dv">193</span></span>
<span id="cb8-246"><a href="#cb8-246" aria-hidden="true"></a>Non<span class="op">-</span>trainable params<span class="op">:</span><span class="st"> </span><span class="dv">0</span></span>
<span id="cb8-247"><a href="#cb8-247" aria-hidden="true"></a>__________________________________________________________________________________________</span></code></pre></div>
</div>
<h2 id="compile-model-and-begin-training">Compile model and begin training</h2>
<p>Aus usual with Keras, before training a model, we need to compile the model. And using <code>fit()</code>, we feed it the R arrays.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>model</span> <span class='op'>%&gt;%</span> <span class='fu'>compile</span><span class='op'>(</span>
  <span class='va'>k_bert</span><span class='op'>$</span><span class='fu'>AdamWarmup</span><span class='op'>(</span>decay_steps<span class='op'>=</span><span class='va'>decay_steps</span>, 
                    warmup_steps<span class='op'>=</span><span class='va'>warmup_steps</span>, lr<span class='op'>=</span><span class='va'>learning_rate</span><span class='op'>)</span>,
  loss <span class='op'>=</span> <span class='st'>'binary_crossentropy'</span>,
  metrics <span class='op'>=</span> <span class='st'>'accuracy'</span>
<span class='op'>)</span>

<span class='va'>model</span> <span class='op'>%&gt;%</span> <span class='fu'>fit</span><span class='op'>(</span>
  <span class='va'>concat</span>,
  <span class='va'>targets</span>,
  epochs<span class='op'>=</span><span class='va'>epochs</span>,
  batch_size<span class='op'>=</span><span class='va'>bch_size</span>, validation_split<span class='op'>=</span><span class='fl'>0.2</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>In this post, weve shown how we can use Keras to conveniently load, configure, and train a BERT model.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://arxiv.org/pdf/1810.04805.pdf">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><a href="#fnref1" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a><a href="#fnref2" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn3" role="doc-endnote"><p>Attention  focuses on salient parts of input by taking a weighted average of them. 768 hidden units divided by 12 chunks and each chunk will have 64 output dimensions, afterward, the result from each chunk will be concatenated and forwarded to the next layer<a href="#fnref3" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn4" role="doc-endnote"><p><a href="https://github.com/CyberZHG/keras-bert">Implementation of the BERT. Official pre-trained models could be loaded for feature extraction and prediction</a><a href="#fnref4" class="footnote-back" role="doc-backlink"></a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2019-09-30-bert-r/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=BERT%20from%20R&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2019-09-30-bert-r%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2019-09-30-bert-r%2F&amp;title=BERT%20from%20R">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/';
  this.page.identifier = 'posts/2019-09-30-bert-r/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="updates-and-corrections">Corrections</h3>
  <p>If you see mistakes or want to suggest changes, please <a href="https://github.com/henry090/BERT-from-R/issues/new">create an issue</a> on the source repository.</p>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. Source code is available at <a href="https://github.com/henry090/BERT-from-R">https://github.com/henry090/BERT-from-R</a>, unless otherwise noted. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Abdullayev (2019, Sept. 30). RStudio AI Blog: BERT from R. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{abdullayev2019bert,
  author = {Abdullayev, Turgut},
  title = {RStudio AI Blog: BERT from R},
  url = {https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/},
  year = {2019}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
