<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?</title>

<meta property="description" itemprop="description" content="TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2019-10-08"/>
<meta property="article:created" itemprop="dateCreated" content="2019-10-08"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/images/thumb.png"/>
<meta property="og:image:width" content="400"/>
<meta property="og:image:height" content="400"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?"/>
<meta property="twitter:description" content="TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/images/thumb.png"/>
<meta property="twitter:image:width" content="400"/>
<meta property="twitter:image:height" content="400"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2019/10/08"/>
<meta name="citation_publication_date" content="2019/10/08"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["TensorFlow 2.0 is here - what changes for R users?"]},{"type":"character","attributes":{},"value":["TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydana2019tf2"]},{"type":"character","attributes":{},"value":["10-08-2019"]},{"type":"character","attributes":{},"value":["TensorFlow/Keras","Packages/Releases"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/thumb.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["images/thumb.png","tf2_files/bowser-1.9.3/bowser.min.js","tf2_files/distill-2.2.21/template.v2.js","tf2_files/jquery-1.11.3/jquery.min.js","tf2_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.6/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"TensorFlow 2.0 is here - what changes for R users?","description":"TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2019-10-08T00:00:00.000+00:00","citationText":"Keydana, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>TensorFlow 2.0 is here - what changes for R users?</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
  <a href="../../index.html#category:Packages/Releases" class="dt-tag">Packages/Releases</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>10-08-2019
</div>

<div class="d-article">
<p>The wait is over  TensorFlow 2.0 (TF 2) is now officially here! What does this mean for us, users of R packages <code>keras</code> and/or <code>tensorflow</code>, which, as we know, <a href="https://blogs.rstudio.com/tensorflow/posts/2019-08-29-using-tf-from-r/">rely on the Python TensorFlow backend</a>?</p>
<p>Before we go into details and explanations, here is an <em>all-clear</em>, for the concerned user who fears their <code>keras</code> code might become obsolete (it wont).</p>
<h2 id="dont-panic">Dont panic</h2>
<ul>
<li>If you are using <code>keras</code> in standard ways, such as those depicted in most code examples and tutorials seen on the web, and things have been working fine for you in recent <code>keras</code> releases (&gt;= 2.2.4.1), dont worry. Most everything should work without major changes.</li>
<li>If you are using an older release of <code>keras</code> (&lt; 2.2.4.1), syntactically things should work fine as well, but you will want to check for changes in behavior/performance.</li>
</ul>
<p>And now for some news and background. This post aims to do three things:</p>
<ul>
<li>Explain the above <em>all-clear</em> statement. Is it really that simple  what exactly is going on?</li>
<li>Characterize the changes brought about by TF 2, from the <em>point of view of the R user</em>.</li>
<li>And, perhaps most interestingly: Take a look at what is going on, in the <code>r-tensorflow</code> ecosystem, around new functionality related to the advent of TF 2.</li>
</ul>
<h2 id="some-background">Some background</h2>
<p>So if all still works fine (assuming standard usage), why so much ado about TF 2 in Python land?</p>
<p>The difference is that on the R side, for the vast majority of users, the framework you used to do deep learning was <code>keras</code>. <code>tensorflow</code> was needed just occasionally, or not at all.</p>
<p>Between <code>keras</code> and <code>tensorflow</code>, there was a clear separation of responsibilities: <code>keras</code> was the frontend, depending on TensorFlow as a low-level backend, just like the <a href="http://keras.io">original Python Keras</a> it was wrapping did. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. In some cases, this lead to people using the words <code>keras</code> and <code>tensorflow</code> almost synonymously: Maybe they said <code>tensorflow</code>, but the code they wrote was <code>keras</code>.</p>
<p>Things were different in Python land. There was original Python Keras, but TensorFlow had its own <code>layers</code> API, and there were a number of third-party high-level APIs built on TensorFlow. Keras, in contrast, was a separate library that just happened to rely on TensorFlow.</p>
<p>So in Python land, now we have a big change: <em>With TF 2, Keras (as incorporated in the TensorFlow codebase) is now the official high-level API for TensorFlow</em>. To bring this across has been a major point of Googles TF 2 information campaign since the early stages.</p>
<p>As R users, who have been focusing on <code>keras</code> all the time, we are essentially less affected. Like we said above, syntactically most everything stays the way it was. So why differentiate between different <code>keras</code> versions?</p>
<p>When <code>keras</code> was written, there was original Python Keras, and that was the library we were binding to. However, Google started to incorporate original Keras code into their TensorFlow codebase as a fork, to continue development independently. For a while there were two Kerases: Original Keras and <code>tf.keras</code>. Our R <code>keras</code> offered to switch between implementations <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, the default being original Keras.</p>
<p>In <code>keras</code> release 2.2.4.1, anticipating discontinuation of original Keras and wanting to get ready for TF 2, we switched to using <code>tf.keras</code> as the default. While in the beginning, the <code>tf.keras</code> fork and original Keras developed more or less in sync, the latest developments for TF 2 brought with them bigger changes in the <code>tf.keras</code> codebase, especially as regards optimizers. This is why, if you are using a <code>keras</code> version &lt; 2.2.4.1, upgrading to TF 2 you will want to check for changes in behavior and/or performance. <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>Thats it for some background. In sum, were happy most existing code will run just fine. But for us R users, <em>something</em> must be changing as well, right?</p>
<h2 id="tf-2-in-a-nutshell-from-an-r-perspective">TF 2 in a nutshell, from an R perspective</h2>
<p>In fact, the most evident-on-user-level change is something we wrote several posts about, more than a year ago <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. By then, <em>eager execution</em> was a brand-new option that had to be turned on explicitly; TF 2 now makes it the default. Along with it came <em>custom models</em> (a.k.a. subclassed models, in Python land) and <em>custom training</em>, making use of <code>tf$GradientTape</code>. Lets talk about what those termini refer to, and how they are relevant to R users.</p>
<h3 id="eager-execution">Eager Execution</h3>
<p>In TF 1, it was all about the <em>graph</em> you built when defining your model. The graph, that was  and is  an <em>Abstract Syntax Tree</em> (AST), with operations as nodes and <em>tensors flowing</em> along the edges. Defining a graph and running it (on actual data) were different steps.</p>
<p>In contrast, with eager execution, operations are run directly when defined.</p>
<p>While this is a more-than-substantial change that must have required lots of resources to implement, if you use <code>keras</code> you wont notice. Just as previously, the typical <code>keras</code> workflow of <code>create model</code> -&gt; <code>compile model</code> -&gt; <code>train model</code> never made you think about there being two distinct phases (define and run), now again you dont have to do anything. Even though the overall execution mode is eager, Keras models are trained in graph mode, to maximize performance. We will talk about how this is done in part 3 when introducing the <code>tfautograph</code> package.</p>
<p>If <code>keras</code> runs in graph mode, how can you even see that eager execution is on? Well, in TF 1, when you ran a TensorFlow operation on a tensor <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, like so</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tensorflow</span><span class='op'>)</span>
<span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>cumprod</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>5</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>this is what you saw:</p>
<pre><code>Tensor(&quot;Cumprod:0&quot;, shape=(5,), dtype=int32)</code></pre>
<p>To extract the actual values, you had to create a TensorFlow <em>Session</em> and <code>run</code> the tensor, or alternatively, use <code>keras::k_eval</code> that did this under the hood:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>keras</span><span class='op'>)</span>
<span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>cumprod</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>k_eval</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>[1]   1   2   6  24 120</code></pre>
<p>With TF 2s execution mode defaulting to <em>eager</em>, we now automatically see the values contained in the tensor: <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>cumprod</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>5</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code>tf.Tensor([  1   2   6  24 120], shape=(5,), dtype=int32)</code></pre>
<p>So thats eager execution. In our last years <em>Eager</em>-category blog posts, it was always accompanied by <a href="https://tensorflow.rstudio.com/keras/articles/custom_models.html">custom models</a>, so lets turn there next.</p>
<h3 id="custom-models">Custom models</h3>
<p>As a <code>keras</code> user, probably youre familiar with the <em>sequential</em> and <em>functional</em> styles of building a model. Custom models allow for even greater flexibility than functional-style ones. Check out the <a href="https://tensorflow.rstudio.com/keras/articles/custom_models.html">documentation</a> for how to create one.</p>
<p>Last years series on eager execution has plenty of examples using custom models, featuring not just their flexibility, but another important aspect as well: the way they allow for modular, easily-intelligible code. <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Encoder-decoder scenarios are a natural match. If you have seen, or written, old-style code for a Generative Adversarial Network (GAN), imagine something like this instead:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co"># define the generator (simplified)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>generator &lt;-</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a><span class="st">  </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>    <span class="kw">keras_model_custom</span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a>      </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>      <span class="co"># define layers for the generator </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>      self<span class="op">$</span>fc1 &lt;-<span class="st"> </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">7</span> <span class="op">*</span><span class="st"> </span><span class="dv">7</span> <span class="op">*</span><span class="st"> </span><span class="dv">64</span>, <span class="dt">use_bias =</span> <span class="ot">FALSE</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a>      self<span class="op">$</span>batchnorm1 &lt;-<span class="st"> </span><span class="kw">layer_batch_normalization</span>()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a>      <span class="co"># more layers ...</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a>      </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a>      <span class="co"># define what should happen in the forward pass</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a>      <span class="cf">function</span>(inputs, <span class="dt">mask =</span> <span class="ot">NULL</span>, <span class="dt">training =</span> <span class="ot">TRUE</span>) {</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a>        self<span class="op">$</span><span class="kw">fc1</span>(inputs) <span class="op">%&gt;%</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a><span class="st">          </span>self<span class="op">$</span><span class="kw">batchnorm1</span>(<span class="dt">training =</span> training) <span class="op">%&gt;%</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a><span class="st">          </span><span class="co"># call remaining layers ...</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a><span class="st">      </span>}</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a>    })</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a>  }</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a><span class="co"># define the discriminator</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true"></a>discriminator &lt;-</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true"></a><span class="st">  </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true"></a>    <span class="kw">keras_model_custom</span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true"></a>      </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true"></a>      self<span class="op">$</span>conv1 &lt;-<span class="st"> </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="co">#...)</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true"></a>      self<span class="op">$</span>leaky_relu1 &lt;-<span class="st"> </span><span class="kw">layer_activation_leaky_relu</span>()</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true"></a>      <span class="co"># more layers ...</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true"></a>    </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true"></a>      <span class="cf">function</span>(inputs, <span class="dt">mask =</span> <span class="ot">NULL</span>, <span class="dt">training =</span> <span class="ot">TRUE</span>) {</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true"></a>        inputs <span class="op">%&gt;%</span><span class="st"> </span>self<span class="op">$</span><span class="kw">conv1</span>() <span class="op">%&gt;%</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true"></a><span class="st">          </span>self<span class="op">$</span><span class="kw">leaky_relu1</span>() <span class="op">%&gt;%</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true"></a><span class="st">          </span><span class="co"># call remaining layers ...</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true"></a><span class="st">      </span>}</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true"></a>    <span class="er">}</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true"></a>  }</span></code></pre></div>
</div>
<p>Coded like this, picture the generator and the discriminator as agents, ready to engage in what is actually the opposite of a zero-sum game.</p>
<p>The game, then, can be nicely coded using <em>custom training</em>.</p>
<h3 id="custom-training">Custom training</h3>
<p>Custom training, as opposed to using <code>keras</code> <code>fit</code>, allows to interleave the training of several models. Models are <em>called</em> on data, and all calls have to happen inside the context of a <code>GradientTape</code>. In eager mode, <code>GradientTape</code>s are used to keep track of operations such that during backprop, their gradients can be calculated.</p>
<p>The following code example shows how using <code>GradientTape</code>-style training, we can <em>see</em> our actors play against each other:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># zooming in on a single batch of a single epoch</span>
<span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>GradientTape</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%as%</span> <span class='va'>gen_tape</span>, <span class='op'>{</span> <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>GradientTape</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%as%</span> <span class='va'>disc_tape</span>, <span class='op'>{</span>
  
  <span class='co'># first, it's the generator's call (yep pun intended)</span>
  <span class='va'>generated_images</span> <span class='op'>&lt;-</span> <span class='fu'>generator</span><span class='op'>(</span><span class='va'>noise</span><span class='op'>)</span>
  <span class='co'># now the discriminator gives its verdict on the real images </span>
  <span class='va'>disc_real_output</span> <span class='op'>&lt;-</span> <span class='fu'>discriminator</span><span class='op'>(</span><span class='va'>batch</span>, training <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
  <span class='co'># as well as the fake ones</span>
  <span class='va'>disc_generated_output</span> <span class='op'>&lt;-</span> <span class='fu'>discriminator</span><span class='op'>(</span><span class='va'>generated_images</span>, training <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
  
  <span class='co'># depending on the discriminator's verdict we just got,</span>
  <span class='co'># what's the generator's loss?</span>
  <span class='va'>gen_loss</span> <span class='op'>&lt;-</span> <span class='fu'>generator_loss</span><span class='op'>(</span><span class='va'>disc_generated_output</span><span class='op'>)</span>
  <span class='co'># and what's the loss for the discriminator?</span>
  <span class='va'>disc_loss</span> <span class='op'>&lt;-</span> <span class='fu'>discriminator_loss</span><span class='op'>(</span><span class='va'>disc_real_output</span>, <span class='va'>disc_generated_output</span><span class='op'>)</span>
<span class='op'>}</span><span class='op'>)</span> <span class='op'>}</span><span class='op'>)</span>

<span class='co'># now outside the tape's context compute the respective gradients</span>
<span class='va'>gradients_of_generator</span> <span class='op'>&lt;-</span> <span class='va'>gen_tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>gen_loss</span>, <span class='va'>generator</span><span class='op'>$</span><span class='va'>variables</span><span class='op'>)</span>
<span class='va'>gradients_of_discriminator</span> <span class='op'>&lt;-</span> <span class='va'>disc_tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>disc_loss</span>, <span class='va'>discriminator</span><span class='op'>$</span><span class='va'>variables</span><span class='op'>)</span>
 
<span class='co'># and apply them!</span>
<span class='va'>generator_optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span>
  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>gradients_of_generator</span>, <span class='va'>generator</span><span class='op'>$</span><span class='va'>variables</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
<span class='va'>discriminator_optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span>
  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>gradients_of_discriminator</span>, <span class='va'>discriminator</span><span class='op'>$</span><span class='va'>variables</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Again, compare this with pre-TF 2 GAN training  it makes for a <em>lot</em> more readable code.</p>
<p>As an aside, last years post series may have created the impression that with eager execution, you <em>have</em> to use custom (<code>GradientTape</code>) training instead of Keras-style <code>fit</code>. In fact, that was the case at the time those posts were written. Today, Keras-style code works just fine with eager execution.</p>
<p>So now with TF 2, we are in an optimal position. We <em>can</em> use custom training when we want to, but we dont have to if declarative <code>fit</code> is all we need.</p>
<p>Thats it for a flashlight on what TF 2 means to R users. We now take a look around in the <code>r-tensorflow</code> ecosystem to see new developments  recent-past, present and future  in areas like data loading, preprocessing, and more.</p>
<h2 id="new-developments-in-the-r-tensorflow-ecosystem">New developments in the <code>r-tensorflow</code> ecosystem</h2>
<p>These are what well cover:</p>
<ul>
<li><code>tfdatasets</code>: Over the recent past, <code>tfdatasets</code> pipelines have become the preferred way for data loading and preprocessing.</li>
<li><em>feature columns</em> and <em>feature specs</em>: Specify your features <code>recipes</code>-style and have <code>keras</code> generate the adequate layers for them.</li>
<li>Keras preprocessing layers: Keras preprocessing pipelines integrating functionality such as data augmentation (currently in planning).<br />
</li>
<li><code>tfhub</code>: Use pretrained models as <code>keras</code> layers, and/or as feature columns in a <code>keras</code> model.</li>
<li><code>tf_function</code> and <code>tfautograph</code>: Speed up training by running parts of your code in graph mode.</li>
</ul>
<h3 id="tfdatasets-input-pipelines"><em>tfdatasets</em> input pipelines</h3>
<p>For 2 years now, the <a href="https://tensorflow.rstudio.com/tools/tfdatasets/articles/introduction.html">tfdatasets</a> package has been available to load data for training Keras models in a streaming way.</p>
<p>Logically, there are three steps involved:</p>
<ol type="1">
<li>First, data has to be loaded from some place. This could be a csv file, a directory containing images, or other sources. In this recent example from <a href="https://blogs.rstudio.com/tensorflow/posts/2019-08-23-unet/">Image segmentation with U-Net</a>, information about file names was first stored into an R <code>tibble</code>, and then <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a> was used to create a <code>dataset</code> from it:</li>
</ol>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>data</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://tibble.tidyverse.org/reference/tibble.html'>tibble</a></span><span class='op'>(</span>
  img <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.files</a></span><span class='op'>(</span><span class='fu'>here</span><span class='fu'>::</span><span class='fu'>here</span><span class='op'>(</span><span class='st'>"data-raw/train"</span><span class='op'>)</span>, full.names <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>,
  mask <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.files</a></span><span class='op'>(</span><span class='fu'>here</span><span class='fu'>::</span><span class='fu'>here</span><span class='op'>(</span><span class='st'>"data-raw/train_masks"</span><span class='op'>)</span>, full.names <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
<span class='op'>)</span>

<span class='va'>data</span> <span class='op'>&lt;-</span> <span class='fu'>initial_split</span><span class='op'>(</span><span class='va'>data</span>, prop <span class='op'>=</span> <span class='fl'>0.8</span><span class='op'>)</span>

<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'>training</span><span class='op'>(</span><span class='va'>data</span><span class='op'>)</span> <span class='op'>%&gt;%</span>  
  <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='op'>)</span> 
</code></pre>
</div>
</div>
<ol start="2" type="1">
<li>Once we have a <code>dataset</code>, we perform any required transformations, <em>mapping</em> over the batch dimension. Continuing with the example from the U-Net post, here we use functions from the <a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/image/">tf.image</a> module to (1) load images according to their file type, (2) scale them to values between 0 and 1 (converting to <code>float32</code> at the same time), and (3) resize them to the desired format:</li>
</ol>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='va'>dataset</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dataset_map</span><span class='op'>(</span><span class='op'>~</span><span class='va'>.x</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://purrr.tidyverse.org/reference/list_modify.html'>list_modify</a></span><span class='op'>(</span>
    img <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>decode_jpeg</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='va'>io</span><span class='op'>$</span><span class='fu'>read_file</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>img</span><span class='op'>)</span><span class='op'>)</span>,
    mask <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>decode_gif</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='va'>io</span><span class='op'>$</span><span class='fu'>read_file</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>mask</span><span class='op'>)</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span>,,,<span class='op'>]</span><span class='op'>[</span>,,<span class='fl'>1</span>,drop<span class='op'>=</span><span class='cn'>FALSE</span><span class='op'>]</span>
  <span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>dataset_map</span><span class='op'>(</span><span class='op'>~</span><span class='va'>.x</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://purrr.tidyverse.org/reference/list_modify.html'>list_modify</a></span><span class='op'>(</span>
    img <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>convert_image_dtype</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>img</span>, dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>,
    mask <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>convert_image_dtype</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>mask</span>, dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>
  <span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>dataset_map</span><span class='op'>(</span><span class='op'>~</span><span class='va'>.x</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://purrr.tidyverse.org/reference/list_modify.html'>list_modify</a></span><span class='op'>(</span>
    img <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>resize</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>img</span>, size <span class='op'>=</span> <span class='fu'>shape</span><span class='op'>(</span><span class='fl'>128</span>, <span class='fl'>128</span><span class='op'>)</span><span class='op'>)</span>,
    mask <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>image</span><span class='op'>$</span><span class='fu'>resize</span><span class='op'>(</span><span class='va'>.x</span><span class='op'>$</span><span class='va'>mask</span>, size <span class='op'>=</span> <span class='fu'>shape</span><span class='op'>(</span><span class='fl'>128</span>, <span class='fl'>128</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Note how once you know what these functions do, they free you of a lot of thinking (remember how in the old Keras approach to image preprocessing, you were doing things like dividing pixel values by 255 by hand?)</p>
<ol start="3" type="1">
<li>After transformation, a third conceptual step relates to item arrangement. You will often want to <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/tensor_slices_dataset.html">shuffle</a>, and you certainly will want to <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/dataset_batch.html">batch</a> the data:</li>
</ol>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"> <span class='kw'>if</span> <span class='op'>(</span><span class='va'>train</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='va'>dataset</span> <span class='op'>%&gt;%</span> 
      <span class='fu'>dataset_shuffle</span><span class='op'>(</span>buffer_size <span class='op'>=</span> <span class='va'>batch_size</span><span class='op'>*</span><span class='fl'>128</span><span class='op'>)</span>
  <span class='op'>}</span>

<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='va'>dataset</span> <span class='op'>%&gt;%</span>  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='va'>batch_size</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Summing up, using <code>tfdatasets</code> you build a pipeline, from loading over transformations to batching, that can then be fed directly to a Keras model. From preprocessing, lets go a step further and look at a new, extremely convenient way to do feature engineering.</p>
<h3 id="feature-columns-and-feature-specs">Feature columns and feature specs</h3>
<p><a href="https://tensorflow.rstudio.com/tools/tfdatasets/articles/feature_columns.html">Feature columns</a> as such are a Python-TensorFlow feature, while <a href="https://tensorflow.rstudio.com/tools/tfdatasets/articles/feature_spec.html">feature specs</a> are an R-only idiom modeled after the popular <a href="https://cran.r-project.org/web/packages/recipes/index.html">recipes</a> package.</p>
<p>It all starts off with creating a feature spec object, using formula syntax to indicate whats predictor and whats target:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tfdatasets</span><span class='op'>)</span>
<span class='va'>hearts_dataset</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='va'>hearts</span><span class='op'>)</span>
<span class='va'>spec</span> <span class='op'>&lt;-</span> <span class='fu'>feature_spec</span><span class='op'>(</span><span class='va'>hearts_dataset</span>, <span class='va'>target</span> <span class='op'>~</span> <span class='va'>.</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>That specification is then refined by successive information about how we want to make use of the raw predictors. This is where feature columns come into play. Different column types exist, of which you can see a few in the following code snippet:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>spec</span> <span class='op'>&lt;-</span> <span class='fu'>feature_spec</span><span class='op'>(</span><span class='va'>hearts</span>, <span class='va'>target</span> <span class='op'>~</span> <span class='va'>.</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_numeric_column</span><span class='op'>(</span>
    <span class='fu'>all_numeric</span><span class='op'>(</span><span class='op'>)</span>, <span class='op'>-</span><span class='va'>cp</span>, <span class='op'>-</span><span class='va'>restecg</span>, <span class='op'>-</span><span class='va'>exang</span>, <span class='op'>-</span><span class='va'>sex</span>, <span class='op'>-</span><span class='va'>fbs</span>,
    normalizer_fn <span class='op'>=</span> <span class='fu'>scaler_standard</span><span class='op'>(</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_categorical_column_with_vocabulary_list</span><span class='op'>(</span><span class='va'>thal</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_bucketized_column</span><span class='op'>(</span><span class='va'>age</span>, boundaries <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>18</span>, <span class='fl'>25</span>, <span class='fl'>30</span>, <span class='fl'>35</span>, <span class='fl'>40</span>, <span class='fl'>45</span>, <span class='fl'>50</span>, <span class='fl'>55</span>, <span class='fl'>60</span>, <span class='fl'>65</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_indicator_column</span><span class='op'>(</span><span class='va'>thal</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_embedding_column</span><span class='op'>(</span><span class='va'>thal</span>, dimension <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>step_crossed_column</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>thal</span>, <span class='va'>bucketized_age</span><span class='op'>)</span>, hash_bucket_size <span class='op'>=</span> <span class='fl'>10</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_indicator_column</span><span class='op'>(</span><span class='va'>crossed_thal_bucketized_age</span><span class='op'>)</span>

<span class='va'>spec</span> <span class='op'>%&gt;%</span> <span class='fu'>fit</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>What happened here is that we told TensorFlow, please take all numeric columns (besides a few ones listed exprs) and scale them; take column <code>thal</code>, treat it as categorical and create an embedding for it; discretize <code>age</code> according to the given ranges; and finally, create a <em>crossed column</em> to capture interaction between <code>thal</code> and that discretized age-range column. <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>This is nice, but when creating the model, well still have to define all those layers, right? (Which would be pretty cumbersome, having to figure out all the right dimensions) Luckily, we dont have to. In sync with <code>tfdatasets</code>, <code>keras</code> now provides <a href="https://tensorflow.rstudio.com/keras/reference/layer_dense_features.html">layer_dense_features</a> to create a layer tailor-made to accommodate the specification.</p>
<p>And we dont need to create separate input layers either, due to <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/layer_input_from_dataset.html">layer_input_from_dataset</a>. Here we see both in action:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>input</span> <span class='op'>&lt;-</span> <span class='fu'>layer_input_from_dataset</span><span class='op'>(</span><span class='va'>hearts</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='op'>-</span><span class='va'>target</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>output</span> <span class='op'>&lt;-</span> <span class='va'>input</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>layer_dense_features</span><span class='op'>(</span>feature_columns <span class='op'>=</span> <span class='fu'>dense_features</span><span class='op'>(</span><span class='va'>spec</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> 
  <span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>1</span>, activation <span class='op'>=</span> <span class='st'>"sigmoid"</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>From then on, its just normal <code>keras</code> <code>compile</code> and <code>fit</code>. See the <a href="https://tensorflow.rstudio.com/tools/tfdatasets/articles/feature_columns.html">vignette</a> for the complete example. There also is a <a href="https://blogs.rstudio.com/tensorflow/posts/2019-07-09-feature-columns/">post on feature columns</a> explaining more of how this works, and illustrating the time-and-nerve-saving effect by comparing with the pre-feature-spec way of working with heterogeneous datasets.</p>
<p>As a last item on the topics of preprocessing and feature engineering, lets look at a promising thing to come in what we hope is the near future.</p>
<h3 id="keras-preprocessing-layers">Keras preprocessing layers</h3>
<p>Reading what we wrote above about using <code>tfdatasets</code> for building a input pipeline, and seeing how we gave an image loading example, you may have been wondering: What about data augmentation functionality available, historically, through <code>keras</code>? Like <code>image_data_generator</code>?</p>
<p>This functionality does not seem to fit. But a nice-looking solution is in preparation. In the Keras community, the recent <a href="https://github.com/keras-team/governance/blob/master/rfcs/20190729-keras-preprocessing-redesign.md">RFC on preprocessing layers for Keras</a> addresses this topic. The RFC is still under discussion, but as soon as it gets implemented in Python well follow up on the R side.</p>
<p>The idea is to provide (chainable) preprocessing layers to be used for data transformation and/or augmentation in areas such as image classification, image segmentation, object detection, text processing, and more. <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> The envisioned, in the RFC, pipeline of preprocessing layers should return a <code>dataset</code>, for compatibility with <code>tf.data</code> (our <code>tfdatasets</code>). Were definitely looking forward to having available this sort of workflow!</p>
<p>Lets move on to the next topic, the common denominator being convenience. But now convenience means not having to build billion-parameter models yourself!</p>
<h3 id="tensorflow-hub-and-the-tfhub-package">Tensorflow Hub and the <code>tfhub</code> package</h3>
<p><a href="https://www.tensorflow.org/hub">Tensorflow Hub</a> is a library for publishing and using pretrained models. Existing models can be browsed on <a href="https://tfhub.dev/">tfhub.dev</a>.</p>
<p>As of this writing, the original Python library is still under development, so complete stability is not guaranteed. That notwithstanding, the <a href="https://github.com/rstudio/tfhub">tfhub</a> R package already allows for some instructive experimentation.</p>
<p>The traditional Keras idea of using pretrained models typically involved either (1) applying a model like <em>MobileNet</em> as a whole, including its output layer, or (2) chaining a custom head to its penultimate layer <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. In contrast, the TF Hub idea is to use a pretrained model as a <em>module</em> in a larger setting.</p>
<p>There are two main ways to accomplish this, namely, integrating a module as a <code>keras</code> layer and using it as a feature column. The <a href="https://github.com/rstudio/tfhub">tfhub README</a> shows the first option:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tfhub</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>keras</span><span class='op'>)</span>

<span class='va'>input</span> <span class='op'>&lt;-</span> <span class='fu'>layer_input</span><span class='op'>(</span>shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>32</span>, <span class='fl'>32</span>, <span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>output</span> <span class='op'>&lt;-</span> <span class='va'>input</span> <span class='op'>%&gt;%</span>
  <span class='co'># we are using a pre-trained MobileNet model!</span>
  <span class='fu'>layer_hub</span><span class='op'>(</span>handle <span class='op'>=</span> <span class='st'>"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>10</span>, activation <span class='op'>=</span> <span class='st'>"softmax"</span><span class='op'>)</span>

<span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>keras_model</span><span class='op'>(</span><span class='va'>input</span>, <span class='va'>output</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>While the <a href="https://github.com/rstudio/tfhub/blob/master/vignettes/examples/feature_column.R">tfhub feature columns vignette</a> illustrates the second one:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>spec</span> <span class='op'>&lt;-</span> <span class='va'>dataset_train</span> <span class='op'>%&gt;%</span>
  <span class='fu'>feature_spec</span><span class='op'>(</span><span class='va'>AdoptionSpeed</span> <span class='op'>~</span> <span class='va'>.</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_text_embedding_column</span><span class='op'>(</span>
    <span class='va'>Description</span>,
    module_spec <span class='op'>=</span> <span class='st'>"https://tfhub.dev/google/universal-sentence-encoder/2"</span>
    <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_image_embedding_column</span><span class='op'>(</span>
    <span class='va'>img</span>,
    module_spec <span class='op'>=</span> <span class='st'>"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/3"</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_numeric_column</span><span class='op'>(</span><span class='va'>Age</span>, <span class='va'>Fee</span>, <span class='va'>Quantity</span>, normalizer_fn <span class='op'>=</span> <span class='fu'>scaler_standard</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_categorical_column_with_vocabulary_list</span><span class='op'>(</span>
    <span class='fu'>has_type</span><span class='op'>(</span><span class='st'>"string"</span><span class='op'>)</span>, <span class='op'>-</span><span class='va'>Description</span>, <span class='op'>-</span><span class='va'>RescuerID</span>, <span class='op'>-</span><span class='va'>img_path</span>, <span class='op'>-</span><span class='va'>PetID</span>, <span class='op'>-</span><span class='va'>Name</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>step_embedding_column</span><span class='op'>(</span><span class='va'>Breed1</span><span class='op'>:</span><span class='va'>Health</span>, <span class='va'>State</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Both usage modes illustrate the high potential of working with Hub modules. Just be cautioned that, as of today, not every model published will work with TF 2.</p>
<h3 id="tf_function-tf-autograph-and-the-r-package-tfautograph"><code>tf_function</code>, TF autograph and the R package <code>tfautograph</code></h3>
<p>As explained above, the default execution mode in TF 2 is eager. For performance reasons however, in many cases it will be desirable to compile parts of your code into a graph. Calls to Keras layers, for example, are run in graph mode.</p>
<p>To compile a function into a graph, wrap it in a call to <code>tf_function</code>, as done e.g.in the post <a href="https://blogs.rstudio.com/tensorflow/posts/2019-07-31-censored-data/">Modeling censored data with tfprobability</a>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>run_mcmc</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>kernel</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='va'>kernel</span> <span class='op'>%&gt;%</span> <span class='fu'>mcmc_sample_chain</span><span class='op'>(</span>
    num_results <span class='op'>=</span> <span class='va'>n_steps</span>,
    num_burnin_steps <span class='op'>=</span> <span class='va'>n_burnin</span>,
    current_state <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>ones_like</span><span class='op'>(</span><span class='va'>initial_betas</span><span class='op'>)</span>,
    trace_fn <span class='op'>=</span> <span class='va'>trace_fn</span>
  <span class='op'>)</span>
<span class='op'>}</span>

<span class='co'># important for performance: run HMC in graph mode</span>
<span class='va'>run_mcmc</span> <span class='op'>&lt;-</span> <span class='fu'>tf_function</span><span class='op'>(</span><span class='va'>run_mcmc</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>On the Python side, the <code>tf.autograph</code> module automatically translates Python control flow statements into appropriate graph operations.</p>
<p>Independently of <code>tf.autograph</code>, the R package <a href="https://t-kalinowski.github.io/tfautograph/index.html">tfautograph</a>, developed by Tomasz Kalinowski, implements control flow conversion directly from R to TensorFlow. This lets you use Rs <code>if</code>, <code>while</code>, <code>for</code>, <code>break</code>, and <code>next</code> when writing custom training flows. Check out the packages extensive documentation for instructive examples!</p>
<h2 id="conclusion">Conclusion</h2>
<p>With that, we end our introduction of TF 2 and the new developments that surround it.</p>
<p>If you have been using <code>keras</code> in traditional ways, how much changes <em>for you</em> is mainly up to you: Most everything will still work, but new options exist to write more performant, more modular, more elegant code. In particular, check out <code>tfdatasets</code> pipelines for efficient data loading.</p>
<p>If youre an advanced user requiring non-standard setup, have a look into custom training and custom models, and consult the <code>tfautograph</code> documentation to see how the package can help.</p>
<p>In any case, stay tuned for upcoming posts showing some of the above-mentioned functionality in action. Thanks for reading!</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Original Python Keras, and thus, R <code>keras</code>, supported additional backends: Theano and CNTK. But the default backend in R <code>keras</code> always was TensorFlow.<a href="#fnref1" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn2" role="doc-endnote"><p>Note the terminology: in R <code>keras</code>, <em>implementation</em> referred to the Python library (Keras or TensorFlow, with its module <code>tf.keras</code>) bound to, while <em>backend</em> referred to the framework providing low-level operations, which could be one of Theano, TensorFlow and CNTK.)<a href="#fnref2" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn3" role="doc-endnote"><p>E.g., parameters like <em>learning_rate</em> may have to be adapted.<a href="#fnref3" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn4" role="doc-endnote"><p>See <a href="https://blogs.rstudio.com/tensorflow/posts/2018-10-02-eager-wrapup/">More flexible models with TensorFlow eager execution and Keras</a> for an overview and annotated links.<a href="#fnref4" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn5" role="doc-endnote"><p>Here the nominal input is an R vector that gets converted to a Python list by <code>reticulate</code>, and to a tensor by TensorFlow.<a href="#fnref5" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn6" role="doc-endnote"><p>This is still a tensor though. To continue working with its values in R, we need to convert it to R using <code>as.numeric</code>, <code>as.matrix</code>, <code>as.array</code> etc.<a href="#fnref6" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn7" role="doc-endnote"><p>For example, see <a href="https://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan/">Generating images with Keras and TensorFlow eager execution</a> on GANs, <a href="https://blogs.rstudio.com/tensorflow/posts/2018-09-10-eager-style-transfer/">Neural style transfer with eager execution and Keras</a> on neural style transfer, or <a href="https://blogs.rstudio.com/tensorflow/posts/2018-10-22-mmd-vae/">Representation learning with MMD-VAE</a> on Variational Autoencoders.<a href="#fnref7" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn8" role="doc-endnote"><p><code>step_indicator_column</code> is there (twice) for technical reasons. Our <a href="https://blogs.rstudio.com/tensorflow/posts/2019-07-09-feature-columns/">post on feature columns</a> explains.<a href="#fnref8" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn9" role="doc-endnote"><p>As readers working in e.g.image segmentation will know, data augmentation is not as easy as just using <code>image_data_generator</code> on the input images, as analogous distortions have to be applied to the masks.<a href="#fnref9" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn10" role="doc-endnote"><p>or block of layers<a href="#fnref10" class="footnote-back" role="doc-backlink"></a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2019-10-08-tf2-whatchanges/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=TensorFlow%202.0%20is%20here%20-%20what%20changes%20for%20R%20users%3F&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2019-10-08-tf2-whatchanges%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2019-10-08-tf2-whatchanges%2F&amp;title=TensorFlow%202.0%20is%20here%20-%20what%20changes%20for%20R%20users%3F">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/';
  this.page.identifier = 'posts/2019-10-08-tf2-whatchanges/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2019, Oct. 8). RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydana2019tf2,
  author = {Keydana, Sigrid},
  title = {RStudio AI Blog: TensorFlow 2.0 is here - what changes for R users?},
  url = {https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/},
  year = {2019}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
