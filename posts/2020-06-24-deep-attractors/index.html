<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #20794d; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007ba5; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #007ba5; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #007ba5; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #20794d; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: Deep attractors: Where deep learning meets chaos</title>

<meta property="description" itemprop="description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-06-24"/>
<meta property="article:created" itemprop="dateCreated" content="2020-06-24"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/images/x_z.gif"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta property="twitter:description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/images/x_z.gif"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/06/24"/>
<meta name="citation_publication_date" content="2020/06/24"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Deep reconstruction of strange attractors from time series;citation_publication_date=2020;citation_author=William Gilpin"/>
  <meta name="citation_reference" content="citation_title=Determining embedding dimension for phase-space reconstruction using a geometrical construction;citation_publication_date=1992;citation_publisher=American Physical Society;citation_volume=45;citation_doi=10.1103/PhysRevA.45.3403;citation_author=Matthew B. Kennel;citation_author=Reggie Brown;citation_author=Henry D. I. Abarbanel"/>
  <meta name="citation_reference" content="citation_title=Linear Algebra and learning from data;citation_publication_date=2019;citation_publisher=Wellesley Cambridge Press;citation_author=Gilbert Strang"/>
  <meta name="citation_reference" content="citation_title=Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering;citation_publication_date=2015;citation_publisher=Westview Press;citation_author=Steven Strogatz"/>
  <meta name="citation_reference" content="citation_title=Nonlinear time series analysis;citation_publication_date=2004;citation_publisher=Cambridge University Press;citation_author=Holger Kantz;citation_author=Thomas Schreiber"/>
  <meta name="citation_reference" content="citation_title=Embedology;citation_publication_date=1991;citation_volume=65;citation_doi=10.1007/BF01053745;citation_author=Tim Sauer;citation_author=James A. Yorke;citation_author=Martin Casdagli"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","bibliography","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Deep attractors: Where deep learning meets chaos"]},{"type":"character","attributes":{},"value":["In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanadeepattractors"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["06-24-2020"]},{"type":"character","attributes":{},"value":["R","TensorFlow/Keras","Time Series","Unsupervised Learning"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/x_z.gif"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","deep_attractors_files/bowser-1.9.3/bowser.min.js","deep_attractors_files/distill-2.2.21/template.v2.js","deep_attractors_files/header-attrs-2.1/header-attrs.js","deep_attractors_files/header-attrs-2.2/header-attrs.js","deep_attractors_files/header-attrs-2.3/header-attrs.js","deep_attractors_files/jquery-1.11.3/jquery.min.js","deep_attractors_files/webcomponents-2.0.0/webcomponents.js","images/2cycle.png","images/chaos.png","images/chaos2.png","images/chaos3.png","images/fnn.png","images/lorenz_attractors.png","images/lorenz_attractors.xcf","images/obs.png","images/predicted_attractors.png","images/single_fixedpoint.png","images/x_z.gif"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      var refHtml = $('#ref-' + $(this).attr('data-cites')).html();
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.7/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Deep attractors: Where deep learning meets chaos","description":"In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-06-24T00:00:00.000+00:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Deep attractors: Where deep learning meets chaos</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
  <a href="../../index.html#category:Time_Series" class="dt-tag">Time Series</a>
  <a href="../../index.html#category:Unsupervised_Learning" class="dt-tag">Unsupervised Learning</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>06-24-2020
</div>

<div class="d-article">
<p>For us deep learning practitioners, the world is  not flat, but  linear, mostly. Or piecewise linear.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Like other linear approximations, or maybe even more so, deep learning can be incredibly successful at making predictions. But lets admit it  sometimes we just miss the thrill of the nonlinear, of good, old, deterministic-yet-unpredictable chaos. Can we have both? It looks like we can. In this post, well see an application of deep learning (DL) to nonlinear time series prediction  or rather, the essential step that predates it: reconstructing the attractor underlying its dynamics. While this post is an introduction, presenting the topic from scratch, further posts will build on this and extrapolate to observational datasets.</p>
<h3 id="what-to-expect-from-this-post">What to expect from this post</h3>
<p>In his 2020 paper <em>Deep reconstruction of strange attractors from time series</em> <span class="citation" data-cites="gilpin2020deep">(Gilpin <a href="#ref-gilpin2020deep" role="doc-biblioref">2020</a>)</span>, William Gilpin uses an autoencoder architecture, combined with a regularizer implementing the <em>false nearest neighbors</em> statistic <span class="citation" data-cites="PhysRevA.45.3403">(Kennel, Brown, and Abarbanel <a href="#ref-PhysRevA.45.3403" role="doc-biblioref">1992</a>)</span>, to reconstruct attractors from univariate observations of multivariate, nonlinear dynamical systems. If you feel you completely understand the sentence you just read, you may as well directly jump to the paper  come back for the code though<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. If, on the other hand, youre more familiar with the chaos on your desk (extrapolating  apologies) than <em>chaos theory chaos</em>, read on. Here, well first go into what its all about<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, and then, show an example application, featuring Edward Lorenzs famous butterfly attractor. While this initial post is primarily supposed to be a fun introduction to a fascinating topic, we hope to follow up with applications to real-world datasets in the future.</p>
<h2 id="rabbits-butterflies-and-low-dimensional-projections-our-problem-statement-in-context">Rabbits, butterflies, and low-dimensional projections: Our problem statement in context</h2>
<p>In curious misalignment with how we use chaos in day-to-day language, chaos, the technical concept, is very different from stochasticity, or randomness. Chaos may emerge from purely deterministic processes - very simplistic ones, even. Lets see how; with rabbits.</p>
<h3 id="rabbits-or-sensitive-dependence-on-initial-conditions">Rabbits, or: Sensitive dependence on initial conditions</h3>
<p>You may be familiar with the <em>logistic</em> equation, used as a toy model for population growth. Often its written like this  with <span class="math inline">\(x\)</span> being the size of the population, expressed as a fraction of the maximal size (a fraction of possible rabbits, thus), and <span class="math inline">\(r\)</span> being the growth rate (the rate at which rabbits reproduce):</p>
<p><span class="math display">\[
x_{n + 1} = r \ x_n \ (1 - x_n)
\]</span></p>
<p>This equation describes an <em>iterated map</em> over discrete timesteps <span class="math inline">\(n\)</span>. Its repeated application results in a <em>trajectory</em> describing how the population of rabbits evolves. Maps can have <em>fixed points</em>, states where further function application goes on producing the same result forever. Example-wise, say the growth rate amounts to <span class="math inline">\(2.1\)</span>, and we start at two (pretty different!) initial values, <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.8\)</span>. Both trajectories arrive at a fixed point  the same fixed point  in fewer than 10 iterations. Were we asked to predict the population size after a hundred iterations, we could make a very confident guess, whatever the of starting value. (If the initial value is <span class="math inline">\(0\)</span>, we stay at <span class="math inline">\(0\)</span>, but we can be pretty certain of that as well.)</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="images/single_fixedpoint.png" alt="Trajectory of the logistic map for r = 2.1 and two different initial values." width="600" />
<p class="caption">
Figure 1: Trajectory of the logistic map for r = 2.1 and two different initial values.
</p>
</div>
</div>
<p>What if the growth rate were somewhat higher, at <span class="math inline">\(3.3\)</span>, say? Again, we immediately compare trajectories resulting from initial values <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.9\)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="images/2cycle.png" alt="Trajectory of the logistic map for r = 3.3 and two different initial values." width="500" />
<p class="caption">
Figure 2: Trajectory of the logistic map for r = 3.3 and two different initial values.
</p>
</div>
</div>
<p>This time, dont see a single fixed point, but a <em>two-cycle</em>: As the trajectories stabilize, population size inevitably is at one of two possible values  either too many rabbits or too few, you could say. The two trajectories are phase-shifted, but again, the attracting values  the <em>attractor</em>  is shared by both initial conditions. So still, predictability is pretty high. But we havent seen everything yet.</p>
<p>Lets again enhance the growth rate some. Now <em>this</em> (literally) is chaos:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="images/chaos.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.9." width="500" />
<p class="caption">
Figure 3: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.9.
</p>
</div>
</div>
<p>Even after a hundred iterations, there is no set of values the trajectories recur to. We cant be confident about any prediction we might make.</p>
<p>Or can we? After all, we have the governing equation, which is deterministic. So we should be able to calculate the size of the population at, say, time <span class="math inline">\(150\)</span>? In principle, yes; but this presupposes we have an accurate measurement for the starting state.</p>
<p>How accurate? Lets compare trajectories for initial values <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.301\)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="images/chaos2.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.301." width="500" />
<p class="caption">
Figure 4: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.301.
</p>
</div>
</div>
<p>At first, trajectories seem to jump around in unison; but during the second dozen iterations already, they dissociate more and more, and increasingly, all bets are off. What if initial values are <em>really</em> close, as in, <span class="math inline">\(0.3\)</span> vs.<span class="math inline">\(0.30000001\)</span>?</p>
<p>It just takes a bit longer for the disassociation to surface.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="images/chaos3.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.30000001." width="600" />
<p class="caption">
Figure 5: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.30000001.
</p>
</div>
</div>
<p>What were seeing here is <em>sensitive dependence on initial conditions</em>, an essential precondition for a system to be chaotic. In an nutshell: Chaos arises when a <em>deterministic</em> system shows <em>sensitive dependence on initial conditions</em>. Or as Edward Lorenz <a href="https://en.wikipedia.org/wiki/Chaos_theory">is said to have put it</a>,</p>
<blockquote>
<p>When the present determines the future, but the approximate present does not approximately determine the future.</p>
</blockquote>
<p>Now if these unstructured, random-looking point clouds constitute chaos, what with the all-but-amorphous butterfly (to be displayed very soon)?</p>
<h3 id="butterflies-or-attractors-and-strange-attractors">Butterflies, or: Attractors and strange attractors</h3>
<p>Actually, in the context of chaos theory, the term butterfly may be encountered in different contexts.</p>
<p>Firstly, as so-called butterfly effect, it is an instantiation of the templatic phrase the flap of a butterflys wing in _________ profoundly affects the course of the weather in _________.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> In this usage, it is mostly a metaphor for sensitive dependence on initial conditions.</p>
<p>Secondly, the existence of this metaphor led to a Rorschach-test-like identification with two-dimensional visualizations of attractors of the Lorenz system. The Lorenz system is a set of three first-order differential equations designed to describe <a href="https://en.wikipedia.org/wiki/Atmospheric_convection">atmospheric convection</a>:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{dx}{dt} = \sigma (y - x)\\
&amp; \frac{dy}{dt} = \rho x - x z - y\\
&amp; \frac{dz}{dt} = x y - \beta z
\end{aligned}
\]</span></p>
<p>This set of equations is nonlinear, as required for chaotic behavior to appear. It also has the required dimensionality, which for smooth, continuous systems, is at least 3<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Whether we actually see chaotic attractors  among which, the butterfly  depends on the settings of the parameters <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\rho\)</span> and <span class="math inline">\(\beta\)</span>. For the values conventionally chosen, <span class="math inline">\(\sigma=10\)</span>, <span class="math inline">\(\rho=28\)</span>, and <span class="math inline">\(\beta=8/3\)</span> , we see it when projecting the trajectory on the <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> axes:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="images/lorenz_attractors.png" alt="Two-dimensional projections of the Lorenz attractor for sigma = 10, rho = 28, beta = 8 / 3. On the right: the butterfly." width="500" />
<p class="caption">
Figure 6: Two-dimensional projections of the Lorenz attractor for sigma = 10, rho = 28, beta = 8 / 3. On the right: the butterfly.
</p>
</div>
</div>
<p>The butterfly is an <em>attractor</em> (as are the other two projections), but it is neither a point nor a cycle. It is an attractor in the sense that starting from a variety of different initial values, we end up in some sub-region of the state space, and we dont get to escape no more. This is easier to see when watching evolution over time, as in this animation:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span id="fig:unnamed-chunk-7"></span>
<img src="images/x_z.gif" alt="How the Lorenz attractor traces out the famous &quot;butterfly&quot; shape."  />
<p class="caption">
Figure 7: How the Lorenz attractor traces out the famous butterfly shape.
</p>
</div>
</div>
<p>Now, to plot the attractor in two dimensions, we threw away the third. But in real life, we dont usually have too <em>much</em> information (although it may sometimes seem like we had). We might have a lot of measurements, but these dont usually reflect the actual state variables were interested in. In these cases, we may want to actually <em>add</em> information.</p>
<h3 id="embeddings-as-a-non-dl-term-or-undoing-the-projection">Embeddings (as a non-DL term), or: Undoing the projection</h3>
<p>Assume that instead of all three variables of the Lorenz system, we had measured just one: <span class="math inline">\(x\)</span>, the rate of convection. Often in nonlinear dynamics, the technique of delay coordinate embedding <span class="citation" data-cites="embedology">(Sauer, Yorke, and Casdagli <a href="#ref-embedology" role="doc-biblioref">1991</a>)</span> is used to enhance a series of univariate measurements.</p>
<p>In this method  or family of methods  the univariate series is augmented by time-shifted copies of itself. There are two decisions to be made: How many copies to add, and how big the delay should be. To illustrate, if we had a scalar series,</p>
<pre><code>1 2 3 4 5 6 7 8 9 10 11 ...</code></pre>
<p>a three-dimensional embedding with time delay 2 would look like this:</p>
<pre><code>1 3 5
2 4 6
3 5 7
4 6 8
5 7 9
6 8 10
7 9 11
...</code></pre>
<p>Of the two decisions to be made  number of shifted series and time lag  the first is a decision on the dimensionality of the reconstruction space. Various theorems, such as <a href="https://en.wikipedia.org/wiki/Takens%27s_theorem">Taken's theorem</a>, indicate bounds on the number of dimensions required, provided the dimensionality of the true state space is known  which, in real-world applications, often is not the case.The second has been of little interest to mathematicians, but is important in practice. In fact, Kantz and Schreiber <span class="citation" data-cites="Kantz">(Kantz and Schreiber <a href="#ref-Kantz" role="doc-biblioref">2004</a>)</span> argue that in practice, it is the product of both parameters that matters, as it indicates the time span represented by an embedding vector.</p>
<p>How are these parameters chosen? Regarding reconstruction dimensionality, the reasoning goes that even in chaotic systems, points that are close in state space at time <span class="math inline">\(t\)</span> should still be close at time <span class="math inline">\(t + \Delta t\)</span>, provided <span class="math inline">\(\Delta t\)</span> is very small. So say we have two points that are close, by some metric, when represented in two-dimensional space. But in three dimensions, that is, if we dont project away the third dimension, they are a lot more distant. As illustrated in <span class="citation" data-cites="gilpin2020deep">(Gilpin <a href="#ref-gilpin2020deep" role="doc-biblioref">2020</a>)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-8"></span>
<img src="images/fnn.png" alt="In the two-dimensional projection on axes x and y, the red points are close neighbors. In 3d, however, they are separate. Compare with the blue points, which stay close even in higher-dimensional space. Figure from Gilpin (2020)." width="380" />
<p class="caption">
Figure 8: In the two-dimensional projection on axes x and y, the red points are close neighbors. In 3d, however, they are separate. Compare with the blue points, which stay close even in higher-dimensional space. Figure from Gilpin (2020).
</p>
</div>
</div>
<p>If this happens, then projecting down has eliminated some essential information. In 2d, the points were <em>false neighbors</em>. The <em>false nearest neighbors</em> (FNN) statistic can be used to determine an adequate embedding size, like this:</p>
<p>For each point, take its closest neighbor in <span class="math inline">\(m\)</span> dimensions, and compute the ratio of their distances in <span class="math inline">\(m\)</span> and <span class="math inline">\(m+1\)</span> dimensions. If the ratio is larger than some threshold <span class="math inline">\(t\)</span>, the neighbor was false. Sum the number of false neighbors over all points. Do this for different <span class="math inline">\(m\)</span> and <span class="math inline">\(t\)</span>, and inspect the resulting curves.</p>
<p>At this point, lets look ahead at the autoencoder approach. The autoencoder will use that same FNN statistic as a regularizer, in addition to the usual autoencoder reconstruction loss. This will result in a new heuristic regarding embedding dimensionality that involves fewer decisions.</p>
<p>Going back to the classic method for an instant, the second parameter, the time lag, is even more difficult to sort out <span class="citation" data-cites="Kantz">(Kantz and Schreiber <a href="#ref-Kantz" role="doc-biblioref">2004</a>)</span>. Usually, mutual information is plotted for different delays and then, the first delay where it falls below some threshold is chosen. We dont further elaborate on this question as it is rendered obsolete in the neural network approach. Which well see now.</p>
<h2 id="learning-the-lorenz-attractor">Learning the Lorenz attractor</h2>
<p>Our code closely follows the architecture, parameter settings, and data setup used in the <a href="https://github.com/williamgilpin/fnn">reference implementation</a> William provided. The loss function, especially, has been ported one-to-one.</p>
<p>The general idea is the following. An autoencoder  for example, an LSTM autoencoder as presented here  is used to compress the univariate time series into a latent representation of some dimensionality, which will constitute an upper bound on the dimensionality of the learned attractor. In addition to mean squared error between input and reconstructions, there will be a second loss term, applying the FNN regularizer. This results in the latent units being roughly ordered by <em>importance</em>, as measured by their variance. It is expected that somewhere in the listing of variances, a sharp drop will appear. The units before the drop are then assumed to encode the <em>attractor</em> of the system in question.</p>
<p>In this setup, there is still a choice to be made: how to weight the FNN loss. One would run training for different weights <span class="math inline">\(\lambda\)</span> and look for the drop. Surely, this could in principle be automated, but given the newness of the method  the paper was published this year  it makes sense to focus on thorough analysis first.</p>
<h3 id="data-generation">Data generation</h3>
<p>We use the <code>deSolve</code> package to generate data from the Lorenz equations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>deSolve</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tidyverse</span><span class='op'>)</span>

<span class='va'>parameters</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>sigma <span class='op'>=</span> <span class='fl'>10</span>,
                rho <span class='op'>=</span> <span class='fl'>28</span>,
                beta <span class='op'>=</span> <span class='fl'>8</span><span class='op'>/</span><span class='fl'>3</span><span class='op'>)</span>

<span class='va'>initial_state</span> <span class='op'>&lt;-</span>
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='op'>-</span><span class='fl'>8.60632853</span>,
    y <span class='op'>=</span> <span class='op'>-</span><span class='fl'>14.85273055</span>,
    z <span class='op'>=</span> <span class='fl'>15.53352487</span><span class='op'>)</span>

<span class='va'>lorenz</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>t</span>, <span class='va'>state</span>, <span class='va'>parameters</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>as.list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>parameters</span><span class='op'>)</span><span class='op'>)</span>, <span class='op'>{</span>
    <span class='va'>dx</span> <span class='op'>&lt;-</span> <span class='va'>sigma</span> <span class='op'>*</span> <span class='op'>(</span><span class='va'>y</span> <span class='op'>-</span> <span class='va'>x</span><span class='op'>)</span>
    <span class='va'>dy</span> <span class='op'>&lt;-</span> <span class='va'>x</span> <span class='op'>*</span> <span class='op'>(</span><span class='va'>rho</span> <span class='op'>-</span> <span class='va'>z</span><span class='op'>)</span> <span class='op'>-</span> <span class='va'>y</span>
    <span class='va'>dz</span> <span class='op'>&lt;-</span> <span class='va'>x</span> <span class='op'>*</span> <span class='va'>y</span> <span class='op'>-</span> <span class='va'>beta</span> <span class='op'>*</span> <span class='va'>z</span>
    
    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>dx</span>, <span class='va'>dy</span>, <span class='va'>dz</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>}</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='va'>times</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>500</span>, length.out <span class='op'>=</span> <span class='fl'>125000</span><span class='op'>)</span>

<span class='va'>lorenz_ts</span> <span class='op'>&lt;-</span>
  <span class='fu'>ode</span><span class='op'>(</span>
    y <span class='op'>=</span> <span class='va'>initial_state</span>,
    times <span class='op'>=</span> <span class='va'>times</span>,
    func <span class='op'>=</span> <span class='va'>lorenz</span>,
    parms <span class='op'>=</span> <span class='va'>parameters</span>,
    method <span class='op'>=</span> <span class='st'>"lsoda"</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>lorenz_ts</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>,<span class='op'>]</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 10 x 4
      time      x     y     z
     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 0        -8.61 -14.9  15.5
 2 0.00400  -8.86 -15.2  15.9
 3 0.00800  -9.12 -15.6  16.3
 4 0.0120   -9.38 -16.0  16.7
 5 0.0160   -9.64 -16.3  17.1
 6 0.0200   -9.91 -16.7  17.6
 7 0.0240  -10.2  -17.0  18.1
 8 0.0280  -10.5  -17.3  18.6
 9 0.0320  -10.7  -17.7  19.1
10 0.0360  -11.0  -18.0  19.7</code></pre>
<p>Weve already seen the attractor, or rather, its three two-dimensional projections, in figure 6 above. But now our scenario is different. We only have access to <span class="math inline">\(x\)</span>, a univariate time series. As the time interval used to numerically integrate the differential equations was rather tiny, we just use every tenth observation.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>obs</span> <span class='op'>&lt;-</span> <span class='va'>lorenz_ts</span> <span class='op'>%&gt;%</span>
  <span class='fu'>select</span><span class='op'>(</span><span class='va'>time</span>, <span class='va'>x</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'>row_number</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%%</span> <span class='fl'>10</span> <span class='op'>==</span> <span class='fl'>0</span><span class='op'>)</span>

<span class='fu'>ggplot</span><span class='op'>(</span><span class='va'>obs</span>, <span class='fu'>aes</span><span class='op'>(</span><span class='va'>time</span>, <span class='va'>x</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>geom_line</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>coord_cartesian</span><span class='op'>(</span>xlim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>100</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
  <span class='fu'>theme_classic</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-11"></span>
<img src="images/obs.png" alt="Convection rates as a univariate time series." width="500" />
<p class="caption">
Figure 9: Convection rates as a univariate time series.
</p>
</div>
</div>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first half of the series is used for training. The data is scaled and transformed into the three-dimensional form expected by recurrent layers.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>keras</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tfdatasets</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>tfautograph</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/reticulate'>reticulate</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://purrr.tidyverse.org'>purrr</a></span><span class='op'>)</span>

<span class='co'># scale observations</span>
<span class='va'>obs</span> <span class='op'>&lt;-</span> <span class='va'>obs</span> <span class='op'>%&gt;%</span> <span class='fu'>mutate</span><span class='op'>(</span>
  x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/scale.html'>scale</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>
<span class='op'>)</span>

<span class='co'># generate timesteps</span>
<span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>)</span>
<span class='va'>n_timesteps</span> <span class='op'>&lt;-</span> <span class='fl'>10</span>

<span class='va'>gen_timesteps</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>n_timesteps</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>rbind</span>,
          <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_along</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>,
             <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span>
               <span class='va'>start</span> <span class='op'>&lt;-</span> <span class='va'>i</span>
               <span class='va'>end</span> <span class='op'>&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='fl'>1</span>
               <span class='va'>out</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>[</span><span class='va'>start</span><span class='op'>:</span><span class='va'>end</span><span class='op'>]</span>
               <span class='va'>out</span>
             <span class='op'>}</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/r/stats/na.fail.html'>na.omit</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='co'># train with start of time series, test with end of time series </span>
<span class='va'>x_train</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>$</span><span class='va'>x</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span>, <span class='va'>n_timesteps</span><span class='op'>)</span>
<span class='va'>x_test</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>$</span><span class='va'>x</span><span class='op'>)</span><span class='op'>[</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>:</span><span class='va'>n</span><span class='op'>]</span>, <span class='va'>n_timesteps</span><span class='op'>)</span> 

<span class='co'># add required dimension for features (we have one)</span>
<span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span>

<span class='co'># some batch size (value not crucial)</span>
<span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>100</span>

<span class='co'># transform to datasets so we can use custom training</span>
<span class='va'>ds_train</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='va'>batch_size</span><span class='op'>)</span>

<span class='va'>ds_test</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h3 id="autoencoder">Autoencoder</h3>
<p>With newer versions of TensorFlow (&gt;= 2.0, certainly if &gt;= 2.2), autoencoder-like models are best coded as custom models, and trained in an autographed loop.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>The encoder is centered around a single LSTM layer, whose size determines the maximum dimensionality of the attractor. The decoder then undoes the compression  again, mainly using a single LSTM.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='co'># size of the latent code</span>
<span class='va'>n_latent</span> <span class='op'>&lt;-</span> <span class='fl'>10L</span>
<span class='va'>n_features</span> <span class='op'>&lt;-</span> <span class='fl'>1</span>

<span class='va'>encoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,
                          <span class='va'>n_features</span>,
                          <span class='va'>n_latent</span>,
                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm</span> <span class='op'>&lt;-</span>  <span class='fu'>layer_lstm</span><span class='op'>(</span>
      units <span class='op'>=</span> <span class='va'>n_latent</span>,
      input_shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span><span class='op'>)</span>,
      return_sequences <span class='op'>=</span> <span class='cn'>FALSE</span>
    <span class='op'>)</span> 
    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span>
    
    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>x</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm</span><span class='op'>(</span><span class='op'>)</span> 
    <span class='op'>}</span>
  <span class='op'>}</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='va'>decoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,
                          <span class='va'>n_features</span>,
                          <span class='va'>n_latent</span>,
                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>repeat_vector</span> <span class='op'>&lt;-</span> <span class='fu'>layer_repeat_vector</span><span class='op'>(</span>n <span class='op'>=</span> <span class='va'>n_timesteps</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_lstm</span><span class='op'>(</span>
        units <span class='op'>=</span> <span class='va'>n_latent</span>,
        return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span>,
        go_backwards <span class='op'>=</span> <span class='cn'>TRUE</span>
      <span class='op'>)</span> 
    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>elu</span> <span class='op'>&lt;-</span> <span class='fu'>layer_activation_elu</span><span class='op'>(</span><span class='op'>)</span> 
    <span class='va'>self</span><span class='op'>$</span><span class='va'>time_distributed</span> <span class='op'>&lt;-</span> <span class='fu'>time_distributed</span><span class='op'>(</span>layer <span class='op'>=</span> <span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='va'>n_features</span><span class='op'>)</span><span class='op'>)</span>
    
    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>x</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>repeat_vector</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>elu</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
        <span class='va'>self</span><span class='op'>$</span><span class='fu'>time_distributed</span><span class='op'>(</span><span class='op'>)</span>
    <span class='op'>}</span>
  <span class='op'>}</span><span class='op'>)</span>
<span class='op'>}</span>


<span class='va'>encoder</span> <span class='op'>&lt;-</span> <span class='fu'>encoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_latent</span><span class='op'>)</span>
<span class='va'>decoder</span> <span class='op'>&lt;-</span> <span class='fu'>decoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_latent</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h3 id="loss">Loss</h3>
<p>As already explained above, the loss function we train with is twofold. On the one hand, we compare the original inputs with the decoder outputs (the reconstruction), using mean squared error:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>mse_loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='fu'>MeanSquaredError</span><span class='op'>(</span>
  reduction <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='va'>Reduction</span><span class='op'>$</span><span class='va'>SUM</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>In addition, we try to keep the number of false neighbors small, by means of the following regularizer.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>loss_false_nn</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
 
  <span class='co'># original values used in Kennel et al. (1992)</span>
  <span class='va'>rtol</span> <span class='op'>&lt;-</span> <span class='fl'>10</span> 
  <span class='va'>atol</span> <span class='op'>&lt;-</span> <span class='fl'>2</span>
  <span class='va'>k_frac</span> <span class='op'>&lt;-</span> <span class='fl'>0.01</span>
  
  <span class='va'>k</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>max</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>k_frac</span> <span class='op'>*</span> <span class='va'>batch_size</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>tri_mask</span> <span class='op'>&lt;-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='va'>linalg</span><span class='op'>$</span><span class='fu'>band_part</span><span class='op'>(</span>
      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>ones</span><span class='op'>(</span>
        shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>n_latent</span><span class='op'>)</span>,
        dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span>
      <span class='op'>)</span>,
      num_lower <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span>,
      num_upper <span class='op'>=</span> <span class='fl'>0L</span>
    <span class='op'>)</span>
  
   <span class='va'>batch_masked</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span>
     <span class='va'>tri_mask</span><span class='op'>[</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>,<span class='op'>]</span>, <span class='va'>x</span><span class='op'>[</span><span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>]</span>
   <span class='op'>)</span>
  
  <span class='va'>x_squared</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span>
    <span class='va'>batch_masked</span> <span class='op'>*</span> <span class='va'>batch_masked</span>,
    axis <span class='op'>=</span> <span class='fl'>2L</span>,
    keepdims <span class='op'>=</span> <span class='cn'>TRUE</span>
  <span class='op'>)</span>

  <span class='va'>pdist_vector</span> <span class='op'>&lt;-</span> <span class='va'>x_squared</span> <span class='op'>+</span>
  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span>
    <span class='va'>x_squared</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span>
  <span class='op'>)</span> <span class='op'>-</span>
  <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span>
    <span class='va'>batch_masked</span>,
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span><span class='va'>batch_masked</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>)</span>

  <span class='va'>all_dists</span> <span class='op'>&lt;-</span> <span class='va'>pdist_vector</span>
  <span class='va'>all_ra</span> <span class='op'>&lt;-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>/</span> <span class='op'>(</span>
      <span class='va'>batch_size</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>range</span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>n_latent</span>, dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>
    <span class='op'>)</span><span class='op'>)</span> <span class='op'>*</span>
      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span>
        <span class='va'>batch_masked</span> <span class='op'>-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>batch_masked</span>, axis <span class='op'>=</span> <span class='fl'>1L</span>, keepdims <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
      <span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>all_dists</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>clip_by_value</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='fl'>1e-14</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_max</span><span class='op'>(</span><span class='va'>all_dists</span><span class='op'>)</span><span class='op'>)</span>

  <span class='va'>top_k</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>top_k</span><span class='op'>(</span><span class='op'>-</span><span class='va'>all_dists</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>1</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>top_indices</span> <span class='op'>&lt;-</span> <span class='va'>top_k</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>

  <span class='va'>neighbor_dists_d</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='va'>top_indices</span>, batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span><span class='op'>)</span>
  
  <span class='va'>neighbor_new_dists</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span>
    <span class='va'>all_dists</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>1</span>, , <span class='op'>]</span>,
    <span class='va'>top_indices</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span>,
    batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span>
  <span class='op'>)</span>
  
  <span class='co'># Eq. 4 of Kennel et al. (1992)</span>
  <span class='va'>scaled_dist</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_new_dists</span><span class='op'>)</span> <span class='op'>-</span>
      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>/</span>
      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span>
  <span class='op'>)</span>
  
  <span class='co'># Kennel condition #1</span>
  <span class='va'>is_false_change</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='va'>scaled_dist</span> <span class='op'>&gt;</span> <span class='va'>rtol</span><span class='op'>)</span>
  <span class='co'># Kennel condition #2</span>
  <span class='va'>is_large_jump</span> <span class='op'>&lt;-</span>
    <span class='op'>(</span><span class='va'>neighbor_new_dists</span> <span class='op'>&gt;</span> <span class='va'>atol</span> <span class='op'>*</span> <span class='va'>all_ra</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span><span class='op'>]</span><span class='op'>)</span>
  
  <span class='va'>is_false_neighbor</span> <span class='op'>&lt;-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>logical_or</span><span class='op'>(</span><span class='va'>is_false_change</span>, <span class='va'>is_large_jump</span><span class='op'>)</span>
  
  <span class='va'>total_false_neighbors</span> <span class='op'>&lt;-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>is_false_neighbor</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>[</span><span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span>, <span class='fl'>2</span><span class='op'>:</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span>
  
  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span> <span class='fl'>1</span> <span class='op'>-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>total_false_neighbors</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>pad</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>activations_batch_averaged</span> <span class='op'>&lt;-</span>
    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='va'>activations_batch_averaged</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>loss</span>
  
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>MSE and FNN are added , with FNN loss weighted according to the essential hyperparameter of this model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>fnn_weight</span> <span class='op'>&lt;-</span> <span class='fl'>10</span>
</code></pre>
</div>
</div>
<p>This value was experimentally chosen as the one best conforming to our <em>look-for-the-highest-drop</em> heuristic.</p>
<h3 id="model-training">Model training</h3>
<p>The training loop closely follows the aforementioned <a href="https://tensorflow.rstudio.com/tutorials/advanced/">recipe</a> on how to train with custom models and <code>tfautograph</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_loss'</span><span class='op'>)</span>
<span class='va'>train_fnn</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_fnn'</span><span class='op'>)</span>
<span class='va'>train_mse</span> <span class='op'>&lt;-</span>  <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_mse'</span><span class='op'>)</span>

<span class='va'>train_step</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span> <span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>GradientTape</span><span class='op'>(</span>persistent <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'>%as%</span> <span class='va'>tape</span>, <span class='op'>{</span>
    
    <span class='va'>code</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span>
    <span class='va'>reconstructed</span> <span class='op'>&lt;-</span> <span class='fu'>decoder</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span>
    
    <span class='va'>l_mse</span> <span class='op'>&lt;-</span> <span class='fu'>mse_loss</span><span class='op'>(</span><span class='va'>batch</span>, <span class='va'>reconstructed</span><span class='op'>)</span>
    <span class='va'>l_fnn</span> <span class='op'>&lt;-</span> <span class='fu'>loss_false_nn</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span>
    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>l_mse</span> <span class='op'>+</span> <span class='va'>fnn_weight</span> <span class='op'>*</span> <span class='va'>l_fnn</span>
    
  <span class='op'>}</span><span class='op'>)</span>
  
  <span class='va'>encoder_gradients</span> <span class='op'>&lt;-</span> <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span>
  <span class='va'>decoder_gradients</span> <span class='op'>&lt;-</span> <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span>
  
  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span>
    <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>encoder_gradients</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>)</span>
  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span>
    <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>decoder_gradients</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>)</span>
  
  <span class='fu'>train_loss</span><span class='op'>(</span><span class='va'>loss</span><span class='op'>)</span>
  <span class='fu'>train_mse</span><span class='op'>(</span><span class='va'>l_mse</span><span class='op'>)</span>
  <span class='fu'>train_fnn</span><span class='op'>(</span><span class='va'>l_fnn</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='va'>training_loop</span> <span class='op'>&lt;-</span> <span class='fu'>tf_function</span><span class='op'>(</span><span class='fu'>autograph</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>batch</span> <span class='kw'>in</span> <span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='fu'>train_step</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span>
  <span class='op'>}</span>
  
  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"Loss: "</span>, <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"MSE: "</span>, <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"FNN loss: "</span>, <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span>
  
<span class='op'>}</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optimizer_adam</span><span class='op'>(</span>lr <span class='op'>=</span> <span class='fl'>1e-3</span><span class='op'>)</span>

<span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>200</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='st'>"Epoch: "</span>, <span class='va'>epoch</span>, <span class='st'>" -----------\n"</span><span class='op'>)</span>
  <span class='fu'>training_loop</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span>  
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>After two hundred epochs, overall loss is at 2.67, with the MSE component at 1.8 and FNN at 0.09.</p>
<h3 id="obtaining-the-attractor-from-the-test-set">Obtaining the attractor from the test set</h3>
<p>We use the test set to inspect the latent code:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>test_batch</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/iterate.html'>as_iterator</a></span><span class='op'>(</span><span class='va'>ds_test</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/pkg/reticulate/man/iterate.html'>iter_next</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='va'>predicted</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>test_batch</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='va'>predicted</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span>

<span class='va'>predicted</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 6,242 x 10
      V1    V2         V3        V4        V5         V6        V7        V8       V9       V10
   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 0.439 0.401 -0.000614  -0.0258   -0.00176  -0.0000276  0.000276  0.00677  -0.0239   0.00906 
 2 0.415 0.504  0.0000481 -0.0279   -0.00435  -0.0000970  0.000921  0.00509  -0.0214   0.00921 
 3 0.389 0.619  0.000848  -0.0240   -0.00661  -0.000171   0.00106   0.00454  -0.0150   0.00794 
 4 0.363 0.729  0.00137   -0.0143   -0.00652  -0.000244   0.000523  0.00450  -0.00594  0.00476 
 5 0.335 0.809  0.00128   -0.000450 -0.00338  -0.000307  -0.000561  0.00407   0.00394 -0.000127
 6 0.304 0.828  0.000631   0.0126    0.000889 -0.000351  -0.00167   0.00250   0.0115  -0.00487 
 7 0.274 0.769 -0.000202   0.0195    0.00403  -0.000367  -0.00220  -0.000308  0.0145  -0.00726 
 8 0.246 0.657 -0.000865   0.0196    0.00558  -0.000359  -0.00208  -0.00376   0.0134  -0.00709 
 9 0.224 0.535 -0.00121    0.0162    0.00608  -0.000335  -0.00169  -0.00697   0.0106  -0.00576 
10 0.211 0.434 -0.00129    0.0129    0.00606  -0.000306  -0.00134  -0.00927   0.00820 -0.00447 
#  with 6,232 more rows</code></pre>
<p>As a result of the FNN regularizer, the latent code units should be ordered roughly by decreasing variance, with a sharp drop appearing some place (if the FNN weight has been chosen adequately).</p>
<p>For an <code>fnn_weight</code> of 10, we do see a drop after the first two units:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span class='va'>predicted</span> <span class='op'>%&gt;%</span> <span class='fu'>summarise_all</span><span class='op'>(</span><span class='va'>var</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<pre><code># A tibble: 1 x 10
      V1     V2      V3      V4      V5      V6      V7      V8      V9     V10
   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
1 0.0739 0.0582 1.12e-6 3.13e-4 1.43e-5 1.52e-8 1.35e-6 1.86e-4 1.67e-4 4.39e-5</code></pre>
<p>So the model indicates that the Lorenz attractor can be represented in two dimensions. If we nonetheless want to plot the complete (reconstructed) state space of three dimensions, we should reorder the remaining variables by magnitude of variance<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Here, this results in three projections of the set <code>V1</code>, <code>V2</code> and <code>V4</code>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<img src="images/predicted_attractors.png" alt="Attractors as predicted from the latent code (test set). The three highest-variance variables were chosen." width="500" />
<p class="caption">
Figure 10: Attractors as predicted from the latent code (test set). The three highest-variance variables were chosen.
</p>
</div>
</div>
<h2 id="wrapping-up-for-this-time">Wrapping up (for this time)</h2>
<p>At this point, weve seen how to reconstruct the Lorenz attractor from data we did not train on (the test set), using an autoencoder regularized by a custom <em>false nearest neighbors</em> loss. It is important to stress that at no point was the network presented with the expected solution (attractor)  training was purely unsupervised.</p>
<p>This is a fascinating result. Of course, thinking practically, the next step is to obtain predictions on heldout data. Given how long this text has become already, we reserve that for a follow-up post. And again <em>of course</em>, were thinking about other datasets, especially ones where the true state space is not known beforehand. What about measurement noise? What about datasets that are not completely deterministic<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>? There is a lot to explore, stay tuned  and as always, thanks for reading!</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-gilpin2020deep">
<p>Gilpin, William. 2020. Deep Reconstruction of Strange Attractors from Time Series. <a href="http://arxiv.org/abs/2002.05909">http://arxiv.org/abs/2002.05909</a>.</p>
</div>
<div id="ref-Kantz">
<p>Kantz, Holger, and Thomas Schreiber. 2004. <em>Nonlinear Time Series Analysis</em>. Cambridge University Press.</p>
</div>
<div id="ref-PhysRevA.45.3403">
<p>Kennel, Matthew B., Reggie Brown, and Henry D. I. Abarbanel. 1992. Determining Embedding Dimension for Phase-Space Reconstruction Using a Geometrical Construction. <em>Phys. Rev. A</em> 45 (6): 340311. <a href="https://doi.org/10.1103/PhysRevA.45.3403">https://doi.org/10.1103/PhysRevA.45.3403</a>.</p>
</div>
<div id="ref-embedology">
<p>Sauer, Tim, James A. Yorke, and Martin Casdagli. 1991. Embedology. <em>Journal of Statistical Physics</em> 65 (3-4): 579616. <a href="https://doi.org/10.1007/BF01053745">https://doi.org/10.1007/BF01053745</a>.</p>
</div>
<div id="ref-Gilbert">
<p>Strang, Gilbert. 2019. <em>Linear Algebra and Learning from Data</em>. Wellesley Cambridge Press.</p>
</div>
<div id="ref-Strogatz">
<p>Strogatz, Steven. 2015. <em>Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering</em>. Westview Press.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>For many popular activation functions at least (such as ReLU). See e.g.<span class="citation" data-cites="Gilbert">(Strang <a href="#ref-Gilbert" role="doc-biblioref">2019</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn2" role="doc-endnote"><p>The paper is also accompanied by a <a href="https://github.com/williamgilpin/fnn">Python implementation</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn3" role="doc-endnote"><p>To people who want to learn more about this topic, the usual recommendation is <span class="citation" data-cites="Strogatz">(Strogatz <a href="#ref-Strogatz" role="doc-biblioref">2015</a>)</span>. Personally I prefer another source, which I cant recommend highly enough: Santa Fe Institutes <a href="https://www.complexityexplorer.org/courses/100-nonlinear-dynamics-mathematical-and-computational-approaches">Nonlinear Dynamics: Mathematical and Computational Approaches</a>, taught by Liz Bradley.<a href="#fnref3" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn4" role="doc-endnote"><p>See e.g.<a href="https://en.wikipedia.org/wiki/Butterfly_effect">Wikipedia</a> for some history and links to sources.<a href="#fnref4" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn5" role="doc-endnote"><p>In discrete systems, like the logistic map, a single dimension is enough.<a href="#fnref5" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn6" role="doc-endnote"><p>See the <a href="https://tensorflow.rstudio.com/tutorials/advanced/">custom training tutorial</a> for a blueprint.<a href="#fnref6" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn7" role="doc-endnote"><p>See the appendix of <span class="citation" data-cites="gilpin2020deep">(Gilpin <a href="#ref-gilpin2020deep" role="doc-biblioref">2020</a>)</span> for a pseudocode-like documentation.<a href="#fnref7" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn8" role="doc-endnote"><p>As per author recommendation (personal communication).<a href="#fnref8" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn9" role="doc-endnote"><p>See <span class="citation" data-cites="Kantz">(Kantz and Schreiber <a href="#ref-Kantz" role="doc-biblioref">2004</a>)</span> for detailed discussions on using methodology from nonlinear deterministic systems analysis for noisy and/or partly-stochastic data.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<a href="#fnref9" class="footnote-back" role="doc-backlink"></a></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-06-24-deep-attractors/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Deep%20attractors%3A%20Where%20deep%20learning%20meets%20chaos&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-06-24-deep-attractors%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-06-24-deep-attractors%2F&amp;title=Deep%20attractors%3A%20Where%20deep%20learning%20meets%20chaos">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/';
  this.page.identifier = 'posts/2020-06-24-deep-attractors/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2020, June 24). RStudio AI Blog: Deep attractors: Where deep learning meets chaos. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanadeepattractors,
  author = {Keydana, Sigrid},
  title = {RStudio AI Blog: Deep attractors: Where deep learning meets chaos},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
