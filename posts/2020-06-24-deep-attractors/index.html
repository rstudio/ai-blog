<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
<title>Posit AI Blog: Deep attractors: Where deep learning meets chaos</title>

<meta property="description" itemprop="description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-06-24"/>
<meta property="article:created" itemprop="dateCreated" content="2020-06-24"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Posit AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/images/x_z.gif"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Posit AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Posit AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta property="twitter:description" content="In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/images/x_z.gif"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Posit AI Blog: Deep attractors: Where deep learning meets chaos"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/06/24"/>
<meta name="citation_publication_date" content="2020/06/24"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Deep reconstruction of strange attractors from time series;citation_author=William Gilpin"/>
  <meta name="citation_reference" content="citation_title=Determining embedding dimension for phase-space reconstruction using a geometrical construction;citation_publisher=American Physical Society;citation_volume=45;citation_doi=10.1103/PhysRevA.45.3403;citation_author=Matthew B. Kennel;citation_author=Reggie Brown;citation_author=Henry D. I. Abarbanel"/>
  <meta name="citation_reference" content="citation_title=Linear algebra and learning from data;citation_publisher=Wellesley Cambridge Press;citation_author=Gilbert Strang"/>
  <meta name="citation_reference" content="citation_title=Nonlinear dynamics and chaos: With applications to physics, biology, chemistry, and engineering;citation_publisher=Westview Press;citation_author=Steven Strogatz"/>
  <meta name="citation_reference" content="citation_title=Nonlinear time series analysis;citation_publisher=Cambridge University Press;citation_author=Holger Kantz;citation_author=Thomas Schreiber"/>
  <meta name="citation_reference" content="citation_title=Embedology;citation_volume=65;citation_doi=10.1007/BF01053745;citation_author=Tim Sauer;citation_author=James A. Yorke;citation_author=Martin Casdagli"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","bibliography","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Deep attractors: Where deep learning meets chaos"]},{"type":"character","attributes":{},"value":["In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanadeepattractors"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["06-24-2020"]},{"type":"character","attributes":{},"value":["R","TensorFlow/Keras","Time Series","Generative Models"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/x_z.gif"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","deep_attractors_files/bowser-1.9.3/bowser.min.js","deep_attractors_files/distill-2.2.21/template.v2.js","deep_attractors_files/header-attrs-2.1/header-attrs.js","deep_attractors_files/header-attrs-2.2/header-attrs.js","deep_attractors_files/header-attrs-2.3/header-attrs.js","deep_attractors_files/jquery-1.11.3/jquery.min.js","deep_attractors_files/webcomponents-2.0.0/webcomponents.js","images/2cycle.png","images/chaos.png","images/chaos2.png","images/chaos3.png","images/fnn.png","images/lorenz_attractors.png","images/lorenz_attractors.xcf","images/obs.png","images/predicted_attractors.png","images/single_fixedpoint.png","images/x_z.gif"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

hr.section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  margin: 0px;
}


d-byline {
  border-top: none;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
  border-top: none;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

/* tweak for Pandoc numbered line within distill */
d-article pre.numberSource code > span {
    left: -2em;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // separator
  var separator = '<hr class="section-separator" style="clear: both"/>';
  // prepend separator above appendix
  $('.d-byline').before(separator);
  $('.d-article').before(separator);

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme, except when numbering line
  // in code chunk
  $('pre:not(.numberLines) code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      var author_name = front_matter.authors[i].author
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.26/header-attrs.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script defer data-domain="blogs.rstudio.com" src="https://plausible.io/js/plausible.js"></script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Deep attractors: Where deep learning meets chaos","description":"In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-06-24T00:00:00.000+00:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/posit.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Deep attractors: Where deep learning meets chaos</h1>

<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
  <a href="../../index.html#category:Time_Series" class="dt-tag">Time Series</a>
  <a href="../../index.html#category:Generative_Models" class="dt-tag">Generative Models</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>06-24-2020
</div>

<div class="d-article">
<p>For us deep learning practitioners, the world is – not flat, but – linear, mostly. Or piecewise linear.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Like other
linear approximations, or maybe even more so, deep learning can be incredibly successful at making predictions. But let’s
admit it – sometimes we just miss the thrill of the nonlinear, of good, old, deterministic-yet-unpredictable chaos. Can we
have both? It looks like we can. In this post, we’ll see an application of deep learning (DL) to nonlinear time series
prediction – or rather, the essential step that predates it: reconstructing the attractor underlying its dynamics. While this
post is an introduction, presenting the topic from scratch, further posts will build on this and extrapolate to observational
datasets.</p>
<h3 id="what-to-expect-from-this-post">What to expect from this post</h3>
<p>In his 2020 paper <em>Deep reconstruction of strange attractors from time series</em> <span class="citation" data-cites="gilpin2020deep">(<a href="#ref-gilpin2020deep" role="doc-biblioref">Gilpin 2020</a>)</span>, William Gilpin uses an
autoencoder architecture, combined with a regularizer implementing the <em>false nearest neighbors</em> statistic
<span class="citation" data-cites="PhysRevA.45.3403">(<a href="#ref-PhysRevA.45.3403" role="doc-biblioref">Kennel, Brown, and Abarbanel 1992</a>)</span>, to reconstruct attractors from univariate observations of multivariate, nonlinear dynamical systems. If
you feel you completely understand the sentence you just read, you may as well directly jump to the paper – come back for the
code though<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. If, on the other hand, you’re more familiar with the chaos on your desk (extrapolating … apologies) than
<em>chaos theory chaos</em>, read on. Here, we’ll first go into what it’s all about<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, and then, show an example application,
featuring Edward Lorenz’s famous butterfly attractor. While this initial post is primarily supposed to be a fun introduction
to a fascinating topic, we hope to follow up with applications to real-world datasets in the future.</p>
<h2 id="rabbits-butterflies-and-low-dimensional-projections-our-problem-statement-in-context">Rabbits, butterflies, and low-dimensional projections: Our problem statement in context</h2>
<p>In curious misalignment with how we use “chaos” in day-to-day language, chaos, the technical concept, is very different from
stochasticity, or randomness. Chaos may emerge from purely deterministic processes - very simplistic ones, even. Let’s see
how; with rabbits.</p>
<h3 id="rabbits-or-sensitive-dependence-on-initial-conditions">Rabbits, or: Sensitive dependence on initial conditions</h3>
<p>You may be familiar with the <em>logistic</em> equation, used as a toy model for population growth. Often it’s written like this –
with <span class="math inline">\(x\)</span> being the size of the population, expressed as a fraction of the maximal size (a fraction of possible rabbits, thus),
and <span class="math inline">\(r\)</span> being the growth rate (the rate at which rabbits reproduce):</p>
<p><span class="math display">\[
x_{n + 1} = r \ x_n \ (1 - x_n)
\]</span></p>
<p>This equation describes an <em>iterated map</em> over discrete timesteps <span class="math inline">\(n\)</span>. Its repeated application results in a <em>trajectory</em>
describing how the population of rabbits evolves. Maps can have <em>fixed points</em>, states where further function application goes
on producing the same result forever. Example-wise, say the growth rate amounts to <span class="math inline">\(2.1\)</span>, and we start at two (pretty
different!) initial values, <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.8\)</span>. Both trajectories arrive at a fixed point – the same fixed point – in fewer
than 10 iterations. Were we asked to predict the population size after a hundred iterations, we could make a very confident
guess, whatever the of starting value. (If the initial value is <span class="math inline">\(0\)</span>, we stay at <span class="math inline">\(0\)</span>, but we can be pretty certain of that as
well.)</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-1"></span>
<img src="images/single_fixedpoint.png" alt="Trajectory of the logistic map for r = 2.1 and two different initial values." width="600" />
<p class="caption">
Figure 1: Trajectory of the logistic map for r = 2.1 and two different initial values.
</p>
</div>
</div>
<p>What if the growth rate were somewhat higher, at <span class="math inline">\(3.3\)</span>, say? Again, we immediately compare trajectories resulting from initial
values <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.9\)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="images/2cycle.png" alt="Trajectory of the logistic map for r = 3.3 and two different initial values." width="500" />
<p class="caption">
Figure 2: Trajectory of the logistic map for r = 3.3 and two different initial values.
</p>
</div>
</div>
<p>This time, don’t see a single fixed point, but a <em>two-cycle</em>: As the trajectories stabilize, population size inevitably is at
one of two possible values – either too many rabbits or too few, you could say. The two trajectories are phase-shifted, but
again, the attracting values – the <em>attractor</em> – is shared by both initial conditions. So still, predictability is pretty
high. But we haven’t seen everything yet.</p>
<p>Let’s again enhance the growth rate some. Now <em>this</em> (literally) is chaos:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-3"></span>
<img src="images/chaos.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.9." width="500" />
<p class="caption">
Figure 3: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.9.
</p>
</div>
</div>
<p>Even after a hundred iterations, there is no set of values the trajectories recur to. We can’t be confident about any
prediction we might make.</p>
<p>Or can we? After all, we have the governing equation, which is deterministic. So we should be able to calculate the size of
the population at, say, time <span class="math inline">\(150\)</span>? In principle, yes; but this presupposes we have an accurate measurement for the starting
state.</p>
<p>How accurate? Let’s compare trajectories for initial values <span class="math inline">\(0.3\)</span> and <span class="math inline">\(0.301\)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="images/chaos2.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.301." width="500" />
<p class="caption">
Figure 4: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.301.
</p>
</div>
</div>
<p>At first, trajectories seem to jump around in unison; but during the second dozen iterations already, they dissociate more and
more, and increasingly, all bets are off. What if initial values are <em>really</em> close, as in, <span class="math inline">\(0.3\)</span> vs. <span class="math inline">\(0.30000001\)</span>?</p>
<p>It just takes a bit longer for the disassociation to surface.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-5"></span>
<img src="images/chaos3.png" alt="Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.30000001." width="600" />
<p class="caption">
Figure 5: Trajectory of the logistic map for r = 3.6 and two different initial values, 0.3 and 0.30000001.
</p>
</div>
</div>
<p>What we’re seeing here is <em>sensitive dependence on initial conditions</em>, an essential precondition for a system to be chaotic.
In an nutshell: Chaos arises when a <em>deterministic</em> system shows <em>sensitive dependence on initial conditions</em>. Or as Edward
Lorenz <a href="https://en.wikipedia.org/wiki/Chaos_theory">is said to have put it</a>,</p>
<blockquote>
<p>When the present determines the future, but the approximate present does not approximately determine the future.</p>
</blockquote>
<p>Now if these unstructured, random-looking point clouds constitute chaos, what with the all-but-amorphous butterfly (to be
displayed very soon)?</p>
<h3 id="butterflies-or-attractors-and-strange-attractors">Butterflies, or: Attractors and strange attractors</h3>
<p>Actually, in the context of chaos theory, the term butterfly may be encountered in different contexts.</p>
<p>Firstly, as so-called “butterfly effect,” it is an instantiation of the templatic phrase “the flap of a butterfly’s wing in
_________ profoundly affects the course of the weather in _________.”<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> In this usage, it is mostly a
metaphor for sensitive dependence on initial conditions.</p>
<p>Secondly, the existence of this metaphor led to a Rorschach-test-like identification with two-dimensional visualizations of
attractors of the Lorenz system. The Lorenz system is a set of three first-order differential equations designed to describe
<a href="https://en.wikipedia.org/wiki/Atmospheric_convection">atmospheric convection</a>:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{dx}{dt} = \sigma (y - x)\\
&amp; \frac{dy}{dt} = \rho x - x z - y\\
&amp; \frac{dz}{dt} = x y - \beta z
\end{aligned}
\]</span></p>
<p>This set of equations is nonlinear, as required for chaotic behavior to appear. It also has the required dimensionality, which
for smooth, continuous systems, is at least 3<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. Whether we actually see chaotic attractors – among which, the butterfly –
depends on the settings of the parameters <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\rho\)</span> and <span class="math inline">\(\beta\)</span>. For the values conventionally chosen, <span class="math inline">\(\sigma=10\)</span>,
<span class="math inline">\(\rho=28\)</span>, and <span class="math inline">\(\beta=8/3\)</span> , we see it when projecting the trajectory on the <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span> axes:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-6"></span>
<img src="images/lorenz_attractors.png" alt="Two-dimensional projections of the Lorenz attractor for sigma = 10, rho = 28, beta = 8 / 3. On the right: the butterfly." width="500" />
<p class="caption">
Figure 6: Two-dimensional projections of the Lorenz attractor for sigma = 10, rho = 28, beta = 8 / 3. On the right: the butterfly.
</p>
</div>
</div>
<p>The butterfly is an <em>attractor</em> (as are the other two projections), but it is neither a point nor a cycle. It is an attractor
in the sense that starting from a variety of different initial values, we end up in some sub-region of the state space, and we
don’t get to escape no more. This is easier to see when watching evolution over time, as in this animation:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-7"></span>
<img src="images/x_z.gif" alt="How the Lorenz attractor traces out the famous &quot;butterfly&quot; shape."  />
<p class="caption">
Figure 7: How the Lorenz attractor traces out the famous “butterfly” shape.
</p>
</div>
</div>
<p>Now, to plot the attractor in two dimensions, we threw away the third. But in “real life,” we don’t usually have too <em>much</em>
information (although it may sometimes seem like we had). We might have a lot of measurements, but these don’t usually reflect
the actual state variables we’re interested in. In these cases, we may want to actually <em>add</em> information.</p>
<h3 id="embeddings-as-a-non-dl-term-or-undoing-the-projection">Embeddings (as a non-DL term), or: Undoing the projection</h3>
<p>Assume that instead of all three variables of the Lorenz system, we had measured just one: <span class="math inline">\(x\)</span>, the rate of convection. Often
in nonlinear dynamics, the technique of delay coordinate embedding <span class="citation" data-cites="embedology">(<a href="#ref-embedology" role="doc-biblioref">Sauer, Yorke, and Casdagli 1991</a>)</span> is used to enhance a series of univariate
measurements.</p>
<p>In this method – or family of methods – the univariate series is augmented by time-shifted copies of itself. There are two
decisions to be made: How many copies to add, and how big the delay should be. To illustrate, if we had a scalar series,</p>
<pre><code>1 2 3 4 5 6 7 8 9 10 11 ...</code></pre>
<p>a three-dimensional embedding with time delay 2 would look like this:</p>
<pre><code>1 3 5
2 4 6
3 5 7
4 6 8
5 7 9
6 8 10
7 9 11
...</code></pre>
<p>Of the two decisions to be made – number of shifted series and time lag – the first is a decision on the dimensionality of
the reconstruction space. Various theorems, such as <a href="https://en.wikipedia.org/wiki/Takens%27s_theorem">Taken's theorem</a>,
indicate bounds on the number of dimensions required, provided the dimensionality of the true state space is known – which,
in real-world applications, often is not the case.The second has been of little interest to mathematicians, but is important
in practice. In fact, Kantz and Schreiber <span class="citation" data-cites="Kantz">(<a href="#ref-Kantz" role="doc-biblioref">Kantz and Schreiber 2004</a>)</span> argue that in practice, it is the product of both parameters that matters,
as it indicates the time span represented by an embedding vector.</p>
<p>How are these parameters chosen? Regarding reconstruction dimensionality, the reasoning goes that even in chaotic systems,
points that are close in state space at time <span class="math inline">\(t\)</span> should still be close at time <span class="math inline">\(t + \Delta t\)</span>, provided <span class="math inline">\(\Delta t\)</span> is very
small. So say we have two points that are close, by some metric, when represented in two-dimensional space. But in three
dimensions, that is, if we don’t “project away” the third dimension, they are a lot more distant. As illustrated in
<span class="citation" data-cites="gilpin2020deep">(<a href="#ref-gilpin2020deep" role="doc-biblioref">Gilpin 2020</a>)</span>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="images/fnn.png" alt="In the two-dimensional projection on axes x and y, the red points are close neighbors. In 3d, however, they are separate. Compare with the blue points, which stay close even in higher-dimensional space. Figure from Gilpin (2020)." width="380" />
<p class="caption">
Figure 8: In the two-dimensional projection on axes x and y, the red points are close neighbors. In 3d, however, they are separate. Compare with the blue points, which stay close even in higher-dimensional space. Figure from Gilpin (2020).
</p>
</div>
</div>
<p>If this happens, then projecting down has eliminated some essential information. In 2d, the points were <em>false neighbors</em>. The
<em>false nearest neighbors</em> (FNN) statistic can be used to determine an adequate embedding size, like this:</p>
<p>For each point, take its closest neighbor in <span class="math inline">\(m\)</span> dimensions, and compute the ratio of their distances in <span class="math inline">\(m\)</span> and <span class="math inline">\(m+1\)</span>
dimensions. If the ratio is larger than some threshold <span class="math inline">\(t\)</span>, the neighbor was false. Sum the number of false neighbors over all
points. Do this for different <span class="math inline">\(m\)</span> and <span class="math inline">\(t\)</span>, and inspect the resulting curves.</p>
<p>At this point, let’s look ahead at the autoencoder approach. The autoencoder will use that same FNN statistic as a
regularizer, in addition to the usual autoencoder reconstruction loss. This will result in a new heuristic regarding embedding
dimensionality that involves fewer decisions.</p>
<p>Going back to the classic method for an instant, the second parameter, the time lag, is even more difficult to sort out
<span class="citation" data-cites="Kantz">(<a href="#ref-Kantz" role="doc-biblioref">Kantz and Schreiber 2004</a>)</span>. Usually, mutual information is plotted for different delays and then, the first delay where it falls below some
threshold is chosen. We don’t further elaborate on this question as it is rendered obsolete in the neural network approach.
Which we’ll see now.</p>
<h2 id="learning-the-lorenz-attractor">Learning the Lorenz attractor</h2>
<p>Our code closely follows the architecture, parameter settings, and data setup used in the <a href="https://github.com/williamgilpin/fnn">reference
implementation</a> William provided. The loss function, especially, has been ported
one-to-one.</p>
<p>The general idea is the following. An autoencoder – for example, an LSTM autoencoder as presented here – is used to compress
the univariate time series into a latent representation of some dimensionality, which will constitute an upper bound on the
dimensionality of the learned attractor. In addition to mean squared error between input and reconstructions, there will be a
second loss term, applying the FNN regularizer. This results in the latent units being roughly ordered by <em>importance</em>, as
measured by their variance. It is expected that somewhere in the listing of variances, a sharp drop will appear. The units
before the drop are then assumed to encode the <em>attractor</em> of the system in question.</p>
<p>In this setup, there is still a choice to be made: how to weight the FNN loss. One would run training for different weights
<span class="math inline">\(\lambda\)</span> and look for the drop. Surely, this could in principle be automated, but given the newness of the method – the
paper was published this year – it makes sense to focus on thorough analysis first.</p>
<h3 id="data-generation">Data generation</h3>
<p>We use the <code>deSolve</code> package to generate data from the Lorenz equations.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://desolve.r-forge.r-project.org/'>deSolve</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>parameters</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>sigma <span class='op'>=</span> <span class='fl'>10</span>,</span>
<span>                rho <span class='op'>=</span> <span class='fl'>28</span>,</span>
<span>                beta <span class='op'>=</span> <span class='fl'>8</span><span class='op'>/</span><span class='fl'>3</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>initial_state</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='op'>-</span><span class='fl'>8.60632853</span>,</span>
<span>    y <span class='op'>=</span> <span class='op'>-</span><span class='fl'>14.85273055</span>,</span>
<span>    z <span class='op'>=</span> <span class='fl'>15.53352487</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>lorenz</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>t</span>, <span class='va'>state</span>, <span class='va'>parameters</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>as.list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>parameters</span><span class='op'>)</span><span class='op'>)</span>, <span class='op'>{</span></span>
<span>    <span class='va'>dx</span> <span class='op'>&lt;-</span> <span class='va'>sigma</span> <span class='op'>*</span> <span class='op'>(</span><span class='va'>y</span> <span class='op'>-</span> <span class='va'>x</span><span class='op'>)</span></span>
<span>    <span class='va'>dy</span> <span class='op'>&lt;-</span> <span class='va'>x</span> <span class='op'>*</span> <span class='op'>(</span><span class='va'>rho</span> <span class='op'>-</span> <span class='va'>z</span><span class='op'>)</span> <span class='op'>-</span> <span class='va'>y</span></span>
<span>    <span class='va'>dz</span> <span class='op'>&lt;-</span> <span class='va'>x</span> <span class='op'>*</span> <span class='va'>y</span> <span class='op'>-</span> <span class='va'>beta</span> <span class='op'>*</span> <span class='va'>z</span></span>
<span>    </span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>dx</span>, <span class='va'>dy</span>, <span class='va'>dz</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>times</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>500</span>, length.out <span class='op'>=</span> <span class='fl'>125000</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>lorenz_ts</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>ode</span><span class='op'>(</span></span>
<span>    y <span class='op'>=</span> <span class='va'>initial_state</span>,</span>
<span>    times <span class='op'>=</span> <span class='va'>times</span>,</span>
<span>    func <span class='op'>=</span> <span class='va'>lorenz</span>,</span>
<span>    parms <span class='op'>=</span> <span class='va'>parameters</span>,</span>
<span>    method <span class='op'>=</span> <span class='st'>"lsoda"</span></span>
<span>  <span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>lorenz_ts</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>,<span class='op'>]</span></span></code></pre>
</div>
</div>
<pre><code># A tibble: 10 x 4
      time      x     y     z
     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 0        -8.61 -14.9  15.5
 2 0.00400  -8.86 -15.2  15.9
 3 0.00800  -9.12 -15.6  16.3
 4 0.0120   -9.38 -16.0  16.7
 5 0.0160   -9.64 -16.3  17.1
 6 0.0200   -9.91 -16.7  17.6
 7 0.0240  -10.2  -17.0  18.1
 8 0.0280  -10.5  -17.3  18.6
 9 0.0320  -10.7  -17.7  19.1
10 0.0360  -11.0  -18.0  19.7</code></pre>
<p>We’ve already seen the attractor, or rather, its three two-dimensional projections, in figure 6 above. But now our scenario is
different. We only have access to <span class="math inline">\(x\)</span>, a univariate time series. As the time interval used to numerically integrate the
differential equations was rather tiny, we just use every tenth observation.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>obs</span> <span class='op'>&lt;-</span> <span class='va'>lorenz_ts</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>time</span>, <span class='va'>x</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'>row_number</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/r/base/Arithmetic.html'>%%</a></span> <span class='fl'>10</span> <span class='op'>==</span> <span class='fl'>0</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'>ggplot</span><span class='op'>(</span><span class='va'>obs</span>, <span class='fu'>aes</span><span class='op'>(</span><span class='va'>time</span>, <span class='va'>x</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>geom_line</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>coord_cartesian</span><span class='op'>(</span>xlim <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>100</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>theme_classic</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="images/obs.png" alt="Convection rates as a univariate time series." width="500" />
<p class="caption">
Figure 9: Convection rates as a univariate time series.
</p>
</div>
</div>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first half of the series is used for training. The data is scaled and transformed into the three-dimensional form expected
by recurrent layers.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tensorflow.rstudio.com/'>keras</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/tfdatasets'>tfdatasets</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://t-kalinowski.github.io/tfautograph/'>tfautograph</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://rstudio.github.io/reticulate/'>reticulate</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://purrr.tidyverse.org/'>purrr</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># scale observations</span></span>
<span><span class='va'>obs</span> <span class='op'>&lt;-</span> <span class='va'>obs</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'>mutate</span><span class='op'>(</span></span>
<span>  x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/scale.html'>scale</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># generate timesteps</span></span>
<span><span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>)</span></span>
<span><span class='va'>n_timesteps</span> <span class='op'>&lt;-</span> <span class='fl'>10</span></span>
<span></span>
<span><span class='va'>gen_timesteps</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>n_timesteps</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>rbind</span>,</span>
<span>          <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_along</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>,</span>
<span>             <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>               <span class='va'>start</span> <span class='op'>&lt;-</span> <span class='va'>i</span></span>
<span>               <span class='va'>end</span> <span class='op'>&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='fl'>1</span></span>
<span>               <span class='va'>out</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>[</span><span class='va'>start</span><span class='op'>:</span><span class='va'>end</span><span class='op'>]</span></span>
<span>               <span class='va'>out</span></span>
<span>             <span class='op'>}</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/stats/na.fail.html'>na.omit</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='co'># train with start of time series, test with end of time series </span></span>
<span><span class='va'>x_train</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>$</span><span class='va'>x</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span>, <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span><span class='va'>x_test</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>obs</span><span class='op'>$</span><span class='va'>x</span><span class='op'>)</span><span class='op'>[</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>:</span><span class='va'>n</span><span class='op'>]</span>, <span class='va'>n_timesteps</span><span class='op'>)</span> </span>
<span></span>
<span><span class='co'># add required dimension for features (we have one)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># some batch size (value not crucial)</span></span>
<span><span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>100</span></span>
<span></span>
<span><span class='co'># transform to datasets so we can use custom training</span></span>
<span><span class='va'>ds_train</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='va'>batch_size</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>ds_test</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="autoencoder">Autoencoder</h3>
<p>With newer versions of TensorFlow (&gt;= 2.0, certainly if &gt;= 2.2), autoencoder-like models are best coded as custom models,
and trained in an “autographed” loop.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>The encoder is centered around a single LSTM layer, whose size determines the maximum dimensionality of the attractor. The
decoder then undoes the compression – again, mainly using a single LSTM.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># size of the latent code</span></span>
<span><span class='va'>n_latent</span> <span class='op'>&lt;-</span> <span class='fl'>10L</span></span>
<span><span class='va'>n_features</span> <span class='op'>&lt;-</span> <span class='fl'>1</span></span>
<span></span>
<span><span class='va'>encoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                          <span class='va'>n_features</span>,</span>
<span>                          <span class='va'>n_latent</span>,</span>
<span>                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm</span> <span class='op'>&lt;-</span>  <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_latent</span>,</span>
<span>      input_shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span><span class='op'>)</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span>    <span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='va'>x</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm</span><span class='op'>(</span><span class='op'>)</span> </span>
<span>    <span class='op'>}</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>decoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                          <span class='va'>n_features</span>,</span>
<span>                          <span class='va'>n_latent</span>,</span>
<span>                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>repeat_vector</span> <span class='op'>&lt;-</span> <span class='fu'>layer_repeat_vector</span><span class='op'>(</span>n <span class='op'>=</span> <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>        units <span class='op'>=</span> <span class='va'>n_latent</span>,</span>
<span>        return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>        go_backwards <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>      <span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>elu</span> <span class='op'>&lt;-</span> <span class='fu'>layer_activation_elu</span><span class='op'>(</span><span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>time_distributed</span> <span class='op'>&lt;-</span> <span class='fu'>time_distributed</span><span class='op'>(</span>layer <span class='op'>=</span> <span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='va'>n_features</span><span class='op'>)</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='va'>x</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>repeat_vector</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>elu</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>time_distributed</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='op'>}</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span></span>
<span><span class='va'>encoder</span> <span class='op'>&lt;-</span> <span class='fu'>encoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_latent</span><span class='op'>)</span></span>
<span><span class='va'>decoder</span> <span class='op'>&lt;-</span> <span class='fu'>decoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_latent</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="loss">Loss</h3>
<p>As already explained above, the loss function we train with is twofold. On the one hand, we compare the original inputs with
the decoder outputs (the reconstruction), using mean squared error:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>mse_loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='fu'>MeanSquaredError</span><span class='op'>(</span></span>
<span>  reduction <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='va'>Reduction</span><span class='op'>$</span><span class='va'>SUM</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>In addition, we try to keep the number of false neighbors small, by means of the following regularizer.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>loss_false_nn</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span></span>
<span> </span>
<span>  <span class='co'># original values used in Kennel et al. (1992)</span></span>
<span>  <span class='va'>rtol</span> <span class='op'>&lt;-</span> <span class='fl'>10</span> </span>
<span>  <span class='va'>atol</span> <span class='op'>&lt;-</span> <span class='fl'>2</span></span>
<span>  <span class='va'>k_frac</span> <span class='op'>&lt;-</span> <span class='fl'>0.01</span></span>
<span>  </span>
<span>  <span class='va'>k</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>max</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>k_frac</span> <span class='op'>*</span> <span class='va'>batch_size</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>tri_mask</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='va'>linalg</span><span class='op'>$</span><span class='fu'>band_part</span><span class='op'>(</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>ones</span><span class='op'>(</span></span>
<span>        shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>n_latent</span><span class='op'>)</span>,</span>
<span>        dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span></span>
<span>      <span class='op'>)</span>,</span>
<span>      num_lower <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span>,</span>
<span>      num_upper <span class='op'>=</span> <span class='fl'>0L</span></span>
<span>    <span class='op'>)</span></span>
<span>  </span>
<span>   <span class='va'>batch_masked</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span></span>
<span>     <span class='va'>tri_mask</span><span class='op'>[</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>,<span class='op'>]</span>, <span class='va'>x</span><span class='op'>[</span><span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rstudio.github.io/reticulate/reference/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>]</span></span>
<span>   <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>x_squared</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span></span>
<span>    <span class='va'>batch_masked</span> <span class='op'>*</span> <span class='va'>batch_masked</span>,</span>
<span>    axis <span class='op'>=</span> <span class='fl'>2L</span>,</span>
<span>    keepdims <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>  <span class='op'>)</span></span>
<span></span>
<span>  <span class='va'>pdist_vector</span> <span class='op'>&lt;-</span> <span class='va'>x_squared</span> <span class='op'>+</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span></span>
<span>    <span class='va'>x_squared</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span> <span class='op'>-</span></span>
<span>  <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span></span>
<span>    <span class='va'>batch_masked</span>,</span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span><span class='va'>batch_masked</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span></span>
<span>  <span class='va'>all_dists</span> <span class='op'>&lt;-</span> <span class='va'>pdist_vector</span></span>
<span>  <span class='va'>all_ra</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>/</span> <span class='op'>(</span></span>
<span>      <span class='va'>batch_size</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>range</span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>n_latent</span>, dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span></span>
<span>    <span class='op'>)</span><span class='op'>)</span> <span class='op'>*</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span></span>
<span>        <span class='va'>batch_masked</span> <span class='op'>-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>batch_masked</span>, axis <span class='op'>=</span> <span class='fl'>1L</span>, keepdims <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span>      <span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>all_dists</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>clip_by_value</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='fl'>1e-14</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_max</span><span class='op'>(</span><span class='va'>all_dists</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='va'>top_k</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>top_k</span><span class='op'>(</span><span class='op'>-</span><span class='va'>all_dists</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>1</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>top_indices</span> <span class='op'>&lt;-</span> <span class='va'>top_k</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span></span>
<span>  <span class='va'>neighbor_dists_d</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='va'>top_indices</span>, batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>neighbor_new_dists</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span></span>
<span>    <span class='va'>all_dists</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>1</span>, , <span class='op'>]</span>,</span>
<span>    <span class='va'>top_indices</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span>,</span>
<span>    batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span></span>
<span>  <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Eq. 4 of Kennel et al. (1992)</span></span>
<span>  <span class='va'>scaled_dist</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_new_dists</span><span class='op'>)</span> <span class='op'>-</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>/</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Kennel condition #1</span></span>
<span>  <span class='va'>is_false_change</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='va'>scaled_dist</span> <span class='op'>&gt;</span> <span class='va'>rtol</span><span class='op'>)</span></span>
<span>  <span class='co'># Kennel condition #2</span></span>
<span>  <span class='va'>is_large_jump</span> <span class='op'>&lt;-</span></span>
<span>    <span class='op'>(</span><span class='va'>neighbor_new_dists</span> <span class='op'>&gt;</span> <span class='va'>atol</span> <span class='op'>*</span> <span class='va'>all_ra</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>is_false_neighbor</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>logical_or</span><span class='op'>(</span><span class='va'>is_false_change</span>, <span class='va'>is_large_jump</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>total_false_neighbors</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>is_false_neighbor</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>[</span><span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rstudio.github.io/reticulate/reference/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span>, <span class='fl'>2</span><span class='op'>:</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span></span>
<span>  </span>
<span>  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span> <span class='fl'>1</span> <span class='op'>-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>total_false_neighbors</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>pad</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>activations_batch_averaged</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='va'>activations_batch_averaged</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span></span>
<span>  </span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>MSE and FNN are added , with FNN loss weighted according to the essential hyperparameter of this model:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>fnn_weight</span> <span class='op'>&lt;-</span> <span class='fl'>10</span></span></code></pre>
</div>
</div>
<p>This value was experimentally chosen as the one best conforming to our <em>look-for-the-highest-drop</em> heuristic.</p>
<h3 id="model-training">Model training</h3>
<p>The training loop closely follows the aforementioned <a href="https://tensorflow.rstudio.com/tutorials/advanced/">recipe</a> on how to
train with custom models and <code>tfautograph</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_loss'</span><span class='op'>)</span></span>
<span><span class='va'>train_fnn</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_fnn'</span><span class='op'>)</span></span>
<span><span class='va'>train_mse</span> <span class='op'>&lt;-</span>  <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name<span class='op'>=</span><span class='st'>'train_mse'</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>train_step</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span> <span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>GradientTape</span><span class='op'>(</span>persistent <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'><a href='https://rstudio.github.io/reticulate/reference/with-as-operator.html'>%as%</a></span> <span class='va'>tape</span>, <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>code</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span></span>
<span>    <span class='va'>reconstructed</span> <span class='op'>&lt;-</span> <span class='fu'>decoder</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>l_mse</span> <span class='op'>&lt;-</span> <span class='fu'>mse_loss</span><span class='op'>(</span><span class='va'>batch</span>, <span class='va'>reconstructed</span><span class='op'>)</span></span>
<span>    <span class='va'>l_fnn</span> <span class='op'>&lt;-</span> <span class='fu'>loss_false_nn</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>l_mse</span> <span class='op'>+</span> <span class='va'>fnn_weight</span> <span class='op'>*</span> <span class='va'>l_fnn</span></span>
<span>    </span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>encoder_gradients</span> <span class='op'>&lt;-</span> <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span></span>
<span>  <span class='va'>decoder_gradients</span> <span class='op'>&lt;-</span> <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span></span>
<span>    <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>encoder_gradients</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span></span>
<span>    <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>decoder_gradients</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'>train_loss</span><span class='op'>(</span><span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='fu'>train_mse</span><span class='op'>(</span><span class='va'>l_mse</span><span class='op'>)</span></span>
<span>  <span class='fu'>train_fnn</span><span class='op'>(</span><span class='va'>l_fnn</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>training_loop</span> <span class='op'>&lt;-</span> <span class='fu'>tf_function</span><span class='op'>(</span><span class='fu'>autograph</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>batch</span> <span class='kw'>in</span> <span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='fu'>train_step</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span></span>
<span>  </span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"Loss: "</span>, <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"MSE: "</span>, <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"FNN loss: "</span>, <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span><span class='op'>}</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optimizer_adam</span><span class='op'>(</span>lr <span class='op'>=</span> <span class='fl'>1e-3</span><span class='op'>)</span></span>
<span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>200</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='st'>"Epoch: "</span>, <span class='va'>epoch</span>, <span class='st'>" -----------\n"</span><span class='op'>)</span></span>
<span>  <span class='fu'>training_loop</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span>  </span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>After two hundred epochs, overall loss is at 2.67, with the MSE component at 1.8 and FNN at 0.09.</p>
<h3 id="obtaining-the-attractor-from-the-test-set">Obtaining the attractor from the test set</h3>
<p>We use the test set to inspect the latent code:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>test_batch</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>as_iterator</a></span><span class='op'>(</span><span class='va'>ds_test</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>iter_next</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>predicted</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>test_batch</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='va'>predicted</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>predicted</span></span></code></pre>
</div>
</div>
<pre><code># A tibble: 6,242 x 10
      V1    V2         V3        V4        V5         V6        V7        V8       V9       V10
   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
 1 0.439 0.401 -0.000614  -0.0258   -0.00176  -0.0000276  0.000276  0.00677  -0.0239   0.00906 
 2 0.415 0.504  0.0000481 -0.0279   -0.00435  -0.0000970  0.000921  0.00509  -0.0214   0.00921 
 3 0.389 0.619  0.000848  -0.0240   -0.00661  -0.000171   0.00106   0.00454  -0.0150   0.00794 
 4 0.363 0.729  0.00137   -0.0143   -0.00652  -0.000244   0.000523  0.00450  -0.00594  0.00476 
 5 0.335 0.809  0.00128   -0.000450 -0.00338  -0.000307  -0.000561  0.00407   0.00394 -0.000127
 6 0.304 0.828  0.000631   0.0126    0.000889 -0.000351  -0.00167   0.00250   0.0115  -0.00487 
 7 0.274 0.769 -0.000202   0.0195    0.00403  -0.000367  -0.00220  -0.000308  0.0145  -0.00726 
 8 0.246 0.657 -0.000865   0.0196    0.00558  -0.000359  -0.00208  -0.00376   0.0134  -0.00709 
 9 0.224 0.535 -0.00121    0.0162    0.00608  -0.000335  -0.00169  -0.00697   0.0106  -0.00576 
10 0.211 0.434 -0.00129    0.0129    0.00606  -0.000306  -0.00134  -0.00927   0.00820 -0.00447 
# … with 6,232 more rows</code></pre>
<p>As a result of the FNN regularizer, the latent code units should be ordered roughly by decreasing variance, with a sharp drop
appearing some place (if the FNN weight has been chosen adequately).</p>
<p>For an <code>fnn_weight</code> of 10, we do see a drop after the first two units:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>predicted</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'>summarise_all</span><span class='op'>(</span><span class='va'>var</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code># A tibble: 1 x 10
      V1     V2      V3      V4      V5      V6      V7      V8      V9     V10
   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
1 0.0739 0.0582 1.12e-6 3.13e-4 1.43e-5 1.52e-8 1.35e-6 1.86e-4 1.67e-4 4.39e-5</code></pre>
<p>So the model indicates that the Lorenz attractor can be represented in two dimensions. If we nonetheless want to plot the
complete (reconstructed) state space of three dimensions, we should reorder the remaining variables by magnitude of
variance<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. Here, this results in three projections of the set <code>V1</code>, <code>V2</code> and <code>V4</code>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-20"></span>
<img src="images/predicted_attractors.png" alt="Attractors as predicted from the latent code (test set). The three highest-variance variables were chosen." width="500" />
<p class="caption">
Figure 10: Attractors as predicted from the latent code (test set). The three highest-variance variables were chosen.
</p>
</div>
</div>
<h2 id="wrapping-up-for-this-time">Wrapping up (for this time)</h2>
<p>At this point, we’ve seen how to reconstruct the Lorenz attractor from data we did not train on (the test set), using an
autoencoder regularized by a custom <em>false nearest neighbors</em> loss. It is important to stress that at no point was the network
presented with the expected solution (attractor) – training was purely unsupervised.</p>
<p>This is a fascinating result. Of course, thinking practically, the next step is to obtain predictions on heldout data. Given
how long this text has become already, we reserve that for a follow-up post. And again <em>of course</em>, we’re thinking about other
datasets, especially ones where the true state space is not known beforehand. What about measurement noise? What about
datasets that are not completely deterministic<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>? There is a lot to explore, stay tuned – and as always, thanks for
reading!</p>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-gilpin2020deep" class="csl-entry" role="doc-biblioentry">
Gilpin, William. 2020. <span>“Deep Reconstruction of Strange Attractors from Time Series.”</span> <a href="https://arxiv.org/abs/2002.05909">https://arxiv.org/abs/2002.05909</a>.
</div>
<div id="ref-Kantz" class="csl-entry" role="doc-biblioentry">
Kantz, Holger, and Thomas Schreiber. 2004. <em>Nonlinear Time Series Analysis</em>. Cambridge University Press.
</div>
<div id="ref-PhysRevA.45.3403" class="csl-entry" role="doc-biblioentry">
Kennel, Matthew B., Reggie Brown, and Henry D. I. Abarbanel. 1992. <span>“Determining Embedding Dimension for Phase-Space Reconstruction Using a Geometrical Construction.”</span> <em>Phys. Rev. A</em> 45 (March): 3403–11. <a href="https://doi.org/10.1103/PhysRevA.45.3403">https://doi.org/10.1103/PhysRevA.45.3403</a>.
</div>
<div id="ref-embedology" class="csl-entry" role="doc-biblioentry">
Sauer, Tim, James A. Yorke, and Martin Casdagli. 1991. <span>“<span>Embedology</span>.”</span> <em>Journal of Statistical Physics</em> 65 (3-4): 579–616. <a href="https://doi.org/10.1007/BF01053745">https://doi.org/10.1007/BF01053745</a>.
</div>
<div id="ref-Gilbert" class="csl-entry" role="doc-biblioentry">
Strang, Gilbert. 2019. <em>Linear Algebra and Learning from Data</em>. Wellesley Cambridge Press.
</div>
<div id="ref-Strogatz" class="csl-entry" role="doc-biblioentry">
Strogatz, Steven. 2015. <em>Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry, and Engineering</em>. Westview Press.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>For many popular activation functions at least (such as ReLU). See e.g. <span class="citation" data-cites="Gilbert">(<a href="#ref-Gilbert" role="doc-biblioref">Strang 2019</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The paper is also accompanied by a <a href="https://github.com/williamgilpin/fnn">Python implementation</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>To people who want to learn more about this topic, the usual recommendation is <span class="citation" data-cites="Strogatz">(<a href="#ref-Strogatz" role="doc-biblioref">Strogatz 2015</a>)</span>. Personally I prefer another
source, which I can’t recommend highly enough: Santa Fe Institute’s <a href="https://www.complexityexplorer.org/courses/100-nonlinear-dynamics-mathematical-and-computational-approaches">Nonlinear Dynamics: Mathematical and Computational
Approaches</a>,
taught by Liz Bradley.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>See e.g. <a href="https://en.wikipedia.org/wiki/Butterfly_effect">Wikipedia</a> for some history and links to sources.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>In discrete systems, like the logistic map, a single dimension is enough.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>See the <a href="https://tensorflow.rstudio.com/tutorials/advanced/">custom training tutorial</a> for a blueprint.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>See the appendix of <span class="citation" data-cites="gilpin2020deep">(<a href="#ref-gilpin2020deep" role="doc-biblioref">Gilpin 2020</a>)</span> for a pseudocode-like documentation.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>As per author recommendation (personal communication).<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>See <span class="citation" data-cites="Kantz">(<a href="#ref-Kantz" role="doc-biblioref">Kantz and Schreiber 2004</a>)</span> for detailed discussions on using methodology from nonlinear deterministic systems analysis for noisy
and/or partly-stochastic data.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-06-24-deep-attractors/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Deep%20attractors%3A%20Where%20deep%20learning%20meets%20chaos&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-06-24-deep-attractors%2F" aria-label="share on twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-06-24-deep-attractors%2F&amp;title=Deep%20attractors%3A%20Where%20deep%20learning%20meets%20chaos" aria-label="share on linkedin">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/';
  this.page.identifier = 'posts/2020-06-24-deep-attractors/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2020, June 24). Posit AI Blog: Deep attractors: Where deep learning meets chaos. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanadeepattractors,
  author = {Keydana, Sigrid},
  title = {Posit AI Blog: Deep attractors: Where deep learning meets chaos},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
