<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
<title>Posit AI Blog: Time series prediction with FNN-LSTM</title>

<meta property="description" itemprop="description" content="In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, &quot;vanilla LSTM&quot;, FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-07-20"/>
<meta property="article:created" itemprop="dateCreated" content="2020-07-20"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Posit AI Blog: Time series prediction with FNN-LSTM"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, &quot;vanilla LSTM&quot;, FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/images/old_faithful.jpg"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Posit AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Posit AI Blog: Time series prediction with FNN-LSTM"/>
<meta property="twitter:description" content="In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, &quot;vanilla LSTM&quot;, FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/images/old_faithful.jpg"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Posit AI Blog: Time series prediction with FNN-LSTM"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/07/20"/>
<meta name="citation_publication_date" content="2020/07/20"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Deep reconstruction of strange attractors from time series;citation_author=William Gilpin"/>
  <meta name="citation_reference" content="citation_title=Nonlinear time series analysis;citation_publisher=Cambridge University Press;citation_author=Holger Kantz;citation_author=Thomas Schreiber"/>
  <meta name="citation_reference" content="citation_title=Embedology;citation_volume=65;citation_doi=10.1007/BF01053745;citation_author=Tim Sauer;citation_author=James A. Yorke;citation_author=Martin Casdagli"/>
  <meta name="citation_reference" content="citation_title=Measuring the strangeness of strange attractors;citation_volume=9;citation_doi=https://doi.org/10.1016/0167-2789(83)90298-1;citation_issn=0167-2789;citation_author=Peter Grassberger;citation_author=Itamar Procaccia"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","bibliography","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Time series prediction with FNN-LSTM"]},{"type":"character","attributes":{},"value":["In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, \"vanilla LSTM\", FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanafnnlstm"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["07-20-2020"]},{"type":"character","attributes":{},"value":["R","TensorFlow/Keras","Time Series","Generative Models"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/old_faithful.jpg"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","data/ecg.csv","data/electricity.csv","data/geyser.csv","data/mouse.csv","images/ecg_mses.png","images/ecg_predictions.png","images/ecg_ts.png","images/electricity_mses.png","images/electricity_predictions.png","images/electricity_ts.png","images/geyser_mses.png","images/geyser_preds.png","images/geyser_ts.png","images/mouse_mses.png","images/mouse_predictions.png","images/mouse_ts.png","images/old_faithful.jpg","timeseries-prediction-with-fnn-lstm_files/bowser-1.9.3/bowser.min.js","timeseries-prediction-with-fnn-lstm_files/distill-2.2.21/template.v2.js","timeseries-prediction-with-fnn-lstm_files/header-attrs-2.3/header-attrs.js","timeseries-prediction-with-fnn-lstm_files/jquery-1.11.3/jquery.min.js","timeseries-prediction-with-fnn-lstm_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.23/header-attrs.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script defer data-domain="blogs.rstudio.com" src="https://plausible.io/js/plausible.js"></script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Time series prediction with FNN-LSTM","description":"In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, \"vanilla LSTM\", FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-07-20T00:00:00.000+00:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/posit.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Time series prediction with FNN-LSTM</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:TensorFlow/Keras" class="dt-tag">TensorFlow/Keras</a>
  <a href="../../index.html#category:Time_Series" class="dt-tag">Time Series</a>
  <a href="../../index.html#category:Generative_Models" class="dt-tag">Generative Models</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, “vanilla LSTM,” FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>07-20-2020
</div>

<div class="d-article">
<p>Today, we pick up on the plan alluded to in the conclusion of the recent <a href="https://blogs.rstudio.com/ai/posts/2020-06-24-deep-attractors/">Deep attractors: Where deep learning meets
chaos</a>: employ that same technique to generate <em>forecasts</em> for
empirical time series data.</p>
<p>“That same technique,” which for conciseness, I’ll take the liberty of referring to as FNN-LSTM, is due to William Gilpin’s
2020 paper “Deep reconstruction of strange attractors from time series” <span class="citation" data-cites="gilpin2020deep">(<a href="#ref-gilpin2020deep" role="doc-biblioref">Gilpin 2020</a>)</span>.</p>
<p>In a nutshell<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, the problem addressed is as follows: A system, known or assumed to be nonlinear and highly dependent on
initial conditions, is observed, resulting in a scalar series of measurements. The measurements are not just – inevitably –
noisy, but in addition, they are – at best – a projection of a multidimensional state space onto a line.</p>
<p>Classically in nonlinear time series analysis, such scalar series of observations are augmented by supplementing, at every
point in time, delayed measurements of that same series – a technique called <em>delay coordinate embedding</em> <span class="citation" data-cites="embedology">(<a href="#ref-embedology" role="doc-biblioref">Sauer, Yorke, and Casdagli 1991</a>)</span>. For
example, instead of just a single vector <code>X1</code>, we could have a matrix of vectors <code>X1</code>, <code>X2</code>, and <code>X3</code>, with <code>X2</code> containing
the same values as <code>X1</code>, but starting from the third observation, and <code>X3</code>, from the fifth. In this case, the <em>delay</em> would be
2, and the <em>embedding dimension</em>, 3. Various <a href="https://en.wikipedia.org/wiki/Takens&#39;s_theorem">theorems</a> state that if these
parameters are chosen adequately, it is possible to reconstruct the complete state space. There is a problem though: The
theorems assume that the dimensionality of the true state space is known, which in many real-world applications, won’t be the
case.</p>
<p>This is where Gilpin’s idea comes in: Train an autoencoder, whose intermediate representation encapsulates the system’s
attractor. Not just any MSE-optimized autoencoder though. The latent representation is regularized by <em>false nearest
neighbors</em> (FNN) loss, a technique commonly used with delay coordinate embedding to determine an adequate embedding dimension.
False neighbors are those who are close in <code>n</code>-dimensional space, but significantly farther apart in <code>n+1</code>-dimensional space.
In the aforementioned introductory <a href="https://blogs.rstudio.com/ai/posts/2020-06-24-deep-attractors/">post</a>, we showed how this
technique allowed to reconstruct the attractor of the (synthetic) Lorenz system. Now, we want to move on to prediction.</p>
<p>We first describe the setup, including model definitions, training procedures, and data preparation. Then, we tell you how it
went.</p>
<h2 id="setup">Setup</h2>
<h3 id="from-reconstruction-to-forecasting-and-branching-out-into-the-real-world">From reconstruction to forecasting, and branching out into the real world</h3>
<p>In the previous post, we trained an LSTM autoencoder to generate a compressed code, representing the attractor of the system.
As usual with autoencoders, the target when training is the same as the input, meaning that overall loss consisted of two
components: The FNN loss, computed on the latent representation only, and the mean-squared-error loss between input and
output. Now for prediction, the target consists of future values, as many as we wish to predict. Put differently: The
architecture stays the same, but instead of reconstruction we perform prediction, in the standard RNN way. Where the usual RNN
setup would just directly chain the desired number of LSTMs, we have an LSTM encoder that outputs a (timestep-less) latent
code, and an LSTM decoder that starting from that code, repeated as many times as required, forecasts the required number of
future values.</p>
<p>This of course means that to evaluate forecast performance, we need to compare against an LSTM-only setup. This is exactly
what we’ll do, and comparison will turn out to be interesting not just quantitatively, but <em>qualitatively</em> as well.</p>
<p>We perform these comparisons on the four datasets Gilpin chose to demonstrate <a href="https://github.com/williamgilpin/fnn/blob/master/exploratory.ipynb">attractor reconstruction on observational
data</a>. While all of these, as is evident from the images
in that notebook, exhibit nice attractors, we’ll see that not all of them are equally suited to forecasting using simple
RNN-based architectures – with or without FNN regularization. But even those that clearly demand a different approach allow
for interesting observations as to the impact of FNN loss.</p>
<h3 id="model-definitions-and-training-setup">Model definitions and training setup</h3>
<p>In all four experiments, we use the same model definitions and training procedures, the only differing parameter being the
number of timesteps used in the LSTMs (for reasons that will become evident when we introduce the individual datasets).</p>
<p>Both architectures were chosen to be straightforward, and about comparable in number of parameters – both basically consist
of two LSTMs with 32 units (<code>n_recurrent</code> will be set to 32 for all experiments).<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h4 id="fnn-lstm">FNN-LSTM</h4>
<p>FNN-LSTM looks nearly like in the previous post, apart from the fact that we split up the encoder LSTM into two, to uncouple
capacity (<code>n_recurrent</code>) from maximal latent state dimensionality (<code>n_latent</code>, kept at 10 just like before).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># DL-related packages</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/tensorflow'>tensorflow</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tensorflow.rstudio.com/'>keras</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/tfdatasets'>tfdatasets</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://t-kalinowski.github.io/tfautograph/'>tfautograph</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://rstudio.github.io/reticulate/'>reticulate</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># going to need those later</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://wilkelab.org/cowplot/'>cowplot</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>encoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                          <span class='va'>n_features</span>,</span>
<span>                          <span class='va'>n_recurrent</span>,</span>
<span>                          <span class='va'>n_latent</span>,</span>
<span>                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm1</span> <span class='op'>&lt;-</span>  <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_recurrent</span>,</span>
<span>      input_shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span><span class='op'>)</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>    <span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm1</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm2</span> <span class='op'>&lt;-</span>  <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_latent</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span>    <span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm2</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='va'>x</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm1</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm1</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm2</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm2</span><span class='op'>(</span><span class='op'>)</span> </span>
<span>    <span class='op'>}</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>decoder_model</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                          <span class='va'>n_features</span>,</span>
<span>                          <span class='va'>n_recurrent</span>,</span>
<span>                          <span class='va'>n_latent</span>,</span>
<span>                          <span class='va'>name</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='fu'>keras_model_custom</span><span class='op'>(</span>name <span class='op'>=</span> <span class='va'>name</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>self</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>repeat_vector</span> <span class='op'>&lt;-</span> <span class='fu'>layer_repeat_vector</span><span class='op'>(</span>n <span class='op'>=</span> <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>noise</span> <span class='op'>&lt;-</span> <span class='fu'>layer_gaussian_noise</span><span class='op'>(</span>stddev <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>lstm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_recurrent</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>      go_backwards <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>    <span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>batchnorm</span> <span class='op'>&lt;-</span> <span class='fu'>layer_batch_normalization</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>elu</span> <span class='op'>&lt;-</span> <span class='fu'>layer_activation_elu</span><span class='op'>(</span><span class='op'>)</span> </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>time_distributed</span> <span class='op'>&lt;-</span> <span class='fu'>time_distributed</span><span class='op'>(</span>layer <span class='op'>=</span> <span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='va'>n_features</span><span class='op'>)</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='kw'>function</span> <span class='op'>(</span><span class='va'>x</span>, <span class='va'>mask</span> <span class='op'>=</span> <span class='cn'>NULL</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='va'>x</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>repeat_vector</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>noise</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>lstm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>batchnorm</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>elu</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='va'>self</span><span class='op'>$</span><span class='fu'>time_distributed</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='op'>}</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>n_latent</span> <span class='op'>&lt;-</span> <span class='fl'>10L</span></span>
<span><span class='va'>n_features</span> <span class='op'>&lt;-</span> <span class='fl'>1</span></span>
<span><span class='va'>n_hidden</span> <span class='op'>&lt;-</span> <span class='fl'>32</span></span>
<span></span>
<span><span class='va'>encoder</span> <span class='op'>&lt;-</span> <span class='fu'>encoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                         <span class='va'>n_features</span>,</span>
<span>                         <span class='va'>n_hidden</span>,</span>
<span>                         <span class='va'>n_latent</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>decoder</span> <span class='op'>&lt;-</span> <span class='fu'>decoder_model</span><span class='op'>(</span><span class='va'>n_timesteps</span>,</span>
<span>                         <span class='va'>n_features</span>,</span>
<span>                         <span class='va'>n_hidden</span>,</span>
<span>                         <span class='va'>n_latent</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>The regularizer, FNN loss, is unchanged:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>loss_false_nn</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='co'># changing these parameters is equivalent to</span></span>
<span>  <span class='co'># changing the strength of the regularizer, so we keep these fixed (these values</span></span>
<span>  <span class='co'># correspond to the original values used in Kennel et al 1992).</span></span>
<span>  <span class='va'>rtol</span> <span class='op'>&lt;-</span> <span class='fl'>10</span> </span>
<span>  <span class='va'>atol</span> <span class='op'>&lt;-</span> <span class='fl'>2</span></span>
<span>  <span class='va'>k_frac</span> <span class='op'>&lt;-</span> <span class='fl'>0.01</span></span>
<span>  </span>
<span>  <span class='va'>k</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Extremes.html'>max</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>k_frac</span> <span class='op'>*</span> <span class='va'>batch_size</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'>## Vectorized version of distance matrix calculation</span></span>
<span>  <span class='va'>tri_mask</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='va'>linalg</span><span class='op'>$</span><span class='fu'>band_part</span><span class='op'>(</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>ones</span><span class='op'>(</span></span>
<span>        shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>)</span>,</span>
<span>        dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span></span>
<span>      <span class='op'>)</span>,</span>
<span>      num_lower <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span>,</span>
<span>      num_upper <span class='op'>=</span> <span class='fl'>0L</span></span>
<span>    <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># latent x batch_size x latent</span></span>
<span>  <span class='va'>batch_masked</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span><span class='va'>tri_mask</span><span class='op'>[</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>,<span class='op'>]</span>, <span class='va'>x</span><span class='op'>[</span><span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rstudio.github.io/reticulate/reference/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># latent x batch_size x 1</span></span>
<span>  <span class='va'>x_squared</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>batch_masked</span> <span class='op'>*</span> <span class='va'>batch_masked</span>,</span>
<span>                  axis <span class='op'>=</span> <span class='fl'>2L</span>,</span>
<span>                  keepdims <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># latent x batch_size x batch_size</span></span>
<span>  <span class='va'>pdist_vector</span> <span class='op'>&lt;-</span> <span class='va'>x_squared</span> <span class='op'>+</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span><span class='va'>x_squared</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>-</span></span>
<span>    <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>batch_masked</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>transpose</span><span class='op'>(</span><span class='va'>batch_masked</span>, perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0L</span>, <span class='fl'>2L</span>, <span class='fl'>1L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'>#(latent, batch_size, batch_size)</span></span>
<span>  <span class='va'>all_dists</span> <span class='op'>&lt;-</span> <span class='va'>pdist_vector</span></span>
<span>  <span class='co'># latent</span></span>
<span>  <span class='va'>all_ra</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span><span class='fl'>1</span> <span class='op'>/</span> <span class='op'>(</span></span>
<span>      <span class='va'>batch_size</span> <span class='op'>*</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>range</span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>n_latent</span>, dtype <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span></span>
<span>    <span class='op'>)</span><span class='op'>)</span> <span class='op'>*</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span></span>
<span>        <span class='va'>batch_masked</span> <span class='op'>-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>batch_masked</span>, axis <span class='op'>=</span> <span class='fl'>1L</span>, keepdims <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span>      <span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Avoid singularity in the case of zeros</span></span>
<span>  <span class='co'>#(latent, batch_size, batch_size)</span></span>
<span>  <span class='va'>all_dists</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>clip_by_value</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='fl'>1e-14</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_max</span><span class='op'>(</span><span class='va'>all_dists</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'>#inds = tf.argsort(all_dists, axis=-1)</span></span>
<span>  <span class='va'>top_k</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>top_k</span><span class='op'>(</span><span class='op'>-</span><span class='va'>all_dists</span>, <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>1</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='co'># (#(latent, batch_size, batch_size)</span></span>
<span>  <span class='va'>top_indices</span> <span class='op'>&lt;-</span> <span class='va'>top_k</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span>  </span>
<span>  <span class='co'>#(latent, batch_size, batch_size)</span></span>
<span>  <span class='va'>neighbor_dists_d</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span><span class='va'>all_dists</span>, <span class='va'>top_indices</span>, batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span><span class='op'>)</span></span>
<span>  <span class='co'>#(latent - 1, batch_size, batch_size)</span></span>
<span>  <span class='va'>neighbor_new_dists</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>gather</span><span class='op'>(</span><span class='va'>all_dists</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>1</span>, , <span class='op'>]</span>,</span>
<span>              <span class='va'>top_indices</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span>,</span>
<span>              batch_dims <span class='op'>=</span> <span class='op'>-</span><span class='fl'>1L</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Eq. 4 of Kennel et al.</span></span>
<span>  <span class='co'>#(latent - 1, batch_size, batch_size)</span></span>
<span>  <span class='va'>scaled_dist</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='op'>(</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_new_dists</span><span class='op'>)</span> <span class='op'>-</span></span>
<span>      <span class='co'># (9, 8, 2)</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>/</span></span>
<span>      <span class='co'># (9, 8, 2)</span></span>
<span>      <span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>neighbor_dists_d</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, , <span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Kennel condition #1</span></span>
<span>  <span class='co'>#(latent - 1, batch_size, batch_size)</span></span>
<span>  <span class='va'>is_false_change</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='va'>scaled_dist</span> <span class='op'>&gt;</span> <span class='va'>rtol</span><span class='op'>)</span></span>
<span>  <span class='co'># Kennel condition 2</span></span>
<span>  <span class='co'>#(latent - 1, batch_size, batch_size)</span></span>
<span>  <span class='va'>is_large_jump</span> <span class='op'>&lt;-</span></span>
<span>    <span class='op'>(</span><span class='va'>neighbor_new_dists</span> <span class='op'>&gt;</span> <span class='va'>atol</span> <span class='op'>*</span> <span class='va'>all_ra</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>newaxis</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>is_false_neighbor</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>logical_or</span><span class='op'>(</span><span class='va'>is_false_change</span>, <span class='va'>is_large_jump</span><span class='op'>)</span></span>
<span>  <span class='co'>#(latent - 1, batch_size, 1)</span></span>
<span>  <span class='va'>total_false_neighbors</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>is_false_neighbor</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>int32</span><span class='op'>)</span><span class='op'>[</span><span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rstudio.github.io/reticulate/reference/py_ellipsis.html'>py_ellipsis</a></span><span class='op'>(</span><span class='op'>)</span>, <span class='fl'>2</span><span class='op'>:</span><span class='op'>(</span><span class='va'>k</span> <span class='op'>+</span> <span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span></span>
<span>  </span>
<span>  <span class='co'># Pad zero to match dimensionality of latent space</span></span>
<span>  <span class='co'># (latent - 1)</span></span>
<span>  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span></span>
<span>    <span class='fl'>1</span> <span class='op'>-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>cast</span><span class='op'>(</span><span class='va'>total_false_neighbors</span>, <span class='va'>tf</span><span class='op'>$</span><span class='va'>float32</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>2L</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='co'># (latent,)</span></span>
<span>  <span class='va'>reg_weights</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>pad</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='fl'>1L</span>, <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='co'># Find batch average activity</span></span>
<span>  </span>
<span>  <span class='co'># L2 Activity regularization</span></span>
<span>  <span class='va'>activations_batch_averaged</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tf</span><span class='op'>$</span><span class='fu'>sqrt</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_mean</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>square</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>, axis <span class='op'>=</span> <span class='fl'>0L</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='fu'>reduce_sum</span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>multiply</span><span class='op'>(</span><span class='va'>reg_weights</span>, <span class='va'>activations_batch_averaged</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span></span>
<span>  </span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>Training is unchanged as well, apart from the fact that now, we continually output latent variable variances in addition to
the losses. This is because with FNN-LSTM, we have to choose an adequate weight for the FNN loss component. An “adequate
weight” is one where the variance drops sharply after the first <code>n</code> variables, with <code>n</code> thought to correspond to attractor
dimensionality. For the Lorenz system discussed in the previous post, this is how these variances looked:</p>
<pre><code>     V1       V2        V3        V4        V5        V6        V7        V8        V9       V10
 0.0739   0.0582   1.12e-6   3.13e-4   1.43e-5   1.52e-8   1.35e-6   1.86e-4   1.67e-4   4.39e-5</code></pre>
<p>If we take variance as an indicator of <em>importance</em>, the first two variables are clearly more important than the rest. This
finding nicely corresponds to “official” estimates of Lorenz attractor dimensionality. For example, the correlation dimension
is estimated to lie around 2.05 <span class="citation" data-cites="GRASSBERGER1983189">(<a href="#ref-GRASSBERGER1983189" role="doc-biblioref">Grassberger and Procaccia 1983</a>)</span>.</p>
<p>Thus, here we have the training routine:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_step</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/with.html'>with</a></span> <span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>GradientTape</span><span class='op'>(</span>persistent <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span> <span class='op'><a href='https://rstudio.github.io/reticulate/reference/with-as-operator.html'>%as%</a></span> <span class='va'>tape</span>, <span class='op'>{</span></span>
<span>    <span class='va'>code</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span>
<span>    <span class='va'>prediction</span> <span class='op'>&lt;-</span> <span class='fu'>decoder</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>l_mse</span> <span class='op'>&lt;-</span> <span class='fu'>mse_loss</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>prediction</span><span class='op'>)</span></span>
<span>    <span class='va'>l_fnn</span> <span class='op'>&lt;-</span> <span class='fu'>loss_false_nn</span><span class='op'>(</span><span class='va'>code</span><span class='op'>)</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='va'>l_mse</span> <span class='op'>+</span> <span class='va'>fnn_weight</span> <span class='op'>*</span> <span class='va'>l_fnn</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>encoder_gradients</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span></span>
<span>  <span class='va'>decoder_gradients</span> <span class='op'>&lt;-</span></span>
<span>    <span class='va'>tape</span><span class='op'>$</span><span class='fu'>gradient</span><span class='op'>(</span><span class='va'>loss</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span><span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span></span>
<span>    <span class='va'>encoder_gradients</span>, <span class='va'>encoder</span><span class='op'>$</span><span class='va'>trainable_variables</span></span>
<span>  <span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>apply_gradients</span><span class='op'>(</span><span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/transpose.html'>transpose</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span></span>
<span>    <span class='va'>decoder_gradients</span>, <span class='va'>decoder</span><span class='op'>$</span><span class='va'>trainable_variables</span></span>
<span>  <span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'>train_loss</span><span class='op'>(</span><span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='fu'>train_mse</span><span class='op'>(</span><span class='va'>l_mse</span><span class='op'>)</span></span>
<span>  <span class='fu'>train_fnn</span><span class='op'>(</span><span class='va'>l_fnn</span><span class='op'>)</span></span>
<span>  </span>
<span>  </span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>training_loop</span> <span class='op'>&lt;-</span> <span class='fu'>tf_function</span><span class='op'>(</span><span class='fu'>autograph</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>batch</span> <span class='kw'>in</span> <span class='va'>ds_train</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='fu'>train_step</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span></span>
<span>  </span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"Loss: "</span>, <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"MSE: "</span>, <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='fu'>print</span><span class='op'>(</span><span class='st'>"FNN loss: "</span>, <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>result</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>train_loss</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_mse</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_fnn</span><span class='op'>$</span><span class='fu'>reset_states</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span><span class='op'>}</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span></span>
<span><span class='va'>mse_loss</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='fu'>MeanSquaredError</span><span class='op'>(</span>reduction <span class='op'>=</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>losses</span><span class='op'>$</span><span class='va'>Reduction</span><span class='op'>$</span><span class='va'>SUM</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name <span class='op'>=</span> <span class='st'>'train_loss'</span><span class='op'>)</span></span>
<span><span class='va'>train_fnn</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name <span class='op'>=</span> <span class='st'>'train_fnn'</span><span class='op'>)</span></span>
<span><span class='va'>train_mse</span> <span class='op'>&lt;-</span>  <span class='va'>tf</span><span class='op'>$</span><span class='va'>keras</span><span class='op'>$</span><span class='va'>metrics</span><span class='op'>$</span><span class='fu'>Mean</span><span class='op'>(</span>name <span class='op'>=</span> <span class='st'>'train_mse'</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># fnn_multiplier should be chosen individually per dataset</span></span>
<span><span class='co'># this is the value we used on the geyser dataset</span></span>
<span><span class='va'>fnn_multiplier</span> <span class='op'>&lt;-</span> <span class='fl'>0.7</span></span>
<span><span class='va'>fnn_weight</span> <span class='op'>&lt;-</span> <span class='va'>fnn_multiplier</span> <span class='op'>*</span> <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span><span class='op'>/</span><span class='va'>batch_size</span></span>
<span></span>
<span><span class='co'># learning rate may also need adjustment</span></span>
<span><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optimizer_adam</span><span class='op'>(</span>lr <span class='op'>=</span> <span class='fl'>1e-3</span><span class='op'>)</span></span>
<span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>200</span><span class='op'>)</span> <span class='op'>{</span></span>
<span> <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='st'>"Epoch: "</span>, <span class='va'>epoch</span>, <span class='st'>" -----------\n"</span><span class='op'>)</span></span>
<span> <span class='fu'>training_loop</span><span class='op'>(</span><span class='va'>ds_train</span><span class='op'>)</span></span>
<span> </span>
<span> <span class='va'>test_batch</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>as_iterator</a></span><span class='op'>(</span><span class='va'>ds_test</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>iter_next</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span> <span class='va'>encoded</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span> </span>
<span> <span class='va'>test_var</span> <span class='op'>&lt;-</span> <span class='va'>tf</span><span class='op'>$</span><span class='va'>math</span><span class='op'>$</span><span class='fu'>reduce_variance</span><span class='op'>(</span><span class='va'>encoded</span>, axis <span class='op'>=</span> <span class='fl'>0L</span><span class='op'>)</span></span>
<span> <span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span><span class='va'>test_var</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>round</a></span><span class='op'>(</span><span class='fl'>5</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>On to what we’ll use as a baseline for comparison.</p>
<h4 id="vanilla-lstm">Vanilla LSTM</h4>
<p>Here is the vanilla LSTM, stacking two layers, each, again, of size 32. Dropout and recurrent dropout were chosen individually
per dataset, as was the learning rate.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lstm</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_recurrent</span>, <span class='va'>dropout</span>, <span class='va'>recurrent_dropout</span>,</span>
<span>                 <span class='va'>optimizer</span> <span class='op'>=</span> <span class='fu'>optimizer_adam</span><span class='op'>(</span>lr <span class='op'>=</span>  <span class='fl'>1e-3</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>keras_model_sequential</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>    <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_recurrent</span>,</span>
<span>      input_shape <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>n_timesteps</span>, <span class='va'>n_features</span><span class='op'>)</span>,</span>
<span>      dropout <span class='op'>=</span> <span class='va'>dropout</span>, </span>
<span>      recurrent_dropout <span class='op'>=</span> <span class='va'>recurrent_dropout</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>    <span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>    <span class='fu'>layer_lstm</span><span class='op'>(</span></span>
<span>      units <span class='op'>=</span> <span class='va'>n_recurrent</span>,</span>
<span>      dropout <span class='op'>=</span> <span class='va'>dropout</span>,</span>
<span>      recurrent_dropout <span class='op'>=</span> <span class='va'>recurrent_dropout</span>,</span>
<span>      return_sequences <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>    <span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>    <span class='fu'>time_distributed</span><span class='op'>(</span><span class='fu'>layer_dense</span><span class='op'>(</span>units <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>model</span> <span class='op'>%&gt;%</span></span>
<span>    <span class='fu'>compile</span><span class='op'>(</span></span>
<span>      loss <span class='op'>=</span> <span class='st'>"mse"</span>,</span>
<span>      optimizer <span class='op'>=</span> <span class='va'>optimizer</span></span>
<span>    <span class='op'>)</span></span>
<span>  <span class='va'>model</span></span>
<span>  </span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>lstm</span><span class='op'>(</span><span class='va'>n_latent</span>, <span class='va'>n_timesteps</span>, <span class='va'>n_features</span>, <span class='va'>n_hidden</span>, dropout <span class='op'>=</span> <span class='fl'>0.2</span>, recurrent_dropout <span class='op'>=</span> <span class='fl'>0.2</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="data-preparation">Data preparation</h3>
<p>For all experiments, data were prepared in the same way.</p>
<p>In every case, we used the first 10000 measurements available in the respective <code>.pkl</code> files <a href="https://github.com/williamgilpin/fnn/tree/master/datasets">provided by Gilpin in his GitHub
repository</a>. To save on file size and not depend on an external
data source, we extracted those first 10000 entries to <code>.csv</code> files downloadable directly from this blog’s repo:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>geyser</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/download.file.html'>download.file</a></span><span class='op'>(</span></span>
<span>  <span class='st'>"https://raw.githubusercontent.com/rstudio/ai-blog/master/docs/posts/2020-07-20-fnn-lstm/data/geyser.csv"</span>,</span>
<span>  <span class='st'>"data/geyser.csv"</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>electricity</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/download.file.html'>download.file</a></span><span class='op'>(</span></span>
<span>  <span class='st'>"https://raw.githubusercontent.com/rstudio/ai-blog/master/docs/posts/2020-07-20-fnn-lstm/data/electricity.csv"</span>,</span>
<span>  <span class='st'>"data/electricity.csv"</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>ecg</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/download.file.html'>download.file</a></span><span class='op'>(</span></span>
<span>  <span class='st'>"https://raw.githubusercontent.com/rstudio/ai-blog/master/docs/posts/2020-07-20-fnn-lstm/data/ecg.csv"</span>,</span>
<span>  <span class='st'>"data/ecg.csv"</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>mouse</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/utils/download.file.html'>download.file</a></span><span class='op'>(</span></span>
<span>  <span class='st'>"https://raw.githubusercontent.com/rstudio/ai-blog/master/docs/posts/2020-07-20-fnn-lstm/data/mouse.csv"</span>,</span>
<span>  <span class='st'>"data/mouse.csv"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Should you want to access the complete time series (of considerably greater lengths), just download them from Gilpin’s repo
and load them using <code>reticulate</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># e.g.</span></span>
<span><span class='va'>geyser</span> <span class='op'>&lt;-</span> <span class='fu'>reticulate</span><span class='fu'>::</span><span class='fu'><a href='https://rstudio.github.io/reticulate/reference/py_save_object.html'>py_load_object</a></span><span class='op'>(</span><span class='st'>"geyser_train_test.pkl"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Here is the data preparation code for the first dataset, <code>geyser</code> - all other datasets were treated the same way.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># the first 10000 measurements from the compilation provided by Gilpin</span></span>
<span><span class='va'>geyser</span> <span class='op'>&lt;-</span> <span class='fu'>read_csv</span><span class='op'>(</span><span class='st'>"geyser.csv"</span>, col_names <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>select</span><span class='op'>(</span><span class='va'>X1</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>pull</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/class.html'>unclass</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># standardize</span></span>
<span><span class='va'>geyser</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/scale.html'>scale</a></span><span class='op'>(</span><span class='va'>geyser</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># varies per dataset; see below </span></span>
<span><span class='va'>n_timesteps</span> <span class='op'>&lt;-</span> <span class='fl'>60</span></span>
<span><span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>32</span></span>
<span></span>
<span><span class='co'># transform into [batch_size, timesteps, features] format required by RNNs</span></span>
<span><span class='va'>gen_timesteps</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>n_timesteps</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/do.call.html'>do.call</a></span><span class='op'>(</span><span class='va'>rbind</span>,</span>
<span>          <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/seq.html'>seq_along</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>,</span>
<span>                     <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>                       <span class='va'>start</span> <span class='op'>&lt;-</span> <span class='va'>i</span></span>
<span>                       <span class='va'>end</span> <span class='op'>&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='fl'>1</span></span>
<span>                       <span class='va'>out</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>[</span><span class='va'>start</span><span class='op'>:</span><span class='va'>end</span><span class='op'>]</span></span>
<span>                       <span class='va'>out</span></span>
<span>                     <span class='op'>}</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/stats/na.fail.html'>na.omit</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fl'>10000</span></span>
<span><span class='va'>train</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='va'>geyser</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>]</span>, <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span><span class='va'>test</span> <span class='op'>&lt;-</span> <span class='fu'>gen_timesteps</span><span class='op'>(</span><span class='va'>geyser</span><span class='op'>[</span><span class='op'>(</span><span class='va'>n</span><span class='op'>/</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>:</span><span class='va'>n</span><span class='op'>]</span>, <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>n_timesteps</span><span class='op'>)</span> </span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>train</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>train</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>test</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>test</span><span class='op'>)</span>, <span class='fl'>1</span><span class='op'>)</span></span>
<span></span>
<span><span class='co'># split into input and target  </span></span>
<span><span class='va'>x_train</span> <span class='op'>&lt;-</span> <span class='va'>train</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>:</span><span class='va'>n_timesteps</span>, , drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span></span>
<span><span class='va'>y_train</span> <span class='op'>&lt;-</span> <span class='va'>train</span><span class='op'>[</span> , <span class='op'>(</span><span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>n_timesteps</span><span class='op'>)</span>, , drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span></span>
<span></span>
<span><span class='va'>x_test</span> <span class='op'>&lt;-</span> <span class='va'>test</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>:</span><span class='va'>n_timesteps</span>, , drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span></span>
<span><span class='va'>y_test</span> <span class='op'>&lt;-</span> <span class='va'>test</span><span class='op'>[</span> , <span class='op'>(</span><span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>*</span><span class='va'>n_timesteps</span><span class='op'>)</span>, , drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span></span>
<span></span>
<span><span class='co'># create tfdatasets</span></span>
<span><span class='va'>ds_train</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>x_train</span>, <span class='va'>y_train</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>dataset_shuffle</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_train</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='va'>batch_size</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>ds_test</span> <span class='op'>&lt;-</span> <span class='fu'>tensor_slices_dataset</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>x_test</span>, <span class='va'>y_test</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>dataset_batch</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>x_test</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Now we’re ready to look at how forecasting goes on our four datasets.</p>
<h2 id="experiments">Experiments</h2>
<h3 id="geyser-dataset">Geyser dataset</h3>
<p>People working with time series may have heard of <a href="https://en.wikipedia.org/wiki/Old_Faithful">Old Faithful</a>, a geyser in
Wyoming, US that has continually been erupting every 44 minutes to two hours since the year 2004. For the subset of data
Gilpin extracted<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>,</p>
<blockquote>
<p><code>geyser_train_test.pkl</code> corresponds to detrended temperature readings from the main runoff pool of the Old Faithful geyser
in Yellowstone National Park, downloaded from the <a href="https://geysertimes.org/">GeyserTimes database</a>. Temperature measurements
start on April 13, 2015 and occur in one-minute increments.</p>
</blockquote>
<p>Like we said above, <code>geyser.csv</code> is a subset of these measurements, comprising the first 10000 data points. To choose an
adequate timestep for the LSTMs, we inspect the series at various resolutions:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="images/geyser_ts.png" alt="Geyer dataset. Top: First 1000 observations. Bottom: Zooming in on the first 200." width="600" />
<p class="caption">
Figure 1: Geyer dataset. Top: First 1000 observations. Bottom: Zooming in on the first 200.
</p>
</div>
</div>
<p>It seems like the behavior is periodic with a period of about 40-50; a timestep of 60 thus seemed like a good try.</p>
<p>Having trained both FNN-LSTM and the vanilla LSTM for 200 epochs, we first inspect the variances of the latent variables on
the test set. The value of <code>fnn_multiplier</code> corresponding to this run was <code>0.7</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>test_batch</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>as_iterator</a></span><span class='op'>(</span><span class='va'>ds_test</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rstudio.github.io/reticulate/reference/iterate.html'>iter_next</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>encoded</span> <span class='op'>&lt;-</span> <span class='fu'>encoder</span><span class='op'>(</span><span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>encoded</span> <span class='op'>%&gt;%</span> <span class='fu'>summarise_all</span><span class='op'>(</span><span class='va'>var</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>   V1     V2        V3          V4       V5       V6       V7       V8       V9      V10
0.258 0.0262 0.0000627 0.000000600 0.000533 0.000362 0.000238 0.000121 0.000518 0.000365</code></pre>
<p>There is a drop in importance between the first two variables and the rest; however, unlike in the Lorenz system, <code>V1</code> and
<code>V2</code> variances also differ by an order of magnitude.</p>
<p>Now, it’s interesting to compare prediction errors for both models. We are going to make an observation that will carry
through to all three datasets to come.</p>
<p>Keeping up the suspense for a while, here is the code used to compute per-timestep prediction errors from both models. The
same code will be used for all other datasets.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>calc_mse</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>df</span>, <span class='va'>y_true</span>, <span class='va'>y_pred</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='op'>(</span><span class='va'>df</span><span class='op'>[[</span><span class='va'>y_true</span><span class='op'>]</span><span class='op'>]</span> <span class='op'>-</span> <span class='va'>df</span><span class='op'>[[</span><span class='va'>y_pred</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span><span class='op'>/</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>df</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>get_mse</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>test_batch</span>, <span class='va'>prediction</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>comp_df</span> <span class='op'>&lt;-</span> </span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span></span>
<span>      <span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>        <span class='fu'>rename_with</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>name</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='va'>name</span>, <span class='st'>"_true"</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>    <span class='fu'>bind_cols</span><span class='op'>(</span></span>
<span>      <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span></span>
<span>        <span class='va'>prediction</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span> <span class='op'>%&gt;%</span></span>
<span>          <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>          <span class='fu'>rename_with</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>name</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='va'>name</span>, <span class='st'>"_pred"</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>mse</span> <span class='op'>&lt;-</span> <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>prediction</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span>,</span>
<span>                        <span class='kw'>function</span><span class='op'>(</span><span class='va'>varno</span><span class='op'>)</span></span>
<span>                          <span class='fu'>calc_mse</span><span class='op'>(</span><span class='va'>comp_df</span>,</span>
<span>                                   <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='st'>"X"</span>, <span class='va'>varno</span>, <span class='st'>"_true"</span><span class='op'>)</span>,</span>
<span>                                   <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='st'>"X"</span>, <span class='va'>varno</span>, <span class='st'>"_pred"</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/unlist.html'>unlist</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>mse</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>prediction_fnn</span> <span class='op'>&lt;-</span> <span class='fu'>decoder</span><span class='op'>(</span><span class='fu'>encoder</span><span class='op'>(</span><span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>mse_fnn</span> <span class='op'>&lt;-</span> <span class='fu'>get_mse</span><span class='op'>(</span><span class='va'>test_batch</span>, <span class='va'>prediction_fnn</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>prediction_lstm</span> <span class='op'>&lt;-</span> <span class='va'>model</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>ds_test</span><span class='op'>)</span></span>
<span><span class='va'>mse_lstm</span> <span class='op'>&lt;-</span> <span class='fu'>get_mse</span><span class='op'>(</span><span class='va'>test_batch</span>, <span class='va'>prediction_lstm</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>mses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>timestep <span class='op'>=</span> <span class='fl'>1</span><span class='op'>:</span><span class='va'>n_timesteps</span>, fnn <span class='op'>=</span> <span class='va'>mse_fnn</span>, lstm <span class='op'>=</span> <span class='va'>mse_lstm</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>gather</span><span class='op'>(</span>key <span class='op'>=</span> <span class='st'>"type"</span>, value <span class='op'>=</span> <span class='st'>"mse"</span>, <span class='op'>-</span><span class='va'>timestep</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'>ggplot</span><span class='op'>(</span><span class='va'>mses</span>, <span class='fu'>aes</span><span class='op'>(</span><span class='va'>timestep</span>, <span class='va'>mse</span>, color <span class='op'>=</span> <span class='va'>type</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>geom_point</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>scale_color_manual</span><span class='op'>(</span>values <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"#00008B"</span>, <span class='st'>"#3CB371"</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>theme_classic</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>theme</span><span class='op'>(</span>legend.position <span class='op'>=</span> <span class='st'>"none"</span><span class='op'>)</span> </span></code></pre>
</div>
</div>
<p>And here is the actual comparison. One thing especially jumps to the eye: FNN-LSTM forecast error is significantly lower for
initial timesteps, first and foremost, for the very first prediction, which from this graph we expect to be pretty good!</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="images/geyser_mses.png" alt="Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM." width="600" />
<p class="caption">
Figure 2: Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM.
</p>
</div>
</div>
<p>Interestingly, we see “jumps” in prediction error, for FNN-LSTM, between the very first forecast and the second, and then
between the second and the ensuing ones, reminding of the similar jumps in variable importance for the latent code! After the
first ten timesteps, vanilla LSTM has caught up with FNN-LSTM, and we won’t interpret further development of the losses based
on just a single run’s output.</p>
<p>Instead, let’s inspect actual predictions. We randomly pick sequences from the test set, and ask both FNN-LSTM and vanilla
LSTM for a forecast. The same procedure will be followed for the other datasets.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>given</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='va'>tf</span><span class='op'>$</span><span class='fu'>concat</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span></span>
<span>  <span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span>, <span class='va'>test_batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span></span>
<span><span class='op'>)</span>,</span>
<span>axis <span class='op'>=</span> <span class='fl'>1L</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>type <span class='op'>=</span> <span class='st'>"given"</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>num <span class='op'>=</span> <span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>n_timesteps</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>fnn</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='va'>prediction_fnn</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>                    <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>type <span class='op'>=</span> <span class='st'>"fnn"</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>num <span class='op'>=</span> <span class='op'>(</span><span class='va'>n_timesteps</span>  <span class='op'>+</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>n_timesteps</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>lstm</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='va'>prediction_lstm</span><span class='op'>[</span>, , <span class='fl'>1</span><span class='op'>]</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>                     <span class='fu'><a href='https://rdrr.io/r/base/t.html'>t</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>type <span class='op'>=</span> <span class='st'>"lstm"</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span>num <span class='op'>=</span> <span class='op'>(</span><span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>n_timesteps</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>compare_preds_df</span> <span class='op'>&lt;-</span> <span class='fu'>bind_rows</span><span class='op'>(</span><span class='va'>given</span>, <span class='va'>lstm</span>, <span class='va'>fnn</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>plots</span> <span class='op'>&lt;-</span> </span>
<span>  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>compare_preds_df</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span>, <span class='fl'>16</span><span class='op'>)</span>,</span>
<span>             <span class='kw'>function</span><span class='op'>(</span><span class='va'>v</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>               <span class='fu'>ggplot</span><span class='op'>(</span><span class='va'>compare_preds_df</span>, <span class='fu'>aes</span><span class='op'>(</span><span class='va'>num</span>, <span class='va'>.data</span><span class='op'>[[</span><span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='st'>"X"</span>, <span class='va'>v</span><span class='op'>)</span><span class='op'>]</span><span class='op'>]</span>, color <span class='op'>=</span> <span class='va'>type</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>                 <span class='fu'>geom_line</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>                 <span class='fu'>theme_classic</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>                 <span class='fu'>theme</span><span class='op'>(</span>legend.position <span class='op'>=</span> <span class='st'>"none"</span>, axis.title <span class='op'>=</span> <span class='fu'>element_blank</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>                 <span class='fu'>scale_color_manual</span><span class='op'>(</span>values <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"#00008B"</span>, <span class='st'>"#DB7093"</span>, <span class='st'>"#3CB371"</span><span class='op'>)</span><span class='op'>)</span></span>
<span>             <span class='op'>}</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'>plot_grid</span><span class='op'>(</span>plotlist <span class='op'>=</span> <span class='va'>plots</span>, ncol <span class='op'>=</span> <span class='fl'>4</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Here are sixteen random picks of predictions on the test set. The ground truth is displayed in pink; blue forecasts are from
FNN-LSTM, green ones from vanilla LSTM.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="images/geyser_preds.png" alt="60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth." width="600" />
<p class="caption">
Figure 3: 60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth.
</p>
</div>
</div>
<p>What we expect from the error inspection comes true: FNN-LSTM yields significantly better predictions for immediate
continuations of a given sequence.</p>
<p>Let’s move on to the second dataset on our list.</p>
<h3 id="electricity-dataset">Electricity dataset</h3>
<p>This is a dataset on power consumption, aggregated over 321 different households and fifteen-minute-intervals.</p>
<blockquote>
<p><code>electricity_train_test.pkl</code> corresponds to average power consumption by 321 Portuguese households between 2012 and 2014, in
units of kilowatts consumed in fifteen minute increments. This dataset is from the <a href="http://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014">UCI machine learning
database</a>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</blockquote>
<p>Here, we see a very regular pattern:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-14"></span>
<img src="images/electricity_ts.png" alt="Electricity dataset. Top: First 2000 observations. Bottom: Zooming in on 500 observations, skipping the very beginning of the series." width="600" />
<p class="caption">
Figure 4: Electricity dataset. Top: First 2000 observations. Bottom: Zooming in on 500 observations, skipping the very beginning of the series.
</p>
</div>
</div>
<p>With such regular behavior, we immediately tried to predict a higher number of timesteps (<code>120</code>) – and didn’t have to retract
behind that aspiration.</p>
<p>For an <code>fnn_multiplier</code> of <code>0.5</code>, latent variable variances look like this:</p>
<pre><code>V1          V2            V3       V4       V5            V6       V7         V8      V9     V10
0.390 0.000637 0.00000000288 1.48e-10 2.10e-11 0.00000000119 6.61e-11 0.00000115 1.11e-4 1.40e-4</code></pre>
<p>We definitely see a sharp drop already after the first variable.</p>
<p>How do prediction errors compare on the two architectures?</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-15"></span>
<img src="images/electricity_mses.png" alt="Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM." width="600" />
<p class="caption">
Figure 5: Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM.
</p>
</div>
</div>
<p>Here, FNN-LSTM performs better over a long range of timesteps, but again, the difference is most visible for immediate
predictions. Will an inspection of actual predictions confirm this view?</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-16"></span>
<img src="images/electricity_predictions.png" alt="60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth." width="600" />
<p class="caption">
Figure 6: 60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth.
</p>
</div>
</div>
<p>It does! In fact, forecasts from FNN-LSTM are very impressive on all time scales.</p>
<p>Now that we’ve seen the easy and predictable, let’s approach the weird and difficult.</p>
<h3 id="ecg-dataset">ECG dataset</h3>
<p>Says Gilpin,</p>
<blockquote>
<p><code>ecg_train.pkl</code> and <code>ecg_test.pkl</code> correspond to ECG measurements for two different patients, taken from the <a href="https://physionet.org/content/qtdb/1.0.0/">PhysioNet QT
database</a>.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</blockquote>
<p>How do these look?</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-17"></span>
<img src="images/ecg_ts.png" alt="ECG dataset. Top: First 1000 observations. Bottom: Zooming in on the first 400 observations." width="600" />
<p class="caption">
Figure 7: ECG dataset. Top: First 1000 observations. Bottom: Zooming in on the first 400 observations.
</p>
</div>
</div>
<p>To the layperson that I am, these do not look nearly as regular as expected. First experiments showed that both architectures
are not capable of dealing with a high number of timesteps. In every try, FNN-LSTM performed better for the very first
timestep.</p>
<p>This is also the case for <code>n_timesteps = 12</code>, the final try (after <code>120</code>, <code>60</code> and <code>30</code>). With an <code>fnn_multiplier</code> of <code>1</code>, the
latent variances obtained amounted to the following:</p>
<pre><code>     V1        V2          V3        V4         V5       V6       V7         V8         V9       V10
  0.110  1.16e-11     3.78e-9 0.0000992    9.63e-9  4.65e-5  1.21e-4    9.91e-9    3.81e-9   2.71e-8</code></pre>
<p>There <em>is</em> a gap between the first variable and all other ones; but not much variance is explained by <code>V1</code> either.</p>
<p>Apart from the very first prediction, vanilla LSTM shows lower forecast errors this time; however, we have to add that this
was not consistently observed when experimenting with other timestep settings.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-18"></span>
<img src="images/ecg_mses.png" alt="Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM." width="600" />
<p class="caption">
Figure 8: Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM.
</p>
</div>
</div>
<p>Looking at actual predictions, both architectures perform best when a persistence forecast is adequate – in fact, they
produce one even when it is <em>not</em>.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-19"></span>
<img src="images/ecg_predictions.png" alt="60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth." width="600" />
<p class="caption">
Figure 9: 60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth.
</p>
</div>
</div>
<p>On this dataset, we certainly would want to explore other architectures better able to capture the presence of high <em>and</em> low
frequencies in the data, such as mixture models. But – were we forced to stay with one of these, and could do a
one-step-ahead, rolling forecast, we’d go with FNN-LSTM.</p>
<p>Speaking of mixed frequencies – we haven’t seen the extremes yet …</p>
<h3 id="mouse-dataset">Mouse dataset</h3>
<p>“Mouse,” that’s spike rates recorded from a mouse thalamus.</p>
<blockquote>
<p><code>mouse.pkl</code> A time series of spiking rates for a neuron in a mouse thalamus. Raw spike data was obtained from
<a href="http://crcns.org/data-sets/thalamus/th-1/about-th-1">CRCNS</a> and processed with the authors' code in order to generate a
spike rate time series.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
</blockquote>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-20"></span>
<img src="images/mouse_ts.png" alt="Mouse dataset. Top: First 2000 observations. Bottom: Zooming in on the first 500 observations." width="600" />
<p class="caption">
Figure 10: Mouse dataset. Top: First 2000 observations. Bottom: Zooming in on the first 500 observations.
</p>
</div>
</div>
<p>Obviously, this dataset will be very hard to predict. How, after “long” silence, do you know that a neuron is going to fire?</p>
<p>As usual, we inspect latent code variances (<code>fnn_multiplier</code> was set to <code>0.4</code>):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>     V1       V2        V3         V4       V5       V6        V7      V8       V9        V10</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a> <span class="fl">0.0796</span>  <span class="fl">0.00246</span>  <span class="fl">0.000214</span>    <span class="fl">2.26e-7</span>   .<span class="fl">71e-9</span>  <span class="fl">4.22e-8</span>  <span class="fl">6.45e-10</span> <span class="fl">1.61e-4</span> <span class="fl">2.63e-10</span>    <span class="fl">2.05e-8</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span></span></code></pre></div>
</div>
<p>Again, we don’t see the first variable explaining much variance. Still, interestingly, when inspecting forecast errors we get
a picture very similar to the one obtained on our first, <code>geyser</code>, dataset:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-22"></span>
<img src="images/mouse_mses.png" alt="Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM." width="600" />
<p class="caption">
Figure 11: Per-timestep prediction error as obtained by FNN-LSTM and a vanilla stacked LSTM. Green: LSTM. Blue: FNN-LSTM.
</p>
</div>
</div>
<p>So here, the latent code definitely seems to help! With every timestep “more” that we try to predict, prediction performance
goes down <em>continuously</em> – or put the other way round, short-time predictions are expected to be pretty good!</p>
<p>Let’s see:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-23"></span>
<img src="images/mouse_predictions.png" alt="60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth." width="600" />
<p class="caption">
Figure 12: 60-step ahead predictions from FNN-LSTM (blue) and vanilla LSTM (green) on randomly selected sequences from the test set. Pink: the ground truth.
</p>
</div>
</div>
<p>In fact on this dataset, the difference in behavior between both architectures is striking. When nothing is “supposed to
happen,” vanilla LSTM produces “flat” curves at about the mean of the data, while FNN-LSTM takes the effort to “stay on track”
as long as possible before also converging to the mean. Choosing FNN-LSTM – had we to choose one of these two – would be an
obvious decision with this dataset.</p>
<h2 id="discussion">Discussion</h2>
<p>When, in timeseries forecasting, would we consider FNN-LSTM? Judging by the above experiments, conducted on four very different
datasets: Whenever we consider a deep learning approach. Of course, this has been a casual exploration – and it was meant to
be, as – hopefully – was evident from the nonchalant and bloomy (sometimes) writing style.</p>
<p>Throughout the text, we’ve emphasized <em>utility</em> – how could this technique be used to improve predictions? But, looking at
the above results, a number of interesting questions come to mind. We already speculated (though in an indirect way) whether
the number of high-variance variables in the latent code was relatable to how far we could sensibly forecast into the future.
However, even more intriguing is the question of how characteristics of the <em>dataset itself</em> affect FNN efficiency.</p>
<p>Such characteristics could be:</p>
<ul>
<li><p>How nonlinear is the dataset? (Put differently, how incompatible, as indicated by some form of test algorithm, is it with
the hypothesis that the data generation mechanism was a linear one?)</p></li>
<li><p>To what degree does the system appear to be sensitively dependent on initial conditions? In other words, what is the value
of its (estimated, from the observations) highest <a href="https://en.wikipedia.org/wiki/Lyapunov_exponent">Lyapunov exponent</a>?</p></li>
<li><p>What is its (estimated) dimensionality, for example, in terms of <a href="https://en.wikipedia.org/wiki/Correlation_dimension">correlation
dimension</a>?</p></li>
</ul>
<p>While it is easy to obtain those estimates, using, for instance, the
<a href="https://cran.r-project.org/web/packages/nonlinearTseries/">nonlinearTseries</a> package explicitly modeled after practices
described in Kantz &amp; Schreiber’s classic <span class="citation" data-cites="Kantz">(<a href="#ref-Kantz" role="doc-biblioref">Kantz and Schreiber 2004</a>)</span>, we don’t want to extrapolate from our tiny sample of datasets, and leave
such explorations and analyses to further posts, and/or the interested reader’s ventures :-). In any case, we hope you enjoyed
the demonstration of practical usability of an approach that in the preceding post, was mainly introduced in terms of its
conceptual attractivity.</p>
<p>Thanks for reading!</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-gilpin2020deep" class="csl-entry" role="doc-biblioentry">
Gilpin, William. 2020. <span>“Deep Reconstruction of Strange Attractors from Time Series.”</span> <a href="https://arxiv.org/abs/2002.05909">https://arxiv.org/abs/2002.05909</a>.
</div>
<div id="ref-GRASSBERGER1983189" class="csl-entry" role="doc-biblioentry">
Grassberger, Peter, and Itamar Procaccia. 1983. <span>“Measuring the Strangeness of Strange Attractors.”</span> <em>Physica D: Nonlinear Phenomena</em> 9 (1): 189–208. https://doi.org/<a href="https://doi.org/10.1016/0167-2789(83)90298-1">https://doi.org/10.1016/0167-2789(83)90298-1</a>.
</div>
<div id="ref-Kantz" class="csl-entry" role="doc-biblioentry">
Kantz, Holger, and Thomas Schreiber. 2004. <em>Nonlinear Time Series Analysis</em>. Cambridge University Press.
</div>
<div id="ref-embedology" class="csl-entry" role="doc-biblioentry">
Sauer, Tim, James A. Yorke, and Martin Casdagli. 1991. <span>“<span>Embedology</span>.”</span> <em>Journal of Statistical Physics</em> 65 (3-4): 579–616. <a href="https://doi.org/10.1007/BF01053745">https://doi.org/10.1007/BF01053745</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Please refer to the aforementioned predecessor post for a detailed introduction.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>“Basically” because FNN-LSTM technically has three LSTMs – the third one, with <code>n_latent = 10</code> units, being used to
store the latent code.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>see dataset descriptions in the <a href="https://github.com/williamgilpin/fnn">repository's README</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>again, citing from Gilpin’s repository’s <a href="https://github.com/williamgilpin/fnn">README</a>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>again, citing from Gilpin’s repository’s <a href="https://github.com/williamgilpin/fnn">README</a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>again, citing from Gilpin’s repository’s <a href="https://github.com/williamgilpin/fnn">README</a>.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-07-20-fnn-lstm/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Time%20series%20prediction%20with%20FNN-LSTM&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-07-20-fnn-lstm%2F" aria-label="share on twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-07-20-fnn-lstm%2F&amp;title=Time%20series%20prediction%20with%20FNN-LSTM" aria-label="share on linkedin">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/';
  this.page.identifier = 'posts/2020-07-20-fnn-lstm/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2020, July 20). Posit AI Blog: Time series prediction with FNN-LSTM. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanafnnlstm,
  author = {Keydana, Sigrid},
  title = {Posit AI Blog: Time series prediction with FNN-LSTM},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
