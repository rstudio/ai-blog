<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: An introduction to weather forecasting with deep learning</title>

<meta property="description" itemprop="description" content="A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the &quot;black-box end&quot; of the continuum."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-09-01"/>
<meta property="article:created" itemprop="dateCreated" content="2020-09-01"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: An introduction to weather forecasting with deep learning"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the &quot;black-box end&quot; of the continuum."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/images/thumb.png"/>
<meta property="og:image:width" content="600"/>
<meta property="og:image:height" content="332"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: An introduction to weather forecasting with deep learning"/>
<meta property="twitter:description" content="A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the &quot;black-box end&quot; of the continuum."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/images/thumb.png"/>
<meta property="twitter:image:width" content="600"/>
<meta property="twitter:image:height" content="332"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: An introduction to weather forecasting with deep learning"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/09/01"/>
<meta name="citation_publication_date" content="2020/09/01"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Purely data-driven medium-range weather forecasting achieves comparable skill to physical models at similar resolution;citation_publication_date=2020;citation_author=Stephan Rasp;citation_author=Nils Thuerey"/>
  <meta name="citation_reference" content="citation_title=Improving data-driven global weather prediction using deep convolutional neural networks on a cubed sphere;citation_volume=n/a;citation_doi=10.1029/2020MS002109;citation_author=Jonathan A. Weyn;citation_author=Dale R. Durran;citation_author=Rich Caruana"/>
  <meta name="citation_reference" content="citation_title=&lt;span class=&quot;nocase&quot;&gt;WeatherBench: A benchmark dataset for data-driven weather forecasting&lt;/span&gt;;citation_publication_date=2020;citation_author=Stephan Rasp;citation_author=Peter D. Dueben;citation_author=Sebastian Scher;citation_author=Jonathan A. Weyn;citation_author=Soukayna Mouatadid;citation_author=Nils Thuerey"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","bibliography","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["An introduction to weather forecasting with deep learning"]},{"type":"character","attributes":{},"value":["A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the \"black-box end\" of the continuum."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanaweatherforecasting"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["09-01-2020"]},{"type":"character","attributes":{},"value":["R","TensorFlow/Keras","Time Series"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/thumb.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","images/history.png","images/thumb.png","images/viz.png","weather_prediction_deep_learning_files/bowser-1.9.3/bowser.min.js","weather_prediction_deep_learning_files/distill-2.2.21/template.v2.js","weather_prediction_deep_learning_files/header-attrs-2.3/header-attrs.js","weather_prediction_deep_learning_files/jquery-1.11.3/jquery.min.js","weather_prediction_deep_learning_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</style>

<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createIndex() {
  var options = {
    keys: [
      "title",
      "categories",
      "description",
      "contents"
    ]
  };
  return new window.Fuse([],options);
}

function createFuseIndex() {

  // create fuse index
  var options = { keys: ["title", "description", "contents"] };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
            keys: [
              { name: 'title', weight: 20 },
              { name: 'categories', weight: 15 },
              { name: 'description', weight: 10 },
              { name: 'contents', weight: 5 },
            ],
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
            .filter(function(item) { return !!item.description; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description}
                </div>
                <div class="search-item-preview">
                  <img src="${suggestion.preview ? offsetURL(suggestion.preview) : ''}"</img>
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: hidden;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.3/header-attrs.js"></script>
  <script src="../../site_libs/jquery-1.11.3/jquery.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"An introduction to weather forecasting with deep learning","description":"A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the \"black-box end\" of the continuum.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-09-01T00:00:00.000+00:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>An introduction to weather forecasting with deep learning</h1>
<p><p>A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the black-box end of the continuum.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>09-01-2020
</div>

<div class="d-article">
<p>With all that is going on in the world these days, is it frivolous to talk about weather prediction? Asked in the 21st century, this is bound to be a rhetorical question. In the 1930s, when German poet Bertolt Brecht wrote the famous lines:</p>
<blockquote>
<p>Was sind das fr Zeiten, wo<br />
Ein Gesprch ber Bume fast ein Verbrechen ist<br />
Weil es ein Schweigen ber so viele Untaten einschliet!<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>(What kind of times are these, where a conversation about trees is almost a crime, for it means silence about so many atrocities!),</p>
<p>he couldnt have anticipated the responses he would get in the second half of that century, with trees symbolizing, as well as literally falling victim to, environmental pollution and climate change.</p>
<p>Today, no lengthy justification is needed as to why prediction of atmospheric states is vital: Due to global warming, frequency and intensity of severe weather conditions  droughts, wildfires, hurricanes, heatwaves  have risen and will continue to rise. And while accurate forecasts dont change those events per se, they constitute essential information in mitigating their consequences. This goes for atmospheric forecasts on all scales: from so-called nowcasting (operating on a range of about six hours), over medium-range (three to five days) and sub-seasonal (weekly/monthly), to climate forecasts (concerned with years and decades). Medium-range forecasts especially are extremely important in acute disaster prevention.</p>
<p>This post will show how deep learning (DL) methods can be used to generate atmospheric forecasts, using a newly published <a href="https://github.com/pangeo-data/WeatherBench">benchmark dataset</a><span class="citation" data-cites="weatherbench">(Rasp et al. <a href="#ref-weatherbench" role="doc-biblioref">2020</a>)</span>. Future posts may refine the model used here and/or discuss the role of DL (AI) in mitigating climate change  and its implications  more globally.</p>
<p>That said, lets put the current endeavor in context. In a way, we have here the usual <em>dej vu</em> of using DL as a black-box-like, magic instrument on a task where <em>human knowledge</em> used to be required. Of course, this characterization is overly dichotomizing; many choices are made in creating DL models, and performance is necessarily constrained by available algorithms  which may, or may not, fit the domain to be modeled to a sufficient degree.</p>
<p>If youve started learning about image recognition rather recently, you may well have been using DL methods from the outset, and not have heard much about the rich set of feature engineering methods developed in pre-DL image recognition. In the context of atmospheric prediction, then, lets begin by asking: How in the world did they do that <em>before</em>?</p>
<h2 id="numerical-weather-prediction-in-a-nutshell">Numerical weather prediction in a nutshell</h2>
<p>It is not like machine learning and/or statistics are not already used in numerical weather prediction  on the contrary. For example, every model has to start from somewhere; but raw observations are not suited to direct use as initial conditions. Instead, they have to be assimilated to the four-dimensional <em>grid</em><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> over which model computations are performed. At the other end, namely, model output, statistical post-processing is used to refine the predictions. And very importantly, ensemble forecasts are employed to determine uncertainty.</p>
<p>That said, the model <em>core</em>, the part that extrapolates into the future atmospheric conditions observed today, is based on a set of differential<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> equations, the so-called <a href="https://en.wikipedia.org/wiki/Primitive_equations">primitive equations</a>, that are due to the conservation laws of <a href="https://en.wikipedia.org/wiki/Conservation_of_momentum">momentum</a>, <a href="https://en.wikipedia.org/wiki/Conservation_of_energy">energy</a>, and <a href="https://en.wikipedia.org/wiki/Conservation_of_mass">mass</a>. These differential equations cannot be solved analytically; rather, they have to be solved numerically, and that on a grid of resolution as high as possible. In that light, even deep learning could appear as just moderately resource-intensive (dependent, though, on the model in question). So how, then, could a DL approach look?</p>
<h2 id="deep-learning-models-for-weather-prediction">Deep learning models for weather prediction</h2>
<p>Accompanying the benchmark dataset they created, Rasp et al.<span class="citation" data-cites="weatherbench">(Rasp et al. <a href="#ref-weatherbench" role="doc-biblioref">2020</a>)</span> provide a set of notebooks, including one demonstrating the use of a simple convolutional neural network to predict two of the available atmospheric variables, <em>500hPa geopotential</em> and <em>850hPa temperature</em>. Here <em>850hPa temperature</em> is the (spatially varying) temperature at a fix atmospheric height of 850hPa (~ 1.5 kms)<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> ; <em>500hPa geopotential</em> is proportional to the (again, spatially varying) altitude associated with the pressure level in question (500hPa).</p>
<p>For this task, two-dimensional convnets, as usually employed in image processing, are a natural fit: Image width and height map to longitude and latitude of the spatial grid, respectively; target variables appear as channels. In this architecture, the time series character of the data is essentially lost: Every sample stands alone, without dependency on either past or present. In this respect, as well as given its size and simplicity, the convnet presented below is only a toy model, meant to introduce the approach as well as the application overall. It may also serve as a <em>deep learning baseline</em>, along with two other types of baseline commonly used in numerical weather prediction introduced below.</p>
<p>Directions on how to improve on that baseline are given by recent publications. Weyn et al.<span class="citation" data-cites="weyn">(Weyn, Durran, and Caruana, <a href="#ref-weyn" role="doc-biblioref">n.d.</a>)</span>, in addition to applying more geometrically-adequate spatial preprocessing, use a U-Net-based architecture instead of a plain convnet. Rasp and Thuerey <span class="citation" data-cites="rasp2020purely">(Rasp and Thuerey <a href="#ref-rasp2020purely" role="doc-biblioref">2020</a>)</span>, building on a fully convolutional, high-capacity ResNet architecture, add a key new procedural ingredient: pre-training on climate models. With their method, they are able to not just compete with physical models, but also, show evidence of the network learning about physical structure and dependencies. Unfortunately, compute facilities of this order are not available to the average individual, which is why well content ourselves with demonstrating a simple toy model. Still, having seen a simple model in action, as well as the type of data it works on, should help a lot in understanding how DL can be used for weather prediction.</p>
<h2 id="dataset">Dataset</h2>
<p><a href="https://github.com/pangeo-data/WeatherBench">Weatherbench</a> was explicitly created as a benchmark dataset and thus, as is common for this species, hides a lot of preprocessing and standardization effort from the user. Atmospheric data are available on an hourly basis, ranging from 1979 to 2018, at different spatial resolutions. Depending on resolution, there are about 15 to 20 measured variables, including temperature, geopotential, wind speed, and humidity. Of these variables, some are available at several pressure levels. Thus, our example makes use of a small subset of available channels. To save storage, network and computational resources, it also operates at the smallest available resolution.</p>
<p>This post is accompanied by executable code on <a href="https://colab.research.google.com/drive/1URSjWfcnhgesHWCqd7Un5GHECYblY04r?usp=sharing">Google Colaboratory</a>, which should not just render unnecessary any copy-pasting of code snippets but also, allow for uncomplicated modification and experimentation.</p>
<p>To read in and extract the data, stored as <a href="https://www.unidata.ucar.edu/software/netcdf/">NetCDF</a> files, we use <a href="https://docs.ropensci.org/tidync/">tidync</a>, a high-level package built on top of <a href="https://cran.r-project.org/package=ncdf4">ncdf4</a> and <a href="https://cran.r-project.org/package=RNetCDF">RNetCDF</a>. Otherwise, availability of the usual TensorFlow family as well as a subset of tidyverse packages is assumed.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(reticulate)
library(tensorflow)
library(keras)
library(tfdatasets)
library(tfautograph)

library(dplyr)
library(ggplot2)
library(tidyr)
library(purrr)
library(lubridate)

library(tidync)</code></pre>
</div>
<p>As already alluded to, our example makes use of two spatio-temporal series: 500hPa geopotential and 850hPa temperature. The following commands will download and unpack the respective sets of by-year files, for a spatial resolution of 5.625 degrees:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
download.file(&quot;https://dataserv.ub.tum.de/s/m1524895/download?path=%2F5.625deg%2Ftemperature_850&amp;files=temperature_850_5.625deg.zip&quot;,
              &quot;temperature_850_5.625deg.zip&quot;)
unzip(&quot;temperature_850_5.625deg.zip&quot;, exdir = &quot;temperature_850&quot;)

download.file(&quot;https://dataserv.ub.tum.de/s/m1524895/download?path=%2F5.625deg%2Fgeopotential_500&amp;files=geopotential_500_5.625deg.zip&quot;,
              &quot;geopotential_500_5.625deg.zip&quot;)
unzip(&quot;geopotential_500_5.625deg.zip&quot;, exdir = &quot;geopotential_500&quot;)</code></pre>
</div>
<p>Inspecting one of those files contents, we see that its data array is structured along three dimensions, longitude (64 different values), latitude (32) and time (8760). The data itself is <code>z</code>, the geopotential.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
tidync(&quot;geopotential_500/geopotential_500hPa_2015_5.625deg.nc&quot;) %&gt;% hyper_array()</code></pre>
</div>
<pre><code>
Class: tidync_data (list of tidync data arrays)
Variables (1): &#39;z&#39;
Dimension (3): lon,lat,time (64, 32, 8760)
Source: /[...]/geopotential_500/geopotential_500hPa_2015_5.625deg.nc</code></pre>
<p>Extraction of the data array is as easy as telling <code>tidync</code> to read the first in the list of arrays:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
z500_2015 &lt;- (tidync(&quot;geopotential_500/geopotential_500hPa_2015_5.625deg.nc&quot;) %&gt;%
                hyper_array())[[1]]

dim(z500_2015)</code></pre>
</div>
<pre><code>
[1] 64 32 8760</code></pre>
<p>While we delegate further introduction to <code>tidync</code> to a comprehensive <a href="https://ropensci.org/blog/2019/11/05/tidync/">blog post</a> on the ROpenSci website, lets at least look at a quick visualization, for which we pick the very first time point. (Extraction and visualization code is analogous for 850hPa temperature.)</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
image(z500_2015[ , , 1],
      col = hcl.colors(20, &quot;viridis&quot;), # for temperature, the color scheme used is YlOrRd 
      xaxt = &#39;n&#39;,
      yaxt = &#39;n&#39;,
      main = &quot;500hPa geopotential&quot;
)</code></pre>
</div>
<p>The maps show how pressure<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> and temperature strongly depend on latitude. Furthermore, its easy to spot the <a href="https://en.wikipedia.org/wiki/Atmospheric_wave">atmospheric waves</a>:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="images/viz.png" alt="Spatial distribution of 500hPa geopotential and 850 hPa temperature for 2015/01/01 0:00h." width="726" />
<p class="caption">
Figure 1: Spatial distribution of 500hPa geopotential and 850 hPa temperature for 2015/01/01 0:00h.
</p>
</div>
</div>
<p>For training, validation and testing, we choose consecutive years: 2015, 2016, and 2017, respectively.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
z500_train &lt;- (tidync(&quot;geopotential_500/geopotential_500hPa_2015_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]

t850_train &lt;- (tidync(&quot;temperature_850/temperature_850hPa_2015_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]

z500_valid &lt;- (tidync(&quot;geopotential_500/geopotential_500hPa_2016_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]

t850_valid &lt;- (tidync(&quot;temperature_850/temperature_850hPa_2016_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]

z500_test &lt;- (tidync(&quot;geopotential_500/geopotential_500hPa_2017_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]

t850_test &lt;- (tidync(&quot;temperature_850/temperature_850hPa_2017_5.625deg.nc&quot;) %&gt;% hyper_array())[[1]]</code></pre>
</div>
<p>Since geopotential and temperature will be treated as channels, we concatenate the corresponding arrays. To transform the data into the format needed for images, a permutation is necessary:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_all &lt;- abind::abind(z500_train, t850_train, along = 4)
train_all &lt;- aperm(train_all, perm = c(3, 2, 1, 4))
dim(train_all)</code></pre>
</div>
<pre><code>
[1] 8760 32 64 2</code></pre>
<p>All data will be standardized according to mean and standard deviation as obtained from the training set:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
level_means &lt;- apply(train_all, 4, mean)
level_sds &lt;- apply(train_all, 4, sd)

round(level_means, 2)</code></pre>
</div>
<pre><code>
54124.91  274.8</code></pre>
<p>In words, the mean geopotential height (see footnote 5 for more on this term), as measured at an isobaric surface of 500hPa, amounts to about 5400 metres<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, while the mean temperature at the 850hPa level approximates 275 Kelvin (about 2 degrees Celsius).</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train &lt;- train_all
train[, , , 1] &lt;- (train[, , , 1] - level_means[1]) / level_sds[1]
train[, , , 2] &lt;- (train[, , , 2] - level_means[2]) / level_sds[2]

valid_all &lt;- abind::abind(z500_valid, t850_valid, along = 4)
valid_all &lt;- aperm(valid_all, perm = c(3, 2, 1, 4))

valid &lt;- valid_all
valid[, , , 1] &lt;- (valid[, , , 1] - level_means[1]) / level_sds[1]
valid[, , , 2] &lt;- (valid[, , , 2] - level_means[2]) / level_sds[2]

test_all &lt;- abind::abind(z500_test, t850_test, along = 4)
test_all &lt;- aperm(test_all, perm = c(3, 2, 1, 4))

test &lt;- test_all
test[, , , 1] &lt;- (test[, , , 1] - level_means[1]) / level_sds[1]
test[, , , 2] &lt;- (test[, , , 2] - level_means[2]) / level_sds[2]</code></pre>
</div>
<p>Well attempt to predict three days ahead.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
lead_time &lt;- 3 * 24 # 3d</code></pre>
</div>
<p>Now all that remains to be done is construct the actual <em>datasets</em>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
batch_size &lt;- 32

train_x &lt;- train %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_take(dim(train)[1] - lead_time)

train_y &lt;- train %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_skip(lead_time)

train_ds &lt;- zip_datasets(train_x, train_y) %&gt;%
  dataset_shuffle(buffer_size = dim(train)[1] - lead_time) %&gt;%
  dataset_batch(batch_size = batch_size, drop_remainder = TRUE)

valid_x &lt;- valid %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_take(dim(valid)[1] - lead_time)

valid_y &lt;- valid %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_skip(lead_time)

valid_ds &lt;- zip_datasets(valid_x, valid_y) %&gt;%
  dataset_batch(batch_size = batch_size, drop_remainder = TRUE)

test_x &lt;- test %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_take(dim(test)[1] - lead_time)

test_y &lt;- test %&gt;%
  tensor_slices_dataset() %&gt;%
  dataset_skip(lead_time)

test_ds &lt;- zip_datasets(test_x, test_y) %&gt;%
  dataset_batch(batch_size = batch_size, drop_remainder = TRUE)</code></pre>
</div>
<p>Lets proceed to defining the model.</p>
<h2 id="basic-cnn-with-periodic-convolutions">Basic CNN with periodic convolutions</h2>
<p>The model is a straightforward convnet, with one exception: Instead of plain convolutions, it uses slightly more sophisticated ones that wrap around longitudinally.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
periodic_padding_2d &lt;- function(pad_width,
                                name = NULL) {
  
  keras_model_custom(name = name, function(self) {
    self$pad_width &lt;- pad_width
    
    function (x, mask = NULL) {
      x &lt;- if (self$pad_width == 0) {
        x
      } else {
        lon_dim &lt;- dim(x)[3]
        pad_width &lt;- tf$cast(self$pad_width, tf$int32)
        # wrap around for longitude
        tf$concat(list(x[, ,-pad_width:lon_dim,],
                       x,
                       x[, , 1:pad_width,]),
                  axis = 2L) %&gt;%
          tf$pad(list(
            list(0L, 0L),
            # zero-pad for latitude
            list(pad_width, pad_width),
            list(0L, 0L),
            list(0L, 0L)
          ))
      }
    }
  })
}

periodic_conv_2d &lt;- function(filters,
                             kernel_size,
                             name = NULL) {
  
  keras_model_custom(name = name, function(self) {
    self$padding &lt;- periodic_padding_2d(pad_width = (kernel_size - 1) / 2)
    self$conv &lt;-
      layer_conv_2d(filters = filters,
                    kernel_size = kernel_size,
                    padding = &#39;valid&#39;)
    
    function (x, mask = NULL) {
      x %&gt;% self$padding() %&gt;% self$conv()
    }
  })
}</code></pre>
</div>
<p>For our purposes of establishing a deep-learning baseline that is fast to train, CNN architecture and parameter defaults are chosen to be simple and moderate, respectively:<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
periodic_cnn &lt;- function(filters = c(64, 64, 64, 64, 2),
                         kernel_size = c(5, 5, 5, 5, 5),
                         dropout = rep(0.2, 5),
                         name = NULL) {
  
  keras_model_custom(name = name, function(self) {
    
    self$conv1 &lt;-
      periodic_conv_2d(filters = filters[1], kernel_size = kernel_size[1])
    self$act1 &lt;- layer_activation_leaky_relu()
    self$drop1 &lt;- layer_dropout(rate = dropout[1])
    self$conv2 &lt;-
      periodic_conv_2d(filters = filters[2], kernel_size = kernel_size[2])
    self$act2 &lt;- layer_activation_leaky_relu()
    self$drop2 &lt;- layer_dropout(rate =dropout[2])
    self$conv3 &lt;-
      periodic_conv_2d(filters = filters[3], kernel_size = kernel_size[3])
    self$act3 &lt;- layer_activation_leaky_relu()
    self$drop3 &lt;- layer_dropout(rate = dropout[3])
    self$conv4 &lt;-
      periodic_conv_2d(filters = filters[4], kernel_size = kernel_size[4])
    self$act4 &lt;- layer_activation_leaky_relu()
    self$drop4 &lt;- layer_dropout(rate = dropout[4])
    self$conv5 &lt;-
      periodic_conv_2d(filters = filters[5], kernel_size = kernel_size[5])
    
    function (x, mask = NULL) {
      x %&gt;%
        self$conv1() %&gt;%
        self$act1() %&gt;%
        self$drop1() %&gt;%
        self$conv2() %&gt;%
        self$act2() %&gt;%
        self$drop2() %&gt;%
        self$conv3() %&gt;%
        self$act3() %&gt;%
        self$drop3() %&gt;%
        self$conv4() %&gt;%
        self$act4() %&gt;%
        self$drop4() %&gt;%
        self$conv5()
    }
  })
}

model &lt;- periodic_cnn()</code></pre>
</div>
<h2 id="training">Training</h2>
<p>In that same spirit of default-ness, we train with MSE loss and Adam optimizer.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
loss &lt;- tf$keras$losses$MeanSquaredError(reduction = tf$keras$losses$Reduction$SUM)
optimizer &lt;- optimizer_adam()

train_loss &lt;- tf$keras$metrics$Mean(name=&#39;train_loss&#39;)

valid_loss &lt;- tf$keras$metrics$Mean(name=&#39;test_loss&#39;)

train_step &lt;- function(train_batch) {

  with (tf$GradientTape() %as% tape, {
    predictions &lt;- model(train_batch[[1]])
    l &lt;- loss(train_batch[[2]], predictions)
  })

  gradients &lt;- tape$gradient(l, model$trainable_variables)
  optimizer$apply_gradients(purrr::transpose(list(
    gradients, model$trainable_variables
  )))

  train_loss(l)

}

valid_step &lt;- function(valid_batch) {
  predictions &lt;- model(valid_batch[[1]])
  l &lt;- loss(valid_batch[[2]], predictions)
  
  valid_loss(l)
}

training_loop &lt;- tf_function(autograph(function(train_ds, valid_ds, epoch) {
  
  for (train_batch in train_ds) {
    train_step(train_batch)
  }
  
  for (valid_batch in valid_ds) {
    valid_step(valid_batch)
  }
  
  tf$print(&quot;MSE: train: &quot;, train_loss$result(), &quot;, validation: &quot;, valid_loss$result()) 
    
}))</code></pre>
</div>
<p>Depicted graphically, we see that the model trains well, but extrapolation does not surpass a certain threshold (which is reached early, after training for just two epochs).</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="figure"><span id="fig:unnamed-chunk-16"></span>
<img src="images/history.png" alt="MSE per epoch on training and validation sets." width="363" />
<p class="caption">
Figure 2: MSE per epoch on training and validation sets.
</p>
</div>
</div>
<p>This is not too surprising though, given the models architectural simplicity and modest size.</p>
<h2 id="evaluation">Evaluation</h2>
<p>Here, we first present two other baselines, which  given a highly complex and chaotic system like the atmosphere  may sound irritatingly simple and yet, be pretty hard to beat. The metric used for comparison is <em>latitudinally weighted root-mean-square error</em>. Latitudinal weighting up-weights the lower latitudes and down-weights the upper ones.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
deg2rad &lt;- function(d) {
  (d / 180) * pi
}

lats &lt;- tidync(&quot;geopotential_500/geopotential_500hPa_2015_5.625deg.nc&quot;)$transforms$lat %&gt;%
  select(lat) %&gt;%
  pull()

lat_weights &lt;- cos(deg2rad(lats))
lat_weights &lt;- lat_weights / mean(lat_weights)

weighted_rmse &lt;- function(forecast, ground_truth) {
  error &lt;- (forecast - ground_truth) ^ 2
  for (i in seq_along(lat_weights)) {
    error[, i, ,] &lt;- error[, i, ,] * lat_weights[i]
  }
  apply(error, 4, mean) %&gt;% sqrt()
}</code></pre>
</div>
<h4 id="baseline-1-weekly-climatology">Baseline 1: Weekly climatology</h4>
<p>In general, climatology refers to long-term averages computed over defined time ranges. Here, we first calculate weekly averages based on the training set. These averages are then used to forecast the variables in question for the time period used as test set.</p>
<p>Step one makes use of <code>tidync</code>, <code>ncmeta</code>, <code>RNetCDF</code> and <code>lubridate</code> to compute weekly averages for 2015, following the <a href="https://en.wikipedia.org/wiki/ISO_week_date">ISO week date system</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_file &lt;- &quot;geopotential_500/geopotential_500hPa_2015_5.625deg.nc&quot;

times_train &lt;- (tidync(train_file) %&gt;% activate(&quot;D2&quot;) %&gt;% hyper_array())$time

time_unit_train &lt;- ncmeta::nc_atts(train_file, &quot;time&quot;) %&gt;%
  tidyr::unnest(cols = c(value)) %&gt;%
  dplyr::filter(name == &quot;units&quot;)

time_parts_train &lt;- RNetCDF::utcal.nc(time_unit_train$value, times_train)

iso_train &lt;- ISOdate(
  time_parts_train[, &quot;year&quot;],
  time_parts_train[, &quot;month&quot;],
  time_parts_train[, &quot;day&quot;],
  time_parts_train[, &quot;hour&quot;],
  time_parts_train[, &quot;minute&quot;],
  time_parts_train[, &quot;second&quot;]
)

isoweeks_train &lt;- map(iso_train, isoweek) %&gt;% unlist()

train_by_week &lt;- apply(train_all, c(2, 3, 4), function(x) {
  tapply(x, isoweeks_train, function(y) {
    mean(y)
  })
})

dim(train_by_week)</code></pre>
</div>
<pre><code>
53 32 64 2</code></pre>
<p>Step two then runs through the test set, mapping dates to corresponding ISO weeks and associating the weekly averages from the training set:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test_file &lt;- &quot;geopotential_500/geopotential_500hPa_2017_5.625deg.nc&quot;

times_test &lt;- (tidync(test_file) %&gt;% activate(&quot;D2&quot;) %&gt;% hyper_array())$time

time_unit_test &lt;- ncmeta::nc_atts(test_file, &quot;time&quot;) %&gt;%
  tidyr::unnest(cols = c(value)) %&gt;%
  dplyr::filter(name == &quot;units&quot;)

time_parts_test &lt;- RNetCDF::utcal.nc(time_unit_test$value, times_test)

iso_test &lt;- ISOdate(
  time_parts_test[, &quot;year&quot;],
  time_parts_test[, &quot;month&quot;],
  time_parts_test[, &quot;day&quot;],
  time_parts_test[, &quot;hour&quot;],
  time_parts_test[, &quot;minute&quot;],
  time_parts_test[, &quot;second&quot;]
)

isoweeks_test &lt;- map(iso_test, isoweek) %&gt;% unlist()

climatology_forecast &lt;- test_all

for (i in 1:dim(climatology_forecast)[1]) {
  week &lt;- isoweeks_test[i]
  lookup &lt;- train_by_week[week, , , ]
  climatology_forecast[i, , ,] &lt;- lookup
}</code></pre>
</div>
<p>For this baseline, the latitudinally-weighted RMSE amounts to roughly 975 for geopotential and 4 for temperature.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
wrmse &lt;- weighted_rmse(climatology_forecast, test_all)
round(wrmse, 2)</code></pre>
</div>
<pre><code>
974.50   4.09</code></pre>
<h4 id="baseline-2-persistence-forecast">Baseline 2: Persistence forecast</h4>
<p>The second baseline commonly used makes a straightforward assumption: Tomorrows weather is todays weather, or, in our case: In three days, things will be just like they are now.</p>
<p>Computation for this metric is almost a one-liner. And as it turns out, for the given lead time (three days), performance is not too dissimilar from obtained by means of weekly climatology:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
persistence_forecast &lt;- test_all[1:(dim(test_all)[1] - lead_time), , ,]

test_period &lt;- test_all[(lead_time + 1):dim(test_all)[1], , ,]

wrmse &lt;- weighted_rmse(persistence_forecast, test_period)

round(wrmse, 2)</code></pre>
</div>
<pre><code>
937.55  4.31</code></pre>
<h4 id="baseline-3-simple-convnet">Baseline 3: Simple convnet</h4>
<p>How does the simple deep learning model stack up against those two?</p>
<p>To answer that question, we first need to obtain predictions on the test set.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test_wrmses &lt;- data.frame()

test_loss &lt;- tf$keras$metrics$Mean(name = &#39;test_loss&#39;)

test_step &lt;- function(test_batch, batch_index) {
  predictions &lt;- model(test_batch[[1]])
  l &lt;- loss(test_batch[[2]], predictions)
  
  predictions &lt;- predictions %&gt;% as.array()
  predictions[, , , 1] &lt;- predictions[, , , 1] * level_sds[1] + level_means[1]
  predictions[, , , 2] &lt;- predictions[, , , 2] * level_sds[2] + level_means[2]
  
  wrmse &lt;- weighted_rmse(predictions, test_all[batch_index:(batch_index + 31), , ,])
  test_wrmses &lt;&lt;- test_wrmses %&gt;% bind_rows(c(z = wrmse[1], temp = wrmse[2]))

  test_loss(l)
}

test_iterator &lt;- as_iterator(test_ds)

batch_index &lt;- 0
while (TRUE) {
  test_batch &lt;- test_iterator %&gt;% iter_next()
  if (is.null(test_batch))
    break
  batch_index &lt;- batch_index + 1
  test_step(test_batch, as.integer(batch_index))
}

test_loss$result() %&gt;% as.numeric()</code></pre>
</div>
<pre><code>
3821.016</code></pre>
<p>Thus, average loss on the test set parallels that seen on the validation set. As to latitudinally weighted RMSE, it turns out to be higher for the DL baseline than for the other two:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
apply(test_wrmses, 2, mean) %&gt;% round(2)</code></pre>
</div>
<pre><code>
      z    temp 
1521.47    7.70 </code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>At first glance, seeing the DL baseline perform worse than the others might feel anticlimactic. But if you think about it, there is no need to be disappointed.</p>
<p>For one, given the enormous complexity of the task, these heuristics are not as easy to outsmart. Take persistence: Depending on lead time - how far into the future were forecasting - the wisest guess may actually be that everything will stay the same. What would you guess the weather will look like in five minutes?  Same with weekly climatology: Looking back at how warm it was, at a given location, that same week two years ago, does not in general sound like a bad strategy.</p>
<p>Second, the DL baseline shown is as basic as it can get, architecture- as well as parameter-wise. More sophisticated and powerful architectures have been developed that not just by far surpass the baselines, but can even compete with physical models (cf.especially Rasp and Thuerey <span class="citation" data-cites="rasp2020purely">(Rasp and Thuerey <a href="#ref-rasp2020purely" role="doc-biblioref">2020</a>)</span> already mentioned above). Unfortunately, models like that need to be trained on <em>a lot</em> of data.</p>
<p>However, other weather-related applications (other than medium-range forecasting, that is) may be more in reach for individuals interested in the topic. For those, we hope we have given a useful introduction. Thanks for reading!</p>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-weatherbench">
<p>Rasp, Stephan, Peter D. Dueben, Sebastian Scher, Jonathan A. Weyn, Soukayna Mouatadid, and Nils Thuerey. 2020. WeatherBench: A benchmark dataset for data-driven weather forecasting. <em>arXiv E-Prints</em>, February, arXiv:2002.00469. <a href="http://arxiv.org/abs/2002.00469">http://arxiv.org/abs/2002.00469</a>.</p>
</div>
<div id="ref-rasp2020purely">
<p>Rasp, Stephan, and Nils Thuerey. 2020. Purely Data-Driven Medium-Range Weather Forecasting Achieves Comparable Skill to Physical Models at Similar Resolution. <a href="http://arxiv.org/abs/2008.08626">http://arxiv.org/abs/2008.08626</a>.</p>
</div>
<div id="ref-weyn">
<p>Weyn, Jonathan A., Dale R. Durran, and Rich Caruana. n.d. Improving Data-Driven Global Weather Prediction Using Deep Convolutional Neural Networks on a Cubed Sphere. <em>Journal of Advances in Modeling Earth Systems</em> n/a (n/a): e2020MS002109. <a href="https://doi.org/10.1029/2020MS002109">https://doi.org/10.1029/2020MS002109</a>.</p>
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><em>An die Nachgeborenen, 1934-38.</em> The atrocities referred to are those of Nazi Germany.<a href="#fnref1" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn2" role="doc-endnote"><p>Four, because in addition to three spatial dimensions, there is the time dimension.<a href="#fnref2" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn3" role="doc-endnote"><p>mostly<a href="#fnref3" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn4" role="doc-endnote"><p>Pressure and altitude are related by the <a href="https://en.wikipedia.org/wiki/Barometric_formula">barometric equation</a>. On weather maps, pressure is often used to represent the vertical dimension.<a href="#fnref4" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn5" role="doc-endnote"><p>Whereas we normally might think of atmospheric pressure as varying at a fixed height (for example, at sea level), meteorologists like to display things the other way round, displaying variable heights at fixed constant-pressure (isobaric) surfaces. Still, intuitively these may be read in the same way: High pressure at a given location means that some predefined pressure level is attained at <em>higher altitude</em> than in some low-pressure location. To be precise, these kinds of inverted pressure maps normally display <em>geopotential height</em>, measured in metres, not <em>geopotential</em>, the variable were dealing with here. <em>Geopotential</em> (without the height) refers to gravitational potential energy per unit mass; it is obtained by multiplying by gravitational acceleration, and is measured in metres squared per second squared. The measures are not a hundred percent equivalent, because gravitational acceleration varies with latitude and longitude as well as elevation.<a href="#fnref5" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn6" role="doc-endnote"><p>As explained in the previous footnote, geopotential height is geopotential divided by standard gravitational acceleration, roughly, 9.8 metres per seconds squared.<a href="#fnref6" class="footnote-back" role="doc-backlink"></a></p></li>
<li id="fn7" role="doc-endnote"><p>These are the same filter and kernel sizes as employed in <a href="https://github.com/pangeo-data/WeatherBench/blob/master/notebooks/3-cnn-example.ipynb">Rasp et al.'s simple CNN example on github</a>.<a href="#fnref7" class="footnote-back" role="doc-backlink"></a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-09-01-weather-prediction/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=An%20introduction%20to%20weather%20forecasting%20with%20deep%20learning&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-09-01-weather-prediction%2F">
        <i class="fab fa-twitter"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-09-01-weather-prediction%2F&amp;title=An%20introduction%20to%20weather%20forecasting%20with%20deep%20learning">
        <i class="fab fa-linkedin"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/';
  this.page.identifier = 'posts/2020-09-01-weather-prediction/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    document.querySelector("a[href='#category:R']").parentNode.style.display = "None";
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerText == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2020, Sept. 1). RStudio AI Blog: An introduction to weather forecasting with deep learning. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanaweatherforecasting,
  author = {Keydana, Sigrid},
  title = {RStudio AI Blog: An introduction to weather forecasting with deep learning},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
