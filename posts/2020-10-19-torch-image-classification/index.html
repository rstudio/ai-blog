<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
<title>Posit AI Blog: Classifying images with torch</title>

<meta property="description" itemprop="description" content="We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2020-10-19"/>
<meta property="article:created" itemprop="dateCreated" content="2020-10-19"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Posit AI Blog: Classifying images with torch"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/images/image_classif_birds.png"/>
<meta property="og:image:width" content="500"/>
<meta property="og:image:height" content="333"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Posit AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Posit AI Blog: Classifying images with torch"/>
<meta property="twitter:description" content="We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/images/image_classif_birds.png"/>
<meta property="twitter:image:width" content="500"/>
<meta property="twitter:image:height" content="333"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Posit AI Blog: Classifying images with torch"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2020/10/19"/>
<meta name="citation_publication_date" content="2020/10/19"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Deep residual learning for image recognition;citation_volume=abs/1512.03385;citation_author=Kaiming He;citation_author=Xiangyu Zhang;citation_author=Shaoqing Ren;citation_author=Jian Sun"/>
  <meta name="citation_reference" content="citation_title=No more pesky learning rate guessing games;citation_volume=abs/1506.01186;citation_author=Leslie N. Smith"/>
  <meta name="citation_reference" content="citation_title=SGDR: Stochastic gradient descent with restarts;citation_volume=abs/1608.03983;citation_author=Ilya Loshchilov;citation_author=Frank Hutter"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","date","categories","bibliography","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Classifying images with torch"]},{"type":"character","attributes":{},"value":["We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanatorchimageclassification"]},{"type":"character","attributes":{},"value":["10-19-2020"]},{"type":"character","attributes":{},"value":["Torch","R","Image Recognition & Image Processing"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["images/image_classif_birds.png"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","images/image_classif_birds.png","images/lr_finder.png","images/one_cycle_lr.png","torch-image-classification_files/anchor-4.2.2/anchor.min.js","torch-image-classification_files/bowser-1.9.3/bowser.min.js","torch-image-classification_files/distill-2.2.21/template.v2.js","torch-image-classification_files/header-attrs-2.3/header-attrs.js","torch-image-classification_files/header-attrs-2.4.6/header-attrs.js","torch-image-classification_files/jquery-1.11.3/jquery.min.js","torch-image-classification_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

hr.section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  margin: 0px;
}


d-byline {
  border-top: none;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
  border-top: none;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

/* tweak for Pandoc numbered line within distill */
d-article pre.numberSource code > span {
    left: -2em;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // separator
  var separator = '<hr class="section-separator" style="clear: both"/>';
  // prepend separator above appendix
  $('.d-byline').before(separator);
  $('.d-article').before(separator);

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme, except when numbering line
  // in code chunk
  $('pre:not(.numberLines) code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      var author_name = front_matter.authors[i].author
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.29/header-attrs.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script defer data-domain="blogs.rstudio.com" src="https://plausible.io/js/plausible.js"></script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Classifying images with torch","description":"We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-10-19T00:00:00.000+00:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/posit.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Classifying images with torch</h1>

<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:Torch" class="dt-tag">Torch</a>
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:Image_Recognition_&amp;_Image_Processing" class="dt-tag">Image Recognition &amp; Image Processing</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>We learn about transfer learning, input pipelines, and learning rate schedulers, all while using torch to tell apart species of beautiful birds.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>10-19-2020
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#data-loading-and-preprocessing">Data loading and preprocessing</a></li>
<li><a href="#model">Model</a></li>
<li><a href="#training">Training</a></li>
<li><a href="#test-set-accuracy">Test set accuracy</a></li>
<li><a href="#wrapup">Wrapup</a></li>
</ul>
</nav>
</div>
<p>In recent posts, we’ve been exploring essential <code>torch</code> functionality: <a href="https://blogs.rstudio.com/ai/posts/2020-10-01-torch-network-from-scratch/">tensors</a>, the sine qua non of every deep learning framework; <a href="https://blogs.rstudio.com/ai/posts/2020-10-05-torch-network-with-autograd">autograd</a>, <code>torch</code>’s implementation of reverse-mode automatic differentiation; <a href="https://blogs.rstudio.com/ai/posts/2020-10-07-torch-modules">modules</a>, composable building blocks of neural networks; and <a href="https://blogs.rstudio.com/ai/posts/2020-10-09-torch-optim/">optimizers</a>, the – well – optimization algorithms that <code>torch</code> provides.</p>
<p>But we haven’t really had our “hello world” moment yet, at least not if by “hello world” you mean the inevitable <em>deep learning experience of classifying pets</em>. Cat or dog? Beagle or boxer? Chinook or Chihuahua? We’ll distinguish ourselves by asking a (slightly) different question: What kind of bird?</p>
<p>Topics we’ll address on our way:</p>
<ul>
<li><p>The core roles of <code>torch</code> <em>datasets</em> and <em>data loaders</em>, respectively.</p></li>
<li><p>How to apply <code>transform</code>s, both for image preprocessing and data augmentation.</p></li>
<li><p>How to use Resnet <span class="citation" data-cites="HeZRS15">(<a href="#ref-HeZRS15" role="doc-biblioref">He et al. 2015</a>)</span>, a pre-trained model that comes with <code>torchvision</code>, for transfer learning.</p></li>
<li><p>How to use learning rate schedulers, and in particular, the one-cycle learning rate algorithm [@abs-1708-07120].</p></li>
<li><p>How to find a good initial learning rate.</p></li>
</ul>
<p>For convenience, the code is available on <a href="https://colab.research.google.com/drive/1OJzzqiQVbh3ZdLB2L2t_DhBGInlh9o-k?usp=sharing">Google Colaboratory</a> – no copy-pasting required.</p>
<h2 id="data-loading-and-preprocessing">Data loading and preprocessing</h2>
<p>The example dataset used here is available on <a href="https://www.kaggle.com/gpiosenka/100-bird-species/data" class="uri">Kaggle</a>.</p>
<p>Conveniently, it may be obtained using <a href="https://github.com/mlverse/torchdatasets"><code>torchdatasets</code></a>, which uses <a href="https://github.com/rstudio/pins"><code>pins</code></a> for authentication, retrieval and storage. To enable <code>pins</code> to manage your Kaggle downloads, please follow the instructions <a href="https://pins.rstudio.com/articles/boards-kaggle.html">here</a>.</p>
<p>This dataset is very “clean,” unlike the images we may be used to from, e.g., <a href="http://image-net.org/">ImageNet</a>. To help with generalization, we introduce noise during training – in other words, we perform <em>data augmentation</em>. In <code>torchvision</code>, data augmentation is part of an <em>image processing pipeline</em> that first converts an image to a tensor, and then applies any transformations such as resizing, cropping, normalization, or various forms of distorsion.</p>
<p>Below are the transformations performed on the training set. Note how most of them are for data augmentation, while normalization is done to comply with what’s expected by ResNet.</p>
<h4 id="image-preprocessing-pipeline">Image preprocessing pipeline</h4>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://torch.mlverse.org/docs'>torch</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://torchvision.mlverse.org'>torchvision</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://mlverse.github.io/torchdatasets/'>torchdatasets</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://pins.rstudio.com/'>pins</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://ggplot2.tidyverse.org'>ggplot2</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>device</span> <span class='op'>&lt;-</span> <span class='kw'>if</span> <span class='op'>(</span><span class='fu'>cuda_is_available</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='fu'>torch_device</span><span class='op'>(</span><span class='st'>"cuda:0"</span><span class='op'>)</span> <span class='kw'>else</span> <span class='st'>"cpu"</span></span>
<span></span>
<span><span class='va'>train_transforms</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='va'>img</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># first convert image to tensor</span></span>
<span>    <span class='fu'>transform_to_tensor</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># then move to the GPU (if available)</span></span>
<span>    <span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='va'>x</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># data augmentation</span></span>
<span>    <span class='fu'>transform_random_resized_crop</span><span class='op'>(</span>size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>224</span>, <span class='fl'>224</span><span class='op'>)</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># data augmentation</span></span>
<span>    <span class='fu'>transform_color_jitter</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># data augmentation</span></span>
<span>    <span class='fu'>transform_random_horizontal_flip</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='co'># normalize according to what is expected by resnet</span></span>
<span>    <span class='fu'>transform_normalize</span><span class='op'>(</span>mean <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.485</span>, <span class='fl'>0.456</span>, <span class='fl'>0.406</span><span class='op'>)</span>, std <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.229</span>, <span class='fl'>0.224</span>, <span class='fl'>0.225</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>On the validation set, we don’t want to introduce noise, but still need to resize, crop, and normalize the images. The test set should be treated identically.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>valid_transforms</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='va'>img</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'>transform_to_tensor</span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='va'>x</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'>transform_resize</span><span class='op'>(</span><span class='fl'>256</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'>transform_center_crop</span><span class='op'>(</span><span class='fl'>224</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'>transform_normalize</span><span class='op'>(</span>mean <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.485</span>, <span class='fl'>0.456</span>, <span class='fl'>0.406</span><span class='op'>)</span>, std <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.229</span>, <span class='fl'>0.224</span>, <span class='fl'>0.225</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>test_transforms</span> <span class='op'>&lt;-</span> <span class='va'>valid_transforms</span></span></code></pre>
</div>
</div>
<p>And now, let’s get the data, nicely divided into training, validation and test sets. Additionally, we tell the corresponding R objects what transformations they’re expected to apply:<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_ds</span> <span class='op'>&lt;-</span> <span class='fu'>bird_species_dataset</span><span class='op'>(</span><span class='st'>"data"</span>, download <span class='op'>=</span> <span class='cn'>TRUE</span>, transform <span class='op'>=</span> <span class='va'>train_transforms</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>valid_ds</span> <span class='op'>&lt;-</span> <span class='fu'>bird_species_dataset</span><span class='op'>(</span><span class='st'>"data"</span>, split <span class='op'>=</span> <span class='st'>"valid"</span>, transform <span class='op'>=</span> <span class='va'>valid_transforms</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_ds</span> <span class='op'>&lt;-</span> <span class='fu'>bird_species_dataset</span><span class='op'>(</span><span class='st'>"data"</span>, split <span class='op'>=</span> <span class='st'>"test"</span>, transform <span class='op'>=</span> <span class='va'>test_transforms</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Two things to note. First, transformations are part of the <em>dataset</em> concept, as opposed to the <em>data loader</em> we’ll encounter shortly. Second, let’s take a look at how the images have been stored on disk. The overall directory structure (starting from <code>data</code>, which we specified as the root directory to be used) is this:</p>
<pre><code>data/bird_species/train
data/bird_species/valid
data/bird_species/test</code></pre>
<p>In the <code>train</code>, <code>valid</code>, and <code>test</code> directories, different classes of images reside in their own folders. For example, here is the directory layout for the first three classes in the test set:</p>
<pre><code>data/bird_species/test/ALBATROSS/
 - data/bird_species/test/ALBATROSS/1.jpg
 - data/bird_species/test/ALBATROSS/2.jpg
 - data/bird_species/test/ALBATROSS/3.jpg
 - data/bird_species/test/ALBATROSS/4.jpg
 - data/bird_species/test/ALBATROSS/5.jpg
 
data/test/&#39;ALEXANDRINE PARAKEET&#39;/
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/1.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/2.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/3.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/4.jpg
 - data/bird_species/test/&#39;ALEXANDRINE PARAKEET&#39;/5.jpg
 
 data/test/&#39;AMERICAN BITTERN&#39;/
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/1.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/2.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/3.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/4.jpg
 - data/bird_species/test/&#39;AMERICAN BITTERN&#39;/5.jpg</code></pre>
<p>This is exactly the kind of layout expected by <code>torch</code>s <code>image_folder_dataset()</code> – and really <code>bird_species_dataset()</code> instantiates a subtype of this class. Had we downloaded the data manually, respecting the required directory structure, we could have created the datasets like so:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># e.g.</span></span>
<span><span class='va'>train_ds</span> <span class='op'>&lt;-</span> <span class='fu'>image_folder_dataset</span><span class='op'>(</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>data_dir</span>, <span class='st'>"train"</span><span class='op'>)</span>,</span>
<span>  transform <span class='op'>=</span> <span class='va'>train_transforms</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Now that we got the data, let’s see how many items there are in each set.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_ds</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>valid_ds</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>test_ds</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>31316
1125
1125</code></pre>
<p>That training set is really big! It’s thus recommended to run this on GPU, or just play around with the provided Colab notebook.</p>
<p>With so many samples, we’re curious how many classes there are.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>class_names</span> <span class='op'>&lt;-</span> <span class='va'>test_ds</span><span class='op'>$</span><span class='va'>classes</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>class_names</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>225</code></pre>
<p>So we <em>do</em> have a substantial training set, but the task is formidable as well: We’re going to tell apart no less than 225 different bird species.</p>
<h4 id="data-loaders">Data loaders</h4>
<p>While <em>datasets</em> know what to do with each single item, <em>data loaders</em> know how to treat them collectively. How many samples make up a batch? Do we want to feed them in the same order always, or instead, have a different order chosen for every epoch?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>64</span></span>
<span></span>
<span><span class='va'>train_dl</span> <span class='op'>&lt;-</span> <span class='fu'>dataloader</span><span class='op'>(</span><span class='va'>train_ds</span>, batch_size <span class='op'>=</span> <span class='va'>batch_size</span>, shuffle <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span><span class='va'>valid_dl</span> <span class='op'>&lt;-</span> <span class='fu'>dataloader</span><span class='op'>(</span><span class='va'>valid_ds</span>, batch_size <span class='op'>=</span> <span class='va'>batch_size</span><span class='op'>)</span></span>
<span><span class='va'>test_dl</span> <span class='op'>&lt;-</span> <span class='fu'>dataloader</span><span class='op'>(</span><span class='va'>test_ds</span>, batch_size <span class='op'>=</span> <span class='va'>batch_size</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Data loaders, too, may be queried for their length. Now length means: How many batches?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_dl</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span> </span>
<span><span class='va'>valid_dl</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span> </span>
<span><span class='va'>test_dl</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span>  </span></code></pre>
</div>
</div>
<pre><code>490
18
18</code></pre>
<h4 id="some-birds">Some birds</h4>
<p>Next, let’s view a few images from the test set. We can retrieve the first batch – images and corresponding classes – by creating an iterator from the <code>dataloader</code> and calling <code>next()</code> on it:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># for display purposes, here we are actually using a batch_size of 24</span></span>
<span><span class='va'>batch</span> <span class='op'>&lt;-</span> <span class='va'>train_dl</span><span class='op'>$</span><span class='fu'>.iter</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>.next</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p><code>batch</code> is a list, the first item being the image tensors:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>size</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>[1]  24   3 224 224</code></pre>
<p>And the second, the classes:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>size</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>[1] 24</code></pre>
<p>Classes are coded as integers, to be used as indices in a vector of class names. We’ll use those for labeling the images.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>classes</span> <span class='op'>&lt;-</span> <span class='va'>batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>classes</span></span></code></pre>
</div>
</div>
<pre><code>torch_tensor 
 1
 1
 1
 1
 1
 2
 2
 2
 2
 2
 3
 3
 3
 3
 3
 4
 4
 4
 4
 4
 5
 5
 5
 5
[ GPULongType{24} ]</code></pre>
<p>The image tensors have shape <code>batch_size x num_channels x height x width</code>. For plotting using <code>as.raster()</code>, we need to reshape the images such that channels come last. We also undo the normalization applied by the <code>dataloader</code>.</p>
<p>Here are the first twenty-four images:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>images</span> <span class='op'>&lt;-</span> <span class='fu'>as_array</span><span class='op'>(</span><span class='va'>batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/aperm.html'>aperm</a></span><span class='op'>(</span>perm <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>3</span>, <span class='fl'>4</span>, <span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>mean</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.485</span>, <span class='fl'>0.456</span>, <span class='fl'>0.406</span><span class='op'>)</span></span>
<span><span class='va'>std</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.229</span>, <span class='fl'>0.224</span>, <span class='fl'>0.225</span><span class='op'>)</span></span>
<span><span class='va'>images</span> <span class='op'>&lt;-</span> <span class='va'>std</span> <span class='op'>*</span> <span class='va'>images</span> <span class='op'>+</span> <span class='va'>mean</span></span>
<span><span class='va'>images</span> <span class='op'>&lt;-</span> <span class='va'>images</span> <span class='op'>*</span> <span class='fl'>255</span></span>
<span><span class='va'>images</span><span class='op'>[</span><span class='va'>images</span> <span class='op'>&gt;</span> <span class='fl'>255</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fl'>255</span></span>
<span><span class='va'>images</span><span class='op'>[</span><span class='va'>images</span> <span class='op'>&lt;</span> <span class='fl'>0</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/graphics/par.html'>par</a></span><span class='op'>(</span>mfcol <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>4</span>,<span class='fl'>6</span><span class='op'>)</span>, mar <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>4</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>images</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/array-coercion.html'>array_tree</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://rlang.r-lib.org/reference/set_names.html'>set_names</a></span><span class='op'>(</span><span class='va'>class_names</span><span class='op'>[</span><span class='fu'>as_array</span><span class='op'>(</span><span class='va'>classes</span><span class='op'>)</span><span class='op'>]</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>map</a></span><span class='op'>(</span><span class='va'>as.raster</span>, max <span class='op'>=</span> <span class='fl'>255</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/imap.html'>iwalk</a></span><span class='op'>(</span><span class='op'>~</span><span class='op'>{</span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>.x</span><span class='op'>)</span>; <span class='fu'><a href='https://rdrr.io/r/graphics/title.html'>title</a></span><span class='op'>(</span><span class='va'>.y</span><span class='op'>)</span><span class='op'>}</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-page">
<p><img src="images/image_classif_birds.png" width="250" /></p>
</div>
<h2 id="model">Model</h2>
<p>The backbone of our model is a pre-trained instance of ResNet.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>model_resnet18</span><span class='op'>(</span>pretrained <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>But we want to distinguish among our 225 bird species, while ResNet was trained on 1000 different classes. What can we do? We simply replace the output layer.</p>
<p>The new output layer is also the only one whose weights we are going to train – leaving all other ResNet parameters the way they are. Technically, we <em>could</em> perform backpropagation through the complete model, striving to fine-tune ResNet’s weights as well. However, this would slow down training significantly. In fact, the choice is not all-or-none: It is up to us how many of the original parameters to keep fixed, and how many to “set free” for fine tuning. For the task at hand, we’ll be content to just train the newly added output layer: With the abundance of animals, including birds, in ImageNet, we expect the trained ResNet to know a lot about them!</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>model</span><span class='op'>$</span><span class='va'>parameters</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>walk</a></span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>param</span><span class='op'>)</span> <span class='va'>param</span><span class='op'>$</span><span class='fu'>requires_grad_</span><span class='op'>(</span><span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>To replace the output layer, the model is modified in-place:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>num_features</span> <span class='op'>&lt;-</span> <span class='va'>model</span><span class='op'>$</span><span class='va'>fc</span><span class='op'>$</span><span class='va'>in_features</span></span>
<span></span>
<span><span class='va'>model</span><span class='op'>$</span><span class='va'>fc</span> <span class='op'>&lt;-</span> <span class='fu'>nn_linear</span><span class='op'>(</span>in_features <span class='op'>=</span> <span class='va'>num_features</span>, out_features <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>class_names</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Now put the modified model on the GPU (if available):</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='va'>model</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h2 id="training">Training</h2>
<p>For optimization, we use cross entropy loss and stochastic gradient descent.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>criterion</span> <span class='op'>&lt;-</span> <span class='fu'>nn_cross_entropy_loss</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optim_sgd</span><span class='op'>(</span><span class='va'>model</span><span class='op'>$</span><span class='va'>parameters</span>, lr <span class='op'>=</span> <span class='fl'>0.1</span>, momentum <span class='op'>=</span> <span class='fl'>0.9</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h4 id="finding-an-optimally-efficient-learning-rate">Finding an optimally efficient learning rate</h4>
<p>We set the learning rate to <code>0.1</code>, but that is just a formality. As has become widely known due to the excellent lectures by <a href="http://fast.ai">fast.ai</a>, it makes sense to spend some time upfront to determine an efficient learning rate. While out-of-the-box, <code>torch</code> does not provide a tool like fast.ai’s learning rate finder, the logic is straightforward to implement. Here’s how to find a good learning rate, as translated to R from <a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html">Sylvain Gugger’s post</a>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># ported from: https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html</span></span>
<span></span>
<span><span class='va'>losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>log_lrs</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>find_lr</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>init_value</span> <span class='op'>=</span> <span class='fl'>1e-8</span>, <span class='va'>final_value</span> <span class='op'>=</span> <span class='fl'>10</span>, <span class='va'>beta</span> <span class='op'>=</span> <span class='fl'>0.98</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>num</span> <span class='op'>&lt;-</span> <span class='va'>train_dl</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>mult</span> <span class='op'>=</span> <span class='op'>(</span><span class='va'>final_value</span><span class='op'>/</span><span class='va'>init_value</span><span class='op'>)</span><span class='op'>^</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>/</span><span class='va'>num</span><span class='op'>)</span></span>
<span>  <span class='va'>lr</span> <span class='op'>&lt;-</span> <span class='va'>init_value</span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='va'>param_groups</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='va'>lr</span> <span class='op'>&lt;-</span> <span class='va'>lr</span></span>
<span>  <span class='va'>avg_loss</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span>  <span class='va'>best_loss</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span>  <span class='va'>batch_num</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span></span>
<span>  <span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>train_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>    <span class='va'>batch_num</span> <span class='op'>&lt;-</span> <span class='va'>batch_num</span> <span class='op'>+</span> <span class='fl'>1</span></span>
<span>    <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>zero_grad</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>criterion</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span>    <span class='co'>#Compute the smoothed loss</span></span>
<span>    <span class='va'>avg_loss</span> <span class='op'>&lt;-</span> <span class='va'>beta</span> <span class='op'>*</span> <span class='va'>avg_loss</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='va'>beta</span><span class='op'>)</span> <span class='op'>*</span> <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>smoothed_loss</span> <span class='op'>&lt;-</span> <span class='va'>avg_loss</span> <span class='op'>/</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='va'>beta</span><span class='op'>^</span><span class='va'>batch_num</span><span class='op'>)</span></span>
<span>    <span class='co'>#Stop if the loss is exploding</span></span>
<span>    <span class='kw'>if</span> <span class='op'>(</span><span class='va'>batch_num</span> <span class='op'>&gt;</span> <span class='fl'>1</span> <span class='op'>&amp;&amp;</span> <span class='va'>smoothed_loss</span> <span class='op'>&gt;</span> <span class='fl'>4</span> <span class='op'>*</span> <span class='va'>best_loss</span><span class='op'>)</span> <span class='kw'>break</span></span>
<span>    <span class='co'>#Record the best loss</span></span>
<span>    <span class='kw'>if</span> <span class='op'>(</span><span class='va'>smoothed_loss</span> <span class='op'>&lt;</span> <span class='va'>best_loss</span> <span class='op'>||</span> <span class='va'>batch_num</span> <span class='op'>==</span> <span class='fl'>1</span><span class='op'>)</span> <span class='va'>best_loss</span> <span class='op'>&lt;-</span> <span class='va'>smoothed_loss</span></span>
<span></span>
<span>    <span class='co'>#Store the values</span></span>
<span>    <span class='va'>losses</span> <span class='op'>&lt;&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>losses</span>, <span class='va'>smoothed_loss</span><span class='op'>)</span></span>
<span>    <span class='va'>log_lrs</span> <span class='op'>&lt;&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>log_lrs</span>, <span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>lr</span>, <span class='fl'>10</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span>    <span class='va'>loss</span><span class='op'>$</span><span class='fu'>backward</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span>    <span class='co'>#Update the lr for the next step</span></span>
<span>    <span class='va'>lr</span> <span class='op'>&lt;-</span> <span class='va'>lr</span> <span class='op'>*</span> <span class='va'>mult</span></span>
<span>    <span class='va'>optimizer</span><span class='op'>$</span><span class='va'>param_groups</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='va'>lr</span> <span class='op'>&lt;-</span> <span class='va'>lr</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='fu'>find_lr</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>df</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>log_lrs <span class='op'>=</span> <span class='va'>log_lrs</span>, losses <span class='op'>=</span> <span class='va'>losses</span><span class='op'>)</span></span>
<span><span class='fu'>ggplot</span><span class='op'>(</span><span class='va'>df</span>, <span class='fu'>aes</span><span class='op'>(</span><span class='va'>log_lrs</span>, <span class='va'>losses</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'>geom_point</span><span class='op'>(</span>size <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'>theme_classic</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="images/lr_finder.png" width="372" /></p>
</div>
<p>The best learning rate is not the exact one where loss is at a minimum. Instead, it should be picked somewhat earlier on the curve, while loss is still decreasing. <code>0.05</code> looks like a sensible choice.</p>
<p>This value is nothing but an anchor, however. <em>Learning rate schedulers</em> allow learning rates to evolve according to some proven algorithm. Among others, <code>torch</code> implements one-cycle learning [@abs-1708-07120], cyclical learning rates <span class="citation" data-cites="Smith15a">(<a href="#ref-Smith15a" role="doc-biblioref">Smith 2015</a>)</span>, and cosine annealing with warm restarts <span class="citation" data-cites="LoshchilovH16a">(<a href="#ref-LoshchilovH16a" role="doc-biblioref">Loshchilov and Hutter 2016</a>)</span>.</p>
<p>Here, we use <code>lr_one_cycle()</code>, passing in our newly found, optimally efficient, hopefully, value <code>0.05</code> as a maximum learning rate. <code>lr_one_cycle()</code> will start with a low rate, then gradually ramp up until it reaches the allowed maximum. After that, the learning rate will slowly, continuously decrease, until it falls slightly below its initial value.</p>
<p>All this happens not per epoch, but exactly once, which is why the name has <code>one_cycle</code> in it. Here’s how the evolution of learning rates looks in our example:</p>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="images/one_cycle_lr.png" width="315" /></p>
</div>
<p>Before we start training, let’s quickly re-initialize the model, so as to start from a clean slate:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>model_resnet18</span><span class='op'>(</span>pretrained <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span><span class='va'>model</span><span class='op'>$</span><span class='va'>parameters</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'>purrr</span><span class='fu'>::</span><span class='fu'><a href='https://purrr.tidyverse.org/reference/map.html'>walk</a></span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>param</span><span class='op'>)</span> <span class='va'>param</span><span class='op'>$</span><span class='fu'>requires_grad_</span><span class='op'>(</span><span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>num_features</span> <span class='op'>&lt;-</span> <span class='va'>model</span><span class='op'>$</span><span class='va'>fc</span><span class='op'>$</span><span class='va'>in_features</span></span>
<span></span>
<span><span class='va'>model</span><span class='op'>$</span><span class='va'>fc</span> <span class='op'>&lt;-</span> <span class='fu'>nn_linear</span><span class='op'>(</span>in_features <span class='op'>=</span> <span class='va'>num_features</span>, out_features <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>class_names</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>model</span> <span class='op'>&lt;-</span> <span class='va'>model</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>criterion</span> <span class='op'>&lt;-</span> <span class='fu'>nn_cross_entropy_loss</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optim_sgd</span><span class='op'>(</span><span class='va'>model</span><span class='op'>$</span><span class='va'>parameters</span>, lr <span class='op'>=</span> <span class='fl'>0.05</span>, momentum <span class='op'>=</span> <span class='fl'>0.9</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>And instantiate the scheduler:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>num_epochs</span> <span class='op'>=</span> <span class='fl'>10</span></span>
<span></span>
<span><span class='va'>scheduler</span> <span class='op'>&lt;-</span> <span class='va'>optimizer</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> </span>
<span>  <span class='fu'>lr_one_cycle</span><span class='op'>(</span>max_lr <span class='op'>=</span> <span class='fl'>0.05</span>, epochs <span class='op'>=</span> <span class='va'>num_epochs</span>, steps_per_epoch <span class='op'>=</span> <span class='va'>train_dl</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h4 id="training-loop">Training loop</h4>
<p>Now we train for ten epochs. For every training batch, we call <code>scheduler$step()</code> to adjust the learning rate. Notably, this has to be done <em>after</em> <code>optimizer$step()</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>train_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>zero_grad</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>criterion</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>backward</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>scheduler</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>valid_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>criterion</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='va'>num_epochs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>model</span><span class='op'>$</span><span class='fu'>train</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>train_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>train_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span>    <span class='va'>train_losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>train_losses</span>, <span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='va'>model</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>valid_losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>valid_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>valid_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span>    <span class='va'>valid_losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>valid_losses</span>, <span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nLoss at epoch %d: training: %3f, validation: %3f\n"</span>, <span class='va'>epoch</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>train_losses</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>valid_losses</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<pre><code>Loss at epoch 1: training: 2.662901, validation: 0.790769

Loss at epoch 2: training: 1.543315, validation: 1.014409

Loss at epoch 3: training: 1.376392, validation: 0.565186

Loss at epoch 4: training: 1.127091, validation: 0.575583

Loss at epoch 5: training: 0.916446, validation: 0.281600

Loss at epoch 6: training: 0.775241, validation: 0.215212

Loss at epoch 7: training: 0.639521, validation: 0.151283

Loss at epoch 8: training: 0.538825, validation: 0.106301

Loss at epoch 9: training: 0.407440, validation: 0.083270

Loss at epoch 10: training: 0.354659, validation: 0.080389</code></pre>
<p>It looks like the model made good progress, but we don’t yet know anything about classification accuracy in absolute terms. We’ll check that out on the test set.</p>
<h2 id="test-set-accuracy">Test set accuracy</h2>
<p>Finally, we calculate accuracy on the test set:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>model</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='va'>labels</span> <span class='op'>&lt;-</span> <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>criterion</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>labels</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>test_losses</span> <span class='op'>&lt;&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>test_losses</span>, <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='co'># torch_max returns a list, with position 1 containing the values</span></span>
<span>  <span class='co'># and position 2 containing the respective indices</span></span>
<span>  <span class='va'>predicted</span> <span class='op'>&lt;-</span> <span class='fu'>torch_max</span><span class='op'>(</span><span class='va'>output</span><span class='op'>$</span><span class='fu'>data</span><span class='op'>(</span><span class='op'>)</span>, dim <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span>  <span class='va'>total</span> <span class='op'>&lt;&lt;-</span> <span class='va'>total</span> <span class='op'>+</span> <span class='va'>labels</span><span class='op'>$</span><span class='fu'>size</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>)</span></span>
<span>  <span class='co'># add number of correct classifications in this batch to the aggregate</span></span>
<span>  <span class='va'>correct</span> <span class='op'>&lt;&lt;-</span> <span class='va'>correct</span> <span class='op'>+</span> <span class='op'>(</span><span class='va'>predicted</span> <span class='op'>==</span> <span class='va'>labels</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>sum</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>test_losses</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>total</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span><span class='va'>correct</span> <span class='op'>&lt;-</span> <span class='fl'>0</span></span>
<span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='fu'>enumerate</span><span class='op'>(</span><span class='va'>test_dl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='fu'>test_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>test_losses</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>[1] 0.03719</code></pre>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>test_accuracy</span> <span class='op'>&lt;-</span>  <span class='va'>correct</span><span class='op'>/</span><span class='va'>total</span></span>
<span><span class='va'>test_accuracy</span></span></code></pre>
</div>
</div>
<pre><code>[1] 0.98756</code></pre>
<p>An impressive result, given how many different species there are!</p>
<h2 id="wrapup">Wrapup</h2>
<p>Hopefully, this has been a useful introduction to classifying images with <code>torch</code>, as well as to its non-domain-specific architectural elements, like datasets, data loaders, and learning-rate schedulers. Future posts will explore other domains, as well as move on beyond “hello world” in image recognition. Thanks for reading!</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-HeZRS15" class="csl-entry" role="doc-biblioentry">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. <span>“Deep Residual Learning for Image Recognition.”</span> <em>CoRR</em> abs/1512.03385. <a href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a>.
</div>
<div id="ref-LoshchilovH16a" class="csl-entry" role="doc-biblioentry">
Loshchilov, Ilya, and Frank Hutter. 2016. <span>“<span>SGDR:</span> Stochastic Gradient Descent with Restarts.”</span> <em>CoRR</em> abs/1608.03983. <a href="http://arxiv.org/abs/1608.03983">http://arxiv.org/abs/1608.03983</a>.
</div>
<div id="ref-Smith15a" class="csl-entry" role="doc-biblioentry">
Smith, Leslie N. 2015. <span>“No More Pesky Learning Rate Guessing Games.”</span> <em>CoRR</em> abs/1506.01186. <a href="http://arxiv.org/abs/1506.01186">http://arxiv.org/abs/1506.01186</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Physically, the dataset consists of a single <code>zip</code> file; so it is really the first instruction that downloads all the data. The remaining two function calls perform semantic mappings only.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2020-10-19-torch-image-classification/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Classifying%20images%20with%20torch&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-10-19-torch-image-classification%2F" aria-label="share on twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2020-10-19-torch-image-classification%2F&amp;title=Classifying%20images%20with%20torch" aria-label="share on linkedin">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/';
  this.page.identifier = 'posts/2020-10-19-torch-image-classification/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2020, Oct. 19). Posit AI Blog: Classifying images with torch. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanatorchimageclassification,
  author = {Keydana, Sigrid},
  title = {Posit AI Blog: Classifying images with torch},
  url = {https://blogs.rstudio.com/tensorflow/posts/2020-10-19-torch-image-classification/},
  year = {2020}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
