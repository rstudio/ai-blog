<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
<title>Posit AI Blog: torch time series, final episode: Attention</title>

<meta property="description" itemprop="description" content="We conclude our mini-series on time-series forecasting with torch by augmenting last time&#39;s sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2021-03-19"/>
<meta property="article:created" itemprop="dateCreated" content="2021-03-19"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Posit AI Blog: torch time series, final episode: Attention"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="We conclude our mini-series on time-series forecasting with torch by augmenting last time&#39;s sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/images/preview.jpg"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Posit AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="Posit AI Blog: torch time series, final episode: Attention"/>
<meta property="twitter:description" content="We conclude our mini-series on time-series forecasting with torch by augmenting last time&#39;s sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/images/preview.jpg"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="Posit AI Blog: torch time series, final episode: Attention"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2021/03/19"/>
<meta name="citation_publication_date" content="2021/03/19"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Grammar as a foreign language;citation_volume=abs/1412.7449;citation_author=Oriol Vinyals;citation_author=Lukasz Kaiser;citation_author=Terry Koo;citation_author=Slav Petrov;citation_author=Ilya Sutskever;citation_author=Geoffrey E. Hinton"/>
  <meta name="citation_reference" content="citation_title=Show, attend and tell: Neural image caption generation with visual attention;citation_volume=abs/1502.03044;citation_author=Kelvin Xu;citation_author=Jimmy Ba;citation_author=Ryan Kiros;citation_author=Kyunghyun Cho;citation_author=Aaron C. Courville;citation_author=Ruslan Salakhutdinov;citation_author=Richard S. Zemel;citation_author=Yoshua Bengio"/>
  <meta name="citation_reference" content="citation_title=Neural machine translation by jointly learning to align and translate;citation_volume=abs/1409.0473;citation_author=Dzmitry Bahdanau;citation_author=Kyunghyun Cho;citation_author=Yoshua Bengio"/>
  <meta name="citation_reference" content="citation_title=Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth;citation_author=Yihe Dong;citation_author=Jean-Baptiste Cordonnier;citation_author=Andreas Loukas"/>
  <meta name="citation_reference" content="citation_title=Attention Is All You Need;citation_author=Ashish Vaswani;citation_author=Noam Shazeer;citation_author=Niki Parmar;citation_author=Jakob Uszkoreit;citation_author=Llion Jones;citation_author=Aidan N. Gomez;citation_author=Lukasz Kaiser;citation_author=Illia Polosukhin"/>
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","date","categories","bibliography","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["torch time series, final episode: Attention"]},{"type":"character","attributes":{},"value":["We conclude our mini-series on time-series forecasting with torch by augmenting last time's sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanatorchts4"]},{"type":"character","attributes":{},"value":["03-19-2021"]},{"type":"character","attributes":{},"value":["Torch","R","Time Series"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["images/preview.jpg"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","images/att_preds.png","images/preview.jpg"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.23/header-attrs.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script defer data-domain="blogs.rstudio.com" src="https://plausible.io/js/plausible.js"></script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"torch time series, final episode: Attention","description":"We conclude our mini-series on time-series forecasting with torch by augmenting last time's sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2021-03-19T00:00:00.000+00:00","citationText":"Keydana, 2021"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/posit.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>torch time series, final episode: Attention</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:Torch" class="dt-tag">Torch</a>
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:Time_Series" class="dt-tag">Time Series</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>We conclude our mini-series on time-series forecasting with torch by augmenting last time’s sequence-to-sequence architecture with a technique both immensely popular in natural language processing and inspired by human (and animal) cognition: attention.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>03-19-2021
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#data-input">Data input</a></li>
<li><a href="#model">Model</a>
<ul>
<li><a href="#encoder">Encoder</a></li>
<li><a href="#attention-module">Attention module</a></li>
<li><a href="#decoder">Decoder</a></li>
<li><a href="#seq2seq-module"><code>seq2seq</code> module</a></li>
</ul></li>
<li><a href="#training">Training</a></li>
<li><a href="#evaluation">Evaluation</a></li>
</ul>
</nav>
</div>
<p>This is the final post in a four-part introduction to time-series forecasting with <code>torch</code>. These posts have been the story of a quest for multiple-step prediction, and by now, we’ve seen three different approaches: forecasting in a loop, incorporating a multi-layer perceptron (MLP), and sequence-to-sequence models. Here’s a quick recap.</p>
<ul>
<li><p>As one should when one sets out for an adventurous journey, we started with an <a href="https://blogs.rstudio.com/ai/posts/2021-03-10-forecasting-time-series-with-torch_1/">in-depth study</a> of the tools at our disposal: recurrent neural networks (RNNs). We trained a model to predict the very next observation in line, and then, thought of a clever hack: How about we use this for multi-step prediction, feeding back individual predictions in a loop? The result , it turned out, was quite acceptable.</p></li>
<li><p>Then, the adventure really started. We built our first model <a href="https://blogs.rstudio.com/ai/posts/2021-03-11-forecasting-time-series-with-torch_2/">“natively” for multi-step prediction,</a> relieving the RNN a bit of its workload and involving a second player, a tiny-ish MLP. Now, it was the MLP’s task to project RNN output to several time points in the future. Although results were pretty satisfactory, we didn’t stop there.</p></li>
<li><p>Instead, we applied to numerical time series a technique commonly used in natural language processing (NLP): <a href="https://blogs.rstudio.com/ai/posts/2021-03-16-forecasting-time-series-with-torch_3/">sequence-to-sequence (<em>seq2seq</em>)</a> prediction. While forecast performance was not much different from the previous case, we found the technique to be more intuitively appealing, since it reflects the <em>causal</em> relationship between successive forecasts.</p></li>
</ul>
<p>Today we’ll enrich the seq2seq approach by adding a new component: the <em>attention</em> module. Originally introduced around 2014<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, attention mechanisms have gained enormous traction, so much so that a recent paper title starts out “Attention is Not All You Need”<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>The idea is the following.</p>
<p>In the classic encoder-decoder setup, the decoder gets “primed” with an encoder summary just a single time: the time it starts its forecasting loop. From then on, it’s on its own. With attention, however, it gets to see the complete sequence of encoder outputs again every time it forecasts a new value. What’s more, every time, it gets to zoom in on <em>those</em> outputs that seem <em>relevant for the current prediction step</em>.</p>
<p>This is a particularly useful strategy in translation: In generating the next word, a model will need to know what part of the source sentence to focus on. How much the technique helps with numerical sequences, in contrast, will likely depend on the features of the series in question.</p>
<h1 id="data-input">Data input</h1>
<p>As before, we work with <code>vic_elec</code>, but this time, we partly deviate from the way we used to employ it. With the original, bi-hourly dataset, training the current model takes a long time, longer than readers will want to wait when experimenting. So instead, we aggregate observations by day. In order to have enough data, we train on years 2012 and 2013, reserving 2014 for validation as well as post-training inspection.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://torch.mlverse.org/docs'>torch</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tsibble.tidyverts.org'>tsibble</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tsibbledata.tidyverts.org/'>tsibbledata</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://lubridate.tidyverse.org'>lubridate</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://fable.tidyverts.org'>fable</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/nteetor/zeallot'>zeallot</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>vic_elec_daily</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>Time</span>, <span class='va'>Demand</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>index_by</span><span class='op'>(</span>Date <span class='op'>=</span> <span class='fu'><a href='https://lubridate.tidyverse.org/reference/date.html'>date</a></span><span class='op'>(</span><span class='va'>Time</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>summarise</span><span class='op'>(</span></span>
<span>    Demand <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>Demand</span><span class='op'>)</span> <span class='op'>/</span> <span class='fl'>1e3</span><span class='op'>)</span> </span>
<span></span>
<span><span class='va'>elec_train</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec_daily</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://lubridate.tidyverse.org/reference/year.html'>year</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/r/base/match.html'>%in%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2012</span>, <span class='fl'>2013</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>Demand</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>elec_valid</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec_daily</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://lubridate.tidyverse.org/reference/year.html'>year</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'>==</span> <span class='fl'>2014</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>Demand</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>elec_test</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec_daily</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://lubridate.tidyverse.org/reference/year.html'>year</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/r/base/match.html'>%in%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2014</span><span class='op'>)</span>, <span class='fu'><a href='https://lubridate.tidyverse.org/reference/month.html'>month</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/r/base/match.html'>%in%</a></span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>4</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>Demand</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>train_mean</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>elec_train</span><span class='op'>)</span></span>
<span><span class='va'>train_sd</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/sd.html'>sd</a></span><span class='op'>(</span><span class='va'>elec_train</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>We’ll attempt to forecast demand up to fourteen days ahead. How long, then, should be the input sequences? This is a matter of experimentation; all the more so now that we’re adding in the attention mechanism. (I suspect that it might not handle very long sequences so well).</p>
<p>Below, we go with fourteen days for input length, too, but that may not necessarily be the best possible choice for this series.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>n_timesteps</span> <span class='op'>&lt;-</span> <span class='fl'>7</span> <span class='op'>*</span> <span class='fl'>2</span></span>
<span><span class='va'>n_forecast</span> <span class='op'>&lt;-</span> <span class='fl'>7</span> <span class='op'>*</span> <span class='fl'>2</span></span>
<span></span>
<span><span class='va'>elec_dataset</span> <span class='op'>&lt;-</span> <span class='fu'>dataset</span><span class='op'>(</span></span>
<span>  name <span class='op'>=</span> <span class='st'>"elec_dataset"</span>,</span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>n_timesteps</span>, <span class='va'>sample_frac</span> <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>n_timesteps</span> <span class='op'>&lt;-</span> <span class='va'>n_timesteps</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_tensor</span><span class='op'>(</span><span class='op'>(</span><span class='va'>x</span> <span class='op'>-</span> <span class='va'>train_mean</span><span class='op'>)</span> <span class='op'>/</span> <span class='va'>train_sd</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='fl'>1</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>starts</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sort.html'>sort</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample.int</a></span><span class='op'>(</span></span>
<span>      n <span class='op'>=</span> <span class='va'>n</span>,</span>
<span>      size <span class='op'>=</span> <span class='va'>n</span> <span class='op'>*</span> <span class='va'>sample_frac</span></span>
<span>    <span class='op'>)</span><span class='op'>)</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  .getitem <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>start</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>starts</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span></span>
<span>    <span class='va'>end</span> <span class='op'>&lt;-</span> <span class='va'>start</span> <span class='op'>+</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='fl'>1</span></span>
<span>    <span class='va'>lag</span> <span class='op'>&lt;-</span> <span class='fl'>1</span></span>
<span>    </span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span></span>
<span>      x <span class='op'>=</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>x</span><span class='op'>[</span><span class='va'>start</span><span class='op'>:</span><span class='va'>end</span><span class='op'>]</span>,</span>
<span>      y <span class='op'>=</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>x</span><span class='op'>[</span><span class='op'>(</span><span class='va'>start</span><span class='op'>+</span><span class='va'>lag</span><span class='op'>)</span><span class='op'>:</span><span class='op'>(</span><span class='va'>end</span><span class='op'>+</span><span class='va'>lag</span><span class='op'>)</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span></span>
<span>    <span class='op'>)</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  .length <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>starts</span><span class='op'>)</span> </span>
<span>  <span class='op'>}</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>32</span></span>
<span></span>
<span><span class='va'>train_ds</span> <span class='op'>&lt;-</span> <span class='fu'>elec_dataset</span><span class='op'>(</span><span class='va'>elec_train</span>, <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span><span class='va'>train_dl</span> <span class='op'>&lt;-</span> <span class='va'>train_ds</span> <span class='op'>%&gt;%</span> <span class='fu'>dataloader</span><span class='op'>(</span>batch_size <span class='op'>=</span> <span class='va'>batch_size</span>, shuffle <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>valid_ds</span> <span class='op'>&lt;-</span> <span class='fu'>elec_dataset</span><span class='op'>(</span><span class='va'>elec_valid</span>, <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span><span class='va'>valid_dl</span> <span class='op'>&lt;-</span> <span class='va'>valid_ds</span> <span class='op'>%&gt;%</span> <span class='fu'>dataloader</span><span class='op'>(</span>batch_size <span class='op'>=</span> <span class='va'>batch_size</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_ds</span> <span class='op'>&lt;-</span> <span class='fu'>elec_dataset</span><span class='op'>(</span><span class='va'>elec_test</span>, <span class='va'>n_timesteps</span><span class='op'>)</span></span>
<span><span class='va'>test_dl</span> <span class='op'>&lt;-</span> <span class='va'>test_ds</span> <span class='op'>%&gt;%</span> <span class='fu'>dataloader</span><span class='op'>(</span>batch_size <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h1 id="model">Model</h1>
<p>Model-wise, we again encounter the three <em>modules</em> familiar from the previous post: encoder, decoder, and top-level seq2seq module. However, there is an additional component: the <em>attention</em> module, used by the decoder to obtain <em>attention weights</em>.</p>
<h3 id="encoder">Encoder</h3>
<p>The encoder still works the same way. It wraps an RNN, and returns the final state.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>encoder_module</span> <span class='op'>&lt;-</span> <span class='fu'>nn_module</span><span class='op'>(</span></span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>type</span>, <span class='va'>input_size</span>, <span class='va'>hidden_size</span>, <span class='va'>num_layers</span> <span class='op'>=</span> <span class='fl'>1</span>, <span class='va'>dropout</span> <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>type</span> <span class='op'>&lt;-</span> <span class='va'>type</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>rnn</span> <span class='op'>&lt;-</span> <span class='kw'>if</span> <span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>type</span> <span class='op'>==</span> <span class='st'>"gru"</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='fu'>nn_gru</span><span class='op'>(</span></span>
<span>        input_size <span class='op'>=</span> <span class='va'>input_size</span>,</span>
<span>        hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>        num_layers <span class='op'>=</span> <span class='va'>num_layers</span>,</span>
<span>        dropout <span class='op'>=</span> <span class='va'>dropout</span>,</span>
<span>        batch_first <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>      <span class='op'>)</span></span>
<span>    <span class='op'>}</span> <span class='kw'>else</span> <span class='op'>{</span></span>
<span>      <span class='fu'>nn_lstm</span><span class='op'>(</span></span>
<span>        input_size <span class='op'>=</span> <span class='va'>input_size</span>,</span>
<span>        hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>        num_layers <span class='op'>=</span> <span class='va'>num_layers</span>,</span>
<span>        dropout <span class='op'>=</span> <span class='va'>dropout</span>,</span>
<span>        batch_first <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>      <span class='op'>)</span></span>
<span>    <span class='op'>}</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='co'># return outputs for all timesteps, as well as last-timestep states for all layers</span></span>
<span>    <span class='va'>x</span> <span class='op'>%&gt;%</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>rnn</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    </span>
<span>  <span class='op'>}</span></span>
<span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="attention-module">Attention module</h3>
<p>In basic seq2seq, whenever it had to generate a new value, the decoder took into account two things: its prior state, and the previous output generated. In an attention-enriched setup, the decoder additionally receives the complete output from the encoder. In deciding what subset of that output should matter, it gets help from a new agent, the attention module.</p>
<p>This, then, is the attention module’s raison d’être: Given current decoder state and well as complete encoder outputs, obtain a weighting of those outputs indicative of how relevant they are to what the decoder is currently up to. This procedure results in the so-called <em>attention weights</em>: a normalized score, for each time step in the encoding, that quantify their respective importance.</p>
<p>Attention may be implemented in a number of different ways. Here, we show two implementation options, one additive, and one multiplicative.</p>
<h4 id="additive-attention">Additive attention</h4>
<p>In additive attention, encoder outputs and decoder state are commonly either added or concatenated (we choose to do the latter, below). The resulting tensor is run through a linear layer, and a softmax is applied for normalization.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>attention_module_additive</span> <span class='op'>&lt;-</span> <span class='fu'>nn_module</span><span class='op'>(</span></span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>hidden_dim</span>, <span class='va'>attention_size</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>attention</span> <span class='op'>&lt;-</span> <span class='fu'>nn_linear</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>hidden_dim</span>, <span class='va'>attention_size</span><span class='op'>)</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='co'># function argument shapes</span></span>
<span>    <span class='co'># encoder_outputs: (bs, timesteps, hidden_dim)</span></span>
<span>    <span class='co'># state: (1, bs, hidden_dim)</span></span>
<span>    </span>
<span>    <span class='co'># multiplex state to allow for concatenation (dimensions 1 and 2 must agree)</span></span>
<span>    <span class='va'>seq_len</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>encoder_outputs</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span></span>
<span>    <span class='co'># resulting shape: (bs, timesteps, hidden_dim)</span></span>
<span>    <span class='va'>state_rep</span> <span class='op'>&lt;-</span> <span class='va'>state</span><span class='op'>$</span><span class='fu'>permute</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>, <span class='fl'>1</span>, <span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>repeat_interleave</span><span class='op'>(</span><span class='va'>seq_len</span>, <span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># concatenate along feature dimension</span></span>
<span>    <span class='va'>concat</span> <span class='op'>&lt;-</span> <span class='fu'>torch_cat</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>state_rep</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span>, dim <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># run through linear layer with tanh</span></span>
<span>    <span class='co'># resulting shape: (bs, timesteps, attention_size)</span></span>
<span>    <span class='va'>scores</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>attention</span><span class='op'>(</span><span class='va'>concat</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>      <span class='fu'>torch_tanh</span><span class='op'>(</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># sum over attention dimension and normalize</span></span>
<span>    <span class='co'># resulting shape: (bs, timesteps) </span></span>
<span>    <span class='va'>attention_weights</span> <span class='op'>&lt;-</span> <span class='va'>scores</span> <span class='op'>%&gt;%</span></span>
<span>      <span class='fu'>torch_sum</span><span class='op'>(</span>dim <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>      <span class='fu'>nnf_softmax</span><span class='op'>(</span>dim <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># a normalized score for every source token</span></span>
<span>    <span class='va'>attention_weights</span></span>
<span>  <span class='op'>}</span></span>
<span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h4 id="multiplicative-attention">Multiplicative attention</h4>
<p>In multiplicative attention, scores are obtained by computing dot products between decoder state and all of the encoder outputs. Here too, a softmax is then used for normalization.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>attention_module_multiplicative</span> <span class='op'>&lt;-</span> <span class='fu'>nn_module</span><span class='op'>(</span></span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='cn'>NULL</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='co'># function argument shapes</span></span>
<span>    <span class='co'># encoder_outputs: (bs, timesteps, hidden_dim)</span></span>
<span>    <span class='co'># state: (1, bs, hidden_dim)</span></span>
<span></span>
<span>    <span class='co'># allow for matrix multiplication with encoder_outputs</span></span>
<span>    <span class='va'>state</span> <span class='op'>&lt;-</span> <span class='va'>state</span><span class='op'>$</span><span class='fu'>permute</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>, <span class='fl'>3</span>, <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span></span>
<span> </span>
<span>    <span class='co'># prepare for scaling by number of features</span></span>
<span>    <span class='va'>d</span> <span class='op'>&lt;-</span> <span class='fu'>torch_tensor</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>encoder_outputs</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span>, dtype <span class='op'>=</span> <span class='fu'>torch_float</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span>       </span>
<span>    <span class='co'># scaled dot products between state and outputs</span></span>
<span>    <span class='co'># resulting shape: (bs, timesteps, 1)</span></span>
<span>    <span class='va'>scores</span> <span class='op'>&lt;-</span> <span class='fu'>torch_bmm</span><span class='op'>(</span><span class='va'>encoder_outputs</span>, <span class='va'>state</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>      <span class='fu'>torch_div</span><span class='op'>(</span><span class='fu'>torch_sqrt</span><span class='op'>(</span><span class='va'>d</span><span class='op'>)</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># normalize</span></span>
<span>    <span class='co'># resulting shape: (bs, timesteps) </span></span>
<span>    <span class='va'>attention_weights</span> <span class='op'>&lt;-</span> <span class='va'>scores</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>3</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>      <span class='fu'>nnf_softmax</span><span class='op'>(</span>dim <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># a normalized score for every source token</span></span>
<span>    <span class='va'>attention_weights</span></span>
<span>  <span class='op'>}</span></span>
<span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="decoder">Decoder</h3>
<p>Once attention weights have been computed, their actual application is handled by the decoder. Concretely, the method in question, <code>weighted_encoder_outputs()</code>, computes a product of weights and encoder outputs, making sure that each output will have appropriate impact.</p>
<p>The rest of the action then happens in <code>forward()</code>. A concatenation of weighted encoder outputs (often called “context”) and current input is run through an RNN. Then, an ensemble of RNN output, context, and input is passed to an MLP. Finally, both RNN state and current prediction are returned.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>decoder_module</span> <span class='op'>&lt;-</span> <span class='fu'>nn_module</span><span class='op'>(</span></span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>type</span>, <span class='va'>input_size</span>, <span class='va'>hidden_size</span>, <span class='va'>attention_type</span>, <span class='va'>attention_size</span> <span class='op'>=</span> <span class='fl'>8</span>, <span class='va'>num_layers</span> <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>type</span> <span class='op'>&lt;-</span> <span class='va'>type</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>rnn</span> <span class='op'>&lt;-</span> <span class='kw'>if</span> <span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>type</span> <span class='op'>==</span> <span class='st'>"gru"</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      <span class='fu'>nn_gru</span><span class='op'>(</span></span>
<span>        input_size <span class='op'>=</span> <span class='va'>input_size</span>,</span>
<span>        hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>        num_layers <span class='op'>=</span> <span class='va'>num_layers</span>,</span>
<span>        batch_first <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>      <span class='op'>)</span></span>
<span>    <span class='op'>}</span> <span class='kw'>else</span> <span class='op'>{</span></span>
<span>      <span class='fu'>nn_lstm</span><span class='op'>(</span></span>
<span>        input_size <span class='op'>=</span> <span class='va'>input_size</span>,</span>
<span>        hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>        num_layers <span class='op'>=</span> <span class='va'>num_layers</span>,</span>
<span>        batch_first <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>      <span class='op'>)</span></span>
<span>    <span class='op'>}</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>linear</span> <span class='op'>&lt;-</span> <span class='fu'>nn_linear</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>hidden_size</span> <span class='op'>+</span> <span class='fl'>1</span>, <span class='fl'>1</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>attention</span> <span class='op'>&lt;-</span> <span class='kw'>if</span> <span class='op'>(</span><span class='va'>attention_type</span> <span class='op'>==</span> <span class='st'>"multiplicative"</span><span class='op'>)</span> <span class='fu'>attention_module_multiplicative</span><span class='op'>(</span><span class='op'>)</span></span>
<span>      <span class='kw'>else</span> <span class='fu'>attention_module_additive</span><span class='op'>(</span><span class='va'>hidden_size</span>, <span class='va'>attention_size</span><span class='op'>)</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  weighted_encoder_outputs <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>    <span class='co'># encoder_outputs is (bs, timesteps, hidden_dim)</span></span>
<span>    <span class='co'># state is (1, bs, hidden_dim)</span></span>
<span>    <span class='co'># resulting shape: (bs * timesteps)</span></span>
<span>    <span class='va'>attention_weights</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>attention</span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># resulting shape: (bs, 1, seq_len)</span></span>
<span>    <span class='va'>attention_weights</span> <span class='op'>&lt;-</span> <span class='va'>attention_weights</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># resulting shape: (bs, 1, hidden_size)</span></span>
<span>    <span class='va'>weighted_encoder_outputs</span> <span class='op'>&lt;-</span> <span class='fu'>torch_bmm</span><span class='op'>(</span><span class='va'>attention_weights</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>weighted_encoder_outputs</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span> </span>
<span>    <span class='co'># encoder_outputs is (bs, timesteps, hidden_dim)</span></span>
<span>    <span class='co'># state is (1, bs, hidden_dim)</span></span>
<span>    </span>
<span>    <span class='co'># resulting shape: (bs, 1, hidden_size)</span></span>
<span>    <span class='va'>context</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>weighted_encoder_outputs</span><span class='op'>(</span><span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># concatenate input and context</span></span>
<span>    <span class='co'># NOTE: this repeating is done to compensate for the absence of an embedding module</span></span>
<span>    <span class='co'># that, in NLP, would give x a higher proportion in the concatenation</span></span>
<span>    <span class='va'>x_rep</span> <span class='op'>&lt;-</span> <span class='va'>x</span><span class='op'>$</span><span class='fu'>repeat_interleave</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>context</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span>, <span class='fl'>3</span><span class='op'>)</span> </span>
<span>    <span class='va'>rnn_input</span> <span class='op'>&lt;-</span> <span class='fu'>torch_cat</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>x_rep</span>, <span class='va'>context</span><span class='op'>)</span>, dim <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># resulting shapes: (bs, 1, hidden_size) and (1, bs, hidden_size)</span></span>
<span>    <span class='va'>rnn_out</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>rnn</span><span class='op'>(</span><span class='va'>rnn_input</span>, <span class='va'>state</span><span class='op'>)</span></span>
<span>    <span class='va'>rnn_output</span> <span class='op'>&lt;-</span> <span class='va'>rnn_out</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    <span class='va'>next_hidden</span> <span class='op'>&lt;-</span> <span class='va'>rnn_out</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    </span>
<span>    <span class='va'>mlp_input</span> <span class='op'>&lt;-</span> <span class='fu'>torch_cat</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>rnn_output</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, <span class='va'>context</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, <span class='va'>x</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span>, dim <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>linear</span><span class='op'>(</span><span class='va'>mlp_input</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='co'># shapes: (bs, 1) and (1, bs, hidden_size)</span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>next_hidden</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span></span>
<span>  </span>
<span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="seq2seq-module"><code>seq2seq</code> module</h3>
<p>The <code>seq2seq</code> module is basically unchanged (apart from the fact that now, it allows for attention module configuration). For a detailed explanation of what happens here, please consult the <a href="https://blogs.rstudio.com/ai/posts/2021-03-16-forecasting-time-series-with-torch_3/">previous post</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>seq2seq_module</span> <span class='op'>&lt;-</span> <span class='fu'>nn_module</span><span class='op'>(</span></span>
<span>  </span>
<span>  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>type</span>, <span class='va'>input_size</span>, <span class='va'>hidden_size</span>, <span class='va'>attention_type</span>, <span class='va'>attention_size</span>, <span class='va'>n_forecast</span>, </span>
<span>                        <span class='va'>num_layers</span> <span class='op'>=</span> <span class='fl'>1</span>, <span class='va'>encoder_dropout</span> <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>encoder</span> <span class='op'>&lt;-</span> <span class='fu'>encoder_module</span><span class='op'>(</span>type <span class='op'>=</span> <span class='va'>type</span>, input_size <span class='op'>=</span> <span class='va'>input_size</span>, hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>                                   <span class='va'>num_layers</span>, <span class='va'>encoder_dropout</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>decoder</span> <span class='op'>&lt;-</span> <span class='fu'>decoder_module</span><span class='op'>(</span>type <span class='op'>=</span> <span class='va'>type</span>, input_size <span class='op'>=</span> <span class='fl'>2</span> <span class='op'>*</span> <span class='va'>hidden_size</span>, hidden_size <span class='op'>=</span> <span class='va'>hidden_size</span>,</span>
<span>                                   attention_type <span class='op'>=</span> <span class='va'>attention_type</span>, attention_size <span class='op'>=</span> <span class='va'>attention_size</span>, <span class='va'>num_layers</span><span class='op'>)</span></span>
<span>    <span class='va'>self</span><span class='op'>$</span><span class='va'>n_forecast</span> <span class='op'>&lt;-</span> <span class='va'>n_forecast</span></span>
<span>    </span>
<span>  <span class='op'>}</span>,</span>
<span>  </span>
<span>  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>y</span>, <span class='va'>teacher_forcing_ratio</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    </span>
<span>    <span class='va'>outputs</span> <span class='op'>&lt;-</span> <span class='fu'>torch_zeros</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>]</span>, <span class='va'>self</span><span class='op'>$</span><span class='va'>n_forecast</span><span class='op'>)</span></span>
<span>    <span class='va'>encoded</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>encoder</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span></span>
<span>    <span class='va'>encoder_outputs</span> <span class='op'>&lt;-</span> <span class='va'>encoded</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    <span class='va'>hidden</span> <span class='op'>&lt;-</span> <span class='va'>encoded</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    <span class='co'># list of (batch_size, 1), (1, batch_size, hidden_size)</span></span>
<span>    <span class='va'>out</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>decoder</span><span class='op'>(</span><span class='va'>x</span><span class='op'>[</span> , <span class='va'>n_timesteps</span>, , drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span>, <span class='va'>hidden</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span></span>
<span>    <span class='co'># (batch_size, 1)</span></span>
<span>    <span class='va'>pred</span> <span class='op'>&lt;-</span> <span class='va'>out</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    <span class='co'># (1, batch_size, hidden_size)</span></span>
<span>    <span class='va'>state</span> <span class='op'>&lt;-</span> <span class='va'>out</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span>    <span class='va'>outputs</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>pred</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span></span>
<span>    </span>
<span>    <span class='kw'>for</span> <span class='op'>(</span><span class='va'>t</span> <span class='kw'>in</span> <span class='fl'>2</span><span class='op'>:</span><span class='va'>self</span><span class='op'>$</span><span class='va'>n_forecast</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>      </span>
<span>      <span class='va'>teacher_forcing</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>)</span> <span class='op'>&lt;</span> <span class='va'>teacher_forcing_ratio</span></span>
<span>      <span class='va'>input</span> <span class='op'>&lt;-</span> <span class='kw'>if</span> <span class='op'>(</span><span class='va'>teacher_forcing</span> <span class='op'>==</span> <span class='cn'>TRUE</span><span class='op'>)</span> <span class='va'>y</span><span class='op'>[</span> , <span class='va'>t</span> <span class='op'>-</span> <span class='fl'>1</span>, drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span> <span class='kw'>else</span> <span class='va'>pred</span></span>
<span>      <span class='va'>input</span> <span class='op'>&lt;-</span> <span class='va'>input</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>3</span><span class='op'>)</span></span>
<span>      <span class='va'>out</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>decoder</span><span class='op'>(</span><span class='va'>input</span>, <span class='va'>state</span>, <span class='va'>encoder_outputs</span><span class='op'>)</span></span>
<span>      <span class='va'>pred</span> <span class='op'>&lt;-</span> <span class='va'>out</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span>      <span class='va'>state</span> <span class='op'>&lt;-</span> <span class='va'>out</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span></span>
<span>      <span class='va'>outputs</span><span class='op'>[</span> , <span class='va'>t</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>pred</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span></span>
<span>      </span>
<span>    <span class='op'>}</span></span>
<span>    </span>
<span>    <span class='va'>outputs</span></span>
<span>  <span class='op'>}</span></span>
<span>  </span>
<span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>When instantiating the top-level model, we now have an additional choice: that between additive and multiplicative attention. In the “accuracy” sense of performance, my tests did not show any differences. However, the multiplicative variant is a lot faster.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>net</span> <span class='op'>&lt;-</span> <span class='fu'>seq2seq_module</span><span class='op'>(</span><span class='st'>"gru"</span>, input_size <span class='op'>=</span> <span class='fl'>1</span>, hidden_size <span class='op'>=</span> <span class='fl'>32</span>, attention_type <span class='op'>=</span> <span class='st'>"multiplicative"</span>,</span>
<span>                      attention_size <span class='op'>=</span> <span class='fl'>8</span>, n_forecast <span class='op'>=</span> <span class='va'>n_forecast</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h1 id="training">Training</h1>
<p>Just like last time, in model training, we get to choose the degree of teacher forcing. Below, we go with a fraction of 0.0, that is, no forcing at all.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'>optim_adam</span><span class='op'>(</span><span class='va'>net</span><span class='op'>$</span><span class='va'>parameters</span>, lr <span class='op'>=</span> <span class='fl'>0.001</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>num_epochs</span> <span class='op'>&lt;-</span> <span class='fl'>1000</span></span>
<span></span>
<span><span class='va'>train_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span>, <span class='va'>teacher_forcing_ratio</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>zero_grad</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>net</span><span class='op'>(</span><span class='va'>b</span><span class='op'>$</span><span class='va'>x</span>, <span class='va'>b</span><span class='op'>$</span><span class='va'>y</span>, <span class='va'>teacher_forcing_ratio</span><span class='op'>)</span></span>
<span>  <span class='va'>target</span> <span class='op'>&lt;-</span> <span class='va'>b</span><span class='op'>$</span><span class='va'>y</span></span>
<span>  </span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>nnf_mse_loss</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>output</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>)</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>backward</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>valid_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span>, <span class='va'>teacher_forcing_ratio</span> <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>net</span><span class='op'>(</span><span class='va'>b</span><span class='op'>$</span><span class='va'>x</span>, <span class='va'>b</span><span class='op'>$</span><span class='va'>y</span>, <span class='va'>teacher_forcing_ratio</span><span class='op'>)</span></span>
<span>  <span class='va'>target</span> <span class='op'>&lt;-</span> <span class='va'>b</span><span class='op'>$</span><span class='va'>y</span></span>
<span>  </span>
<span>  <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>nnf_mse_loss</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>:</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>output</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>)</span><span class='op'>]</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='va'>num_epochs</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>net</span><span class='op'>$</span><span class='fu'>train</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>train_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span><span class='fu'>train_batch</span><span class='op'>(</span><span class='va'>b</span>, teacher_forcing_ratio <span class='op'>=</span> <span class='fl'>0.0</span><span class='op'>)</span></span>
<span>    <span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>train_loss</span>, <span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nEpoch %d, training: loss: %3.5f \n"</span>, <span class='va'>epoch</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>train_loss</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>net</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  <span class='va'>valid_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>valid_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>    <span class='va'>loss</span> <span class='op'>&lt;-</span> <span class='fu'>valid_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span>    <span class='va'>valid_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>valid_loss</span>, <span class='va'>loss</span><span class='op'>)</span></span>
<span>  <span class='op'>}</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nEpoch %d, validation: loss: %3.5f \n"</span>, <span class='va'>epoch</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>valid_loss</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<pre><code># Epoch 1, training: loss: 0.83752 
# Epoch 1, validation: loss: 0.83167

# Epoch 2, training: loss: 0.72803 
# Epoch 2, validation: loss: 0.80804 

# ...
# ...

# Epoch 99, training: loss: 0.10385 
# Epoch 99, validation: loss: 0.21259 

# Epoch 100, training: loss: 0.10396 
# Epoch 100, validation: loss: 0.20975 </code></pre>
<h1 id="evaluation">Evaluation</h1>
<p>For visual inspection, we pick a few forecasts from the test set.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>net</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_preds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/vector.html'>vector</a></span><span class='op'>(</span>mode <span class='op'>=</span> <span class='st'>"list"</span>, length <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>test_dl</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>i</span> <span class='op'>&lt;-</span> <span class='fl'>1</span></span>
<span></span>
<span><span class='va'>vic_elec_test</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec_daily</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://lubridate.tidyverse.org/reference/year.html'>year</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'>==</span> <span class='fl'>2014</span>, <span class='fu'><a href='https://lubridate.tidyverse.org/reference/month.html'>month</a></span><span class='op'>(</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'><a href='https://rdrr.io/r/base/match.html'>%in%</a></span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>4</span><span class='op'>)</span></span>
<span></span>
<span></span>
<span><span class='fu'>coro</span><span class='fu'>::</span><span class='fu'>loop</span><span class='op'>(</span><span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='va'>test_dl</span><span class='op'>)</span> <span class='op'>{</span></span>
<span></span>
<span>  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>net</span><span class='op'>(</span><span class='va'>b</span><span class='op'>$</span><span class='va'>x</span>, <span class='va'>b</span><span class='op'>$</span><span class='va'>y</span>, teacher_forcing_ratio <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span></span>
<span>  <span class='va'>preds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='va'>output</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>test_preds</span><span class='op'>[[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>preds</span></span>
<span>  <span class='va'>i</span> <span class='op'>&lt;&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='fl'>1</span></span>
<span>  </span>
<span><span class='op'>}</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_pred1</span> <span class='op'>&lt;-</span> <span class='va'>test_preds</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>test_pred1</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='va'>n_timesteps</span><span class='op'>)</span>, <span class='va'>test_pred1</span>, <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>vic_elec_test</span><span class='op'>)</span> <span class='op'>-</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='va'>n_forecast</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_pred2</span> <span class='op'>&lt;-</span> <span class='va'>test_preds</span><span class='op'>[[</span><span class='fl'>21</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>test_pred2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>20</span><span class='op'>)</span>, <span class='va'>test_pred2</span>, <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>vic_elec_test</span><span class='op'>)</span> <span class='op'>-</span> <span class='fl'>20</span> <span class='op'>-</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='va'>n_forecast</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_pred3</span> <span class='op'>&lt;-</span> <span class='va'>test_preds</span><span class='op'>[[</span><span class='fl'>41</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>test_pred3</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>40</span><span class='op'>)</span>, <span class='va'>test_pred3</span>, <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>vic_elec_test</span><span class='op'>)</span> <span class='op'>-</span> <span class='fl'>40</span> <span class='op'>-</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='va'>n_forecast</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_pred4</span> <span class='op'>&lt;-</span> <span class='va'>test_preds</span><span class='op'>[[</span><span class='fl'>61</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>test_pred4</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>60</span><span class='op'>)</span>, <span class='va'>test_pred4</span>, <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>vic_elec_test</span><span class='op'>)</span> <span class='op'>-</span> <span class='fl'>60</span> <span class='op'>-</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='va'>n_forecast</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_pred5</span> <span class='op'>&lt;-</span> <span class='va'>test_preds</span><span class='op'>[[</span><span class='fl'>81</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>test_pred5</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='va'>n_timesteps</span> <span class='op'>+</span> <span class='fl'>80</span><span class='op'>)</span>, <span class='va'>test_pred5</span>, <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='cn'>NA</span>, <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>vic_elec_test</span><span class='op'>)</span> <span class='op'>-</span> <span class='fl'>80</span> <span class='op'>-</span> <span class='va'>n_timesteps</span> <span class='op'>-</span> <span class='va'>n_forecast</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span></span>
<span><span class='va'>preds_ts</span> <span class='op'>&lt;-</span> <span class='va'>vic_elec_test</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>select</span><span class='op'>(</span><span class='va'>Demand</span>, <span class='va'>Date</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>add_column</span><span class='op'>(</span></span>
<span>    ex_1 <span class='op'>=</span> <span class='va'>test_pred1</span> <span class='op'>*</span> <span class='va'>train_sd</span> <span class='op'>+</span> <span class='va'>train_mean</span>,</span>
<span>    ex_2 <span class='op'>=</span> <span class='va'>test_pred2</span> <span class='op'>*</span> <span class='va'>train_sd</span> <span class='op'>+</span> <span class='va'>train_mean</span>,</span>
<span>    ex_3 <span class='op'>=</span> <span class='va'>test_pred3</span> <span class='op'>*</span> <span class='va'>train_sd</span> <span class='op'>+</span> <span class='va'>train_mean</span>,</span>
<span>    ex_4 <span class='op'>=</span> <span class='va'>test_pred4</span> <span class='op'>*</span> <span class='va'>train_sd</span> <span class='op'>+</span> <span class='va'>train_mean</span>,</span>
<span>    ex_5 <span class='op'>=</span> <span class='va'>test_pred5</span> <span class='op'>*</span> <span class='va'>train_sd</span> <span class='op'>+</span> <span class='va'>train_mean</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>pivot_longer</span><span class='op'>(</span><span class='op'>-</span><span class='va'>Date</span><span class='op'>)</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>update_tsibble</span><span class='op'>(</span>key <span class='op'>=</span> <span class='va'>name</span><span class='op'>)</span></span>
<span></span>
<span></span>
<span><span class='va'>preds_ts</span> <span class='op'>%&gt;%</span></span>
<span>  <span class='fu'>autoplot</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>scale_color_hue</span><span class='op'>(</span>h <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>80</span>, <span class='fl'>300</span><span class='op'>)</span>, l <span class='op'>=</span> <span class='fl'>70</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>theme_minimal</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-page">
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="images/att_preds.png" alt="A sample of two-weeks-ahead predictions for the test set, 2014." width="600" />
<p class="caption">
Figure 1: A sample of two-weeks-ahead predictions for the test set, 2014.
</p>
</div>
</div>
<p>We can’t directly compare performance here to that of previous models in our series, as we’ve pragmatically redefined the task. The main goal, however, has been to introduce the concept of attention. Specifically, how to <em>manually</em> implement the technique – something that, once you’ve understood the concept, you may never have to do in practice. Instead, you would likely make use of existing tools that come with <code>torch</code> (multi-head attention and transformer modules), tools we may introduce in a future “season” of this series.</p>
<p>Thanks for reading!</p>
<p>Photo by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode</a> on <a href="/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-BahdanauCB14" class="csl-entry" role="doc-biblioentry">
Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2014. <span>“Neural Machine Translation by Jointly Learning to Align and Translate.”</span> <em>CoRR</em> abs/1409.0473. <a href="http://arxiv.org/abs/1409.0473">http://arxiv.org/abs/1409.0473</a>.
</div>
<div id="ref-2021arXiv210303404D" class="csl-entry" role="doc-biblioentry">
Dong, Yihe, Jean-Baptiste Cordonnier, and Andreas Loukas. 2021. <span>“<span class="nocase">Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth</span>.”</span> <em>arXiv e-Prints</em>, March, arXiv:2103.03404. <a href="https://arxiv.org/abs/2103.03404">https://arxiv.org/abs/2103.03404</a>.
</div>
<div id="ref-2017arXiv170603762V" class="csl-entry" role="doc-biblioentry">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“<span>Attention Is All You Need</span>.”</span> <em>arXiv e-Prints</em>, June, arXiv:1706.03762. <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
<div id="ref-VinyalsKKPSH14" class="csl-entry" role="doc-biblioentry">
Vinyals, Oriol, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey E. Hinton. 2014. <span>“Grammar as a Foreign Language.”</span> <em>CoRR</em> abs/1412.7449. <a href="http://arxiv.org/abs/1412.7449">http://arxiv.org/abs/1412.7449</a>.
</div>
<div id="ref-XuBKCCSZB15" class="csl-entry" role="doc-biblioentry">
Xu, Kelvin, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. <span>“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.”</span> <em>CoRR</em> abs/1502.03044. <a href="http://arxiv.org/abs/1502.03044">http://arxiv.org/abs/1502.03044</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>For important papers see: <span class="citation" data-cites="BahdanauCB14"><a href="#ref-BahdanauCB14" role="doc-biblioref">Bahdanau, Cho, and Bengio</a> (<a href="#ref-BahdanauCB14" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="VinyalsKKPSH14"><a href="#ref-VinyalsKKPSH14" role="doc-biblioref">Vinyals et al.</a> (<a href="#ref-VinyalsKKPSH14" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="XuBKCCSZB15"><a href="#ref-XuBKCCSZB15" role="doc-biblioref">Xu et al.</a> (<a href="#ref-XuBKCCSZB15" role="doc-biblioref">2015</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation" data-cites="2021arXiv210303404D"><a href="#ref-2021arXiv210303404D" role="doc-biblioref">Dong, Cordonnier, and Loukas</a> (<a href="#ref-2021arXiv210303404D" role="doc-biblioref">2021</a>)</span>, thus replying to <span class="citation" data-cites="2017arXiv170603762V"><a href="#ref-2017arXiv170603762V" role="doc-biblioref">Vaswani et al.</a> (<a href="#ref-2017arXiv170603762V" role="doc-biblioref">2017</a>)</span>, whose 2017 paper “went viral” for stating the opposite.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2021-03-19-forecasting-time-series-with-torch_4/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=torch%20time%20series%2C%20final%20episode%3A%20Attention&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2021-03-19-forecasting-time-series-with-torch_4%2F" aria-label="share on twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2021-03-19-forecasting-time-series-with-torch_4%2F&amp;title=torch%20time%20series%2C%20final%20episode%3A%20Attention" aria-label="share on linkedin">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/';
  this.page.identifier = 'posts/2021-03-19-forecasting-time-series-with-torch_4/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2021, March 19). Posit AI Blog: torch time series, final episode: Attention. Retrieved from https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanatorchts4,
  author = {Keydana, Sigrid},
  title = {Posit AI Blog: torch time series, final episode: Attention},
  url = {https://blogs.rstudio.com/tensorflow/posts/2021-03-19-forecasting-time-series-with-torch_4/},
  year = {2021}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
