<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
<title>RStudio AI Blog: Five ways to do least squares (with torch)</title>

<meta property="description" itemprop="description" content="Get to know torch&#39;s linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press."/>

<link rel="canonical" href="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"/>
<link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
<link rel="icon" type="image/png" href="../../images/favicon.png"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2022-10-13"/>
<meta property="article:created" itemprop="dateCreated" content="2022-10-13"/>
<meta name="article:author" content="Sigrid Keydana"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="RStudio AI Blog: Five ways to do least squares (with torch)"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="Get to know torch&#39;s linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press."/>
<meta property="og:url" content="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"/>
<meta property="og:image" content="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/images/squirrel.jpg"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="RStudio AI Blog"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary_large_image"/>
<meta property="twitter:title" content="RStudio AI Blog: Five ways to do least squares (with torch)"/>
<meta property="twitter:description" content="Get to know torch&#39;s linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press."/>
<meta property="twitter:url" content="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"/>
<meta property="twitter:image" content="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/images/squirrel.jpg"/>

<!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing -->
<meta name="citation_title" content="RStudio AI Blog: Five ways to do least squares (with torch)"/>
<meta name="citation_fulltext_html_url" content="https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"/>
<meta name="citation_fulltext_world_readable" content=""/>
<meta name="citation_online_date" content="2022/10/13"/>
<meta name="citation_publication_date" content="2022/10/13"/>
<meta name="citation_author" content="Sigrid Keydana"/>
<meta name="citation_author_institution" content="RStudio"/>
<!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","slug","date","categories","output","preview","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Five ways to do least squares (with torch)"]},{"type":"character","attributes":{},"value":["Get to know torch's linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanatorchlinalg"]},{"type":"character","attributes":{},"value":["2022-10-13"]},{"type":"character","attributes":{},"value":["Torch","R","Concepts","Tabular Data"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["images/squirrel.jpg"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"]},{"type":"character","attributes":{},"value":["https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["images/squirrel.jpg"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme
  $('code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<!--/radix_placeholder_distill-->
  <script src="../../site_libs/header-attrs-2.17/header-attrs.js"></script>
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<script type="text/javascript" cookie-consent="tracking" async src="https://www.googletagmanager.com/gtag/js?id=UA-20375833-3"></script>
<script type="text/javascript" cookie-consent="tracking">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-20375833-3');
</script>
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Five ways to do least squares (with torch)","description":"Get to know torch's linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2022-10-13T00:00:00.000+00:00","citationText":"Keydana, 2022"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<span class="logo">
<img src="../../images/rstudio.png"/>
</span>
<a href="../../index.html" class="title">AI Blog</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="../../index.html">Home</a>
<a href="../../gallery.html">Gallery</a>
<a href="../../about.html">About</a>
<a href="../../contributing.html">Contributing</a>
<a href="../../index.xml">
<i class="fa fa-rss" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Five ways to do least squares (with torch)</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
  <a href="../../index.html#category:Torch" class="dt-tag">Torch</a>
  <a href="../../index.html#category:R" class="dt-tag">R</a>
  <a href="../../index.html#category:Concepts" class="dt-tag">Concepts</a>
  <a href="../../index.html#category:Tabular_Data" class="dt-tag">Tabular Data</a>
</div>
<!--/radix_placeholder_categories-->
<p><p>Get to know torchs linalg module, all while learning about different ways to do least-squares regression from scratch. This post is a condensed version of the corresponding chapter in the forthcoming book, Deep Learning and Scientific Computing with R torch, to be published by CRC Press.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>2022-10-13
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#the-plan">The plan</a></li>
<li><a href="#regression-for-weather-prediction">Regression for weather prediction</a></li>
<li><a href="#setting-expectations-with-lm">Setting expectations with <code>lm()</code></a></li>
<li><a href="#using-torch-the-quick-way-linalg_lstsq">Using <code>torch</code>, the quick way: <code>linalg_lstsq()</code></a></li>
<li><a href="#least-squares-i-the-normal-equations">Least squares (I): The normal equations</a></li>
<li><a href="#least-squares-ii-cholesky-decomposition">Least squares (II): Cholesky decomposition</a></li>
<li><a href="#least-squares-iii-lu-factorization">Least squares (III): LU factorization</a></li>
<li><a href="#least-squares-iv-qr-factorization">Least squares (IV): QR factorization</a></li>
<li><a href="#least-squares-v-singular-value-decomposition-svd">Least squares (V): Singular Value Decomposition (SVD)</a></li>
</ul>
</nav>
</div>
<p><em>Note: This post is a condensed version of a chapter from part three of the forthcoming book, Deep Learning and Scientific Computing with R torch. Part three is dedicated to scientific computation beyond deep learning. Throughout the book, I focus on the underlying concepts, striving to explain them in as verbal a way as I can. This does not mean skipping the equations; it means taking care to explain why they are the way they are.</em></p>
<p>How do you compute linear least-squares regression? In R, using <code>lm()</code>; in <code>torch</code>, there is <code>linalg_lstsq()</code>.</p>
<p>Where R, sometimes, hides complexity from the user, high-performance computation frameworks like <code>torch</code> tend to ask for a bit more effort up front, be it careful reading of documentation, or playing around some, or both. For example, here is the central piece of documentation for <code>linalg_lstsq()</code>, elaborating on the <code>driver</code> parameter to the function:</p>
<pre><code>`driver` chooses the LAPACK/MAGMA function that will be used.
For CPU inputs the valid values are &#39;gels&#39;, &#39;gelsy&#39;, &#39;gelsd, &#39;gelss&#39;.
For CUDA input, the only valid driver is &#39;gels&#39;, which assumes that A is full-rank.
To choose the best driver on CPU consider:
  -   If A is well-conditioned (its condition number is not too large), or you do not mind some precision loss:
     -   For a general matrix: &#39;gelsy&#39; (QR with pivoting) (default)
     -   If A is full-rank: &#39;gels&#39; (QR)
  -   If A is not well-conditioned:
     -   &#39;gelsd&#39; (tridiagonal reduction and SVD)
     -   But if you run into memory issues: &#39;gelss&#39; (full SVD).</code></pre>
<p>Whether youll need to know this will depend on the problem youre solving. But if you do, it certainly will help to have an idea of what is alluded to there, if only in a high-level way.</p>
<p>In our example problem below, were going to be lucky. All drivers will return the same result  but only once well have applied a trick, of sorts. The book analyzes why that works; I wont do that here, to keep the post reasonably short. What well do instead is dig deeper into the various methods used by <code>linalg_lstsq()</code>, as well as a few others of common use.</p>
<h2 id="the-plan">The plan</h2>
<p>The way well organize this exploration is by solving a least-squares problem from scratch, making use of various matrix factorizations. Concretely, well approach the task:</p>
<ol type="1">
<li><p>By means of the so-called <em>normal equations</em>, the most direct way, in the sense that it immediately results from a mathematical statement of the problem.</p></li>
<li><p>Again, starting from the normal equations, but making use of <em>Cholesky factorization</em> in solving them.</p></li>
<li><p>Yet again, taking the normal equations for a point of departure, but proceeding by means of <em>LU</em> decomposition.</p></li>
<li><p>Next, employing another type of factorization  <em>QR</em>  that, together with the final one, accounts for the vast majority of decompositions applied in the real world. With QR decomposition, the solution algorithm does not start from the normal equations.</p></li>
<li><p>And, finally, making use of <em>Singular Value Decomposition</em> (SVD). Here, too, the normal equations are not needed.</p></li>
</ol>
<h2 id="regression-for-weather-prediction">Regression for weather prediction</h2>
<p>The dataset well use is available from the <a href="http://archive.ics.uci.edu/ml/machine-learning-dAtAbases/00514/Bias_correction_ucl.csv">UCI Machine Learning Repository</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://torch.mlverse.org/docs'>torch</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://readr.tidyverse.org'>readr</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/nteetor/zeallot'>zeallot</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>uci</span> <span class='op'>&lt;-</span> <span class='st'>"https://archive.ics.uci.edu"</span></span>
<span><span class='va'>ds_path</span> <span class='op'>&lt;-</span> <span class='st'>"ml/machine-learning-databases/00514"</span></span>
<span><span class='va'>ds_file</span> <span class='op'>&lt;-</span> <span class='st'>"Bias_correction_ucl.csv"</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/utils/download.file.html'>download.file</a></span><span class='op'>(</span></span>
<span> <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>uci</span>, <span class='va'>ds_path</span>, <span class='va'>ds_file</span><span class='op'>)</span>,</span>
<span> destfile <span class='op'>=</span> <span class='st'>"resources/matrix-weather.csv"</span></span>
<span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>weather_df</span> <span class='op'>&lt;-</span> <span class='fu'>read_csv</span><span class='op'>(</span><span class='st'>"resources/matrix-weather.csv"</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/stats/na.fail.html'>na.omit</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>weather_df</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://pillar.r-lib.org/reference/glimpse.html'>glimpse</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>Rows: 7,588
Columns: 25
$ station           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,
$ Date              &lt;date&gt; 2013-06-30, 2013-06-30,
$ Present_Tmax      &lt;dbl&gt; 28.7, 31.9, 31.6, 32.0, 31.4, 31.9,
$ Present_Tmin      &lt;dbl&gt; 21.4, 21.6, 23.3, 23.4, 21.9, 23.5,
$ LDAPS_RHmin       &lt;dbl&gt; 58.25569, 52.26340, 48.69048,
$ LDAPS_RHmax       &lt;dbl&gt; 91.11636, 90.60472, 83.97359,
$ LDAPS_Tmax_lapse  &lt;dbl&gt; 28.07410, 29.85069, 30.09129,
$ LDAPS_Tmin_lapse  &lt;dbl&gt; 23.00694, 24.03501, 24.56563,
$ LDAPS_WS          &lt;dbl&gt; 6.818887, 5.691890, 6.138224,
$ LDAPS_LH          &lt;dbl&gt; 69.45181, 51.93745, 20.57305,
$ LDAPS_CC1         &lt;dbl&gt; 0.2339475, 0.2255082, 0.2093437,
$ LDAPS_CC2         &lt;dbl&gt; 0.2038957, 0.2517714, 0.2574694,
$ LDAPS_CC3         &lt;dbl&gt; 0.1616969, 0.1594441, 0.2040915,
$ LDAPS_CC4         &lt;dbl&gt; 0.1309282, 0.1277273, 0.1421253,
$ LDAPS_PPT1        &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000,
$ LDAPS_PPT2        &lt;dbl&gt; 0.000000, 0.000000, 0.000000,
$ LDAPS_PPT3        &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000,
$ LDAPS_PPT4        &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000,
$ lat               &lt;dbl&gt; 37.6046, 37.6046, 37.5776, 37.6450,
$ lon               &lt;dbl&gt; 126.991, 127.032, 127.058, 127.022,
$ DEM               &lt;dbl&gt; 212.3350, 44.7624, 33.3068, 45.7160,
$ Slope             &lt;dbl&gt; 2.7850, 0.5141, 0.2661, 2.5348,
$ `Solar radiation` &lt;dbl&gt; 5992.896, 5869.312, 5863.556,
$ Next_Tmax         &lt;dbl&gt; 29.1, 30.5, 31.1, 31.7, 31.2, 31.5,
$ Next_Tmin         &lt;dbl&gt; 21.2, 22.5, 23.9, 24.3, 22.5, 24.0,</code></pre>
<p>The way were framing the task, nearly everything in the dataset serves as a predictor. As a target, well use <code>Next_Tmax</code>, the maximal temperature reached on the subsequent day. This means we need to remove <code>Next_Tmin</code> from the set of predictors, as it would make for too powerful of a clue. Well do the same for <code>station</code>, the weather station id, and <code>Date</code>. This leaves us with twenty-one predictors, including measurements of actual temperature (<code>Present_Tmax</code>, <code>Present_Tmin</code>), model forecasts of various variables (<code>LDAPS_*</code>), and auxiliary information (<code>lat</code>, <code>lon</code>, and <code>`Solar radiation`</code>, among others).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>weather_df</span> <span class='op'>&lt;-</span> <span class='va'>weather_df</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/select.html'>select</a></span><span class='op'>(</span><span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>station</span>, <span class='va'>Next_Tmin</span>, <span class='va'>Date</span><span class='op'>)</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>  <span class='co'># standardize predictors</span></span>
<span>  <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span><span class='fu'><a href='https://dplyr.tidyverse.org/reference/across.html'>across</a></span><span class='op'>(</span>.fns <span class='op'>=</span> <span class='va'>scale</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Note how, above, Ive added a line to <em>standardize</em> the predictors. This is the trick I was alluding to above. To see what happens without standardization, please check out the book. (The bottom line is: You would have to call <code>linalg_lstsq()</code> with non-default arguments.)</p>
<p>For <code>torch</code>, we split up the data into two tensors: a matrix <code>A</code>, containing all predictors, and a vector <code>b</code> that holds the target.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>weather</span> <span class='op'>&lt;-</span> <span class='fu'>torch_tensor</span><span class='op'>(</span><span class='va'>weather_df</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>A</span> <span class='op'>&lt;-</span> <span class='va'>weather</span><span class='op'>[</span> , <span class='fl'>1</span><span class='op'>:</span><span class='op'>-</span><span class='fl'>2</span><span class='op'>]</span></span>
<span><span class='va'>b</span> <span class='op'>&lt;-</span> <span class='va'>weather</span><span class='op'>[</span> , <span class='op'>-</span><span class='fl'>1</span><span class='op'>]</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>[1] 7588   21</code></pre>
<p>Now, first lets determine the expected output.</p>
<h2 id="setting-expectations-with-lm">Setting expectations with <code>lm()</code></h2>
<p>If theres a least squares implementation we believe in, it surely must be <code>lm()</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>fit</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/lm.html'>lm</a></span><span class='op'>(</span><span class='va'>Next_Tmax</span> <span class='op'>~</span> <span class='va'>.</span> , data <span class='op'>=</span> <span class='va'>weather_df</span><span class='op'>)</span></span>
<span><span class='va'>fit</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span> <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>Call:
lm(formula = Next_Tmax ~ ., data = weather_df)

Residuals:
     Min       1Q   Median       3Q      Max
-1.94439 -0.27097  0.01407  0.28931  2.04015

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        2.605e-15  5.390e-03   0.000 1.000000    
Present_Tmax       1.456e-01  9.049e-03  16.089  &lt; 2e-16 ***
Present_Tmin       4.029e-03  9.587e-03   0.420 0.674312    
LDAPS_RHmin        1.166e-01  1.364e-02   8.547  &lt; 2e-16 ***
LDAPS_RHmax       -8.872e-03  8.045e-03  -1.103 0.270154    
LDAPS_Tmax_lapse   5.908e-01  1.480e-02  39.905  &lt; 2e-16 ***
LDAPS_Tmin_lapse   8.376e-02  1.463e-02   5.726 1.07e-08 ***
LDAPS_WS          -1.018e-01  6.046e-03 -16.836  &lt; 2e-16 ***
LDAPS_LH           8.010e-02  6.651e-03  12.043  &lt; 2e-16 ***
LDAPS_CC1         -9.478e-02  1.009e-02  -9.397  &lt; 2e-16 ***
LDAPS_CC2         -5.988e-02  1.230e-02  -4.868 1.15e-06 ***
LDAPS_CC3         -6.079e-02  1.237e-02  -4.913 9.15e-07 ***
LDAPS_CC4         -9.948e-02  9.329e-03 -10.663  &lt; 2e-16 ***
LDAPS_PPT1        -3.970e-03  6.412e-03  -0.619 0.535766    
LDAPS_PPT2         7.534e-02  6.513e-03  11.568  &lt; 2e-16 ***
LDAPS_PPT3        -1.131e-02  6.058e-03  -1.866 0.062056 .  
LDAPS_PPT4        -1.361e-03  6.073e-03  -0.224 0.822706    
lat               -2.181e-02  5.875e-03  -3.713 0.000207 ***
lon               -4.688e-02  5.825e-03  -8.048 9.74e-16 ***
DEM               -9.480e-02  9.153e-03 -10.357  &lt; 2e-16 ***
Slope              9.402e-02  9.100e-03  10.331  &lt; 2e-16 ***
`Solar radiation`  1.145e-02  5.986e-03   1.913 0.055746 .  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 0.4695 on 7566 degrees of freedom
Multiple R-squared:  0.7802,    Adjusted R-squared:  0.7796
F-statistic:  1279 on 21 and 7566 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>With an explained variance of 78%, the forecast is working pretty well. This is the baseline we want to check all other methods against. To that purpose, well store respective predictions and prediction errors (the latter being operationalized as root mean squared error, RMSE). For now, we just have entries for <code>lm()</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>rmse</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>y_true</span>, <span class='va'>y_pred</span><span class='op'>)</span> <span class='op'>{</span></span>
<span>  <span class='op'>(</span><span class='va'>y_true</span> <span class='op'>-</span> <span class='va'>y_pred</span><span class='op'>)</span><span class='op'>^</span><span class='fl'>2</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'><a href='https://magrittr.tidyverse.org/reference/pipe.html'>%&gt;%</a></span></span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>sqrt</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span>
<span></span>
<span><span class='va'>all_preds</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span></span>
<span>  b <span class='op'>=</span> <span class='va'>weather_df</span><span class='op'>$</span><span class='va'>Next_Tmax</span>,</span>
<span>  lm <span class='op'>=</span> <span class='va'>fit</span><span class='op'>$</span><span class='va'>fitted.values</span></span>
<span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/data.frame.html'>data.frame</a></span><span class='op'>(</span>lm <span class='op'>=</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lm</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span></span></code></pre>
</div>
</div>
<pre><code>       lm
1 40.8369</code></pre>
<h2 id="using-torch-the-quick-way-linalg_lstsq">Using <code>torch</code>, the quick way: <code>linalg_lstsq()</code></h2>
<p>Now, for a moment lets assume this was not about exploring different approaches, but getting a quick result. In <code>torch</code>, we have <code>linalg_lstsq()</code>, a function dedicated specifically to solving least-squares problems. (This is the function whose documentation I was citing, above.) Just like we did with <code>lm()</code>, wed probably just go ahead and call it, making use of the default settings:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>x_lstsq</span> <span class='op'>&lt;-</span> <span class='fu'>linalg_lstsq</span><span class='op'>(</span><span class='va'>A</span>, <span class='va'>b</span><span class='op'>)</span><span class='op'>$</span><span class='va'>solution</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lstsq</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x_lstsq</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>lstsq</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lstsq</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/utils/head.html'>tail</a></span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>              b         lm      lstsq
7583 -1.1380931 -1.3544620 -1.3544616
7584 -0.8488721 -0.9040997 -0.9040993
7585 -0.7203294 -0.9675286 -0.9675281
7586 -0.6239224 -0.9044044 -0.9044040
7587 -0.5275154 -0.8738639 -0.8738635
7588 -0.7846007 -0.8725795 -0.8725792</code></pre>
<p>Predictions resemble those of <code>lm()</code> very closely  so closely, in fact, that we may guess those tiny differences are just due to numerical errors surfacing from deep down the respective call stacks. RMSE, thus, should be equal as well:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>all_errs</span></span></code></pre>
</div>
</div>
<pre><code>       lm    lstsq
1 40.8369 40.8369</code></pre>
<p>It is; and this is a satisfying outcome. However, it only really came about due to that trick: normalization. (Again, I have to ask you to consult the book for details.)</p>
<p>Now, lets explore what we can do without using <code>linalg_lstsq()</code>.</p>
<h2 id="least-squares-i-the-normal-equations">Least squares (I): The normal equations</h2>
<p>We start by stating the goal. Given a matrix, <span class="math inline">\(\mathbf{A}\)</span>, that holds features in its columns and observations in its rows, and a vector of observed outcomes, <span class="math inline">\(\mathbf{b}\)</span>, we want to find regression coefficients, one for each feature, that allow us to approximate <span class="math inline">\(\mathbf{b}\)</span> as well as possible. Call the vector of regression coefficients <span class="math inline">\(\mathbf{x}\)</span>. To obtain it, we need to solve a simultaneous system of equations, that in matrix notation appears as</p>
<p><span class="math display">\[
\mathbf{Ax} = \mathbf{b}
\]</span></p>
<p>If <span class="math inline">\(\mathbf{b}\)</span> were a square, invertible matrix, the solution could directly be computed as <span class="math inline">\(\mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\)</span>. This will hardly ever be possible, though; well (hopefully) always have more observations than predictors. Another approach is needed. It directly starts from the problem statement.</p>
<p>When we use the columns of <span class="math inline">\(\mathbf{A}\)</span> to approximate <span class="math inline">\(\mathbf{b}\)</span>, that approximation necessarily is in the column space of <span class="math inline">\(\mathbf{A}\)</span>. <span class="math inline">\(\mathbf{b}\)</span>, on the other hand, normally wont be. We want those two to be as close as possible. In other words, we want to minimize the distance between them. Choosing the 2-norm for the distance, this yields the objective</p>
<p><span class="math display">\[
minimize \ ||\mathbf{Ax}-\mathbf{b}||^2
\]</span></p>
<p>This distance is the (squared) length of the vector of prediction errors. That vector necessarily is orthogonal to <span class="math inline">\(\mathbf{A}\)</span> itself. That is, when we multiply it with <span class="math inline">\(\mathbf{A}\)</span>, we get the zero vector:</p>
<p><span class="math display">\[
\mathbf{A}^T(\mathbf{Ax} - \mathbf{b}) = \mathbf{0}
\]</span></p>
<p>A rearrangement of this equation yields the so-called <em>normal equations</em>:</p>
<p><span class="math display">\[
\mathbf{A}^T \mathbf{A} \mathbf{x} = \mathbf{A}^T \mathbf{b}
\]</span></p>
<p>These may be solved for <span class="math inline">\(\mathbf{x}\)</span>, computing the inverse of <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>:</p>
<p><span class="math display">\[
\mathbf{x} = (\mathbf{A}^T \mathbf{A})^{-1} \mathbf{A}^T \mathbf{b}
\]</span></p>
<p><span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> is a square matrix. It still might not be invertible, in which case the so-called pseudoinverse would be computed instead. In our case, this will not be needed; we already know <span class="math inline">\(\mathbf{A}\)</span> has full rank, and so does <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>.</p>
<p>Thus, from the normal equations we have derived a recipe for computing <span class="math inline">\(\mathbf{b}\)</span>. Lets put it to use, and compare with what we got from <code>lm()</code> and <code>linalg_lstsq()</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>AtA</span> <span class='op'>&lt;-</span> <span class='va'>A</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>A</span><span class='op'>)</span></span>
<span><span class='va'>Atb</span> <span class='op'>&lt;-</span> <span class='va'>A</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span><span class='va'>inv</span> <span class='op'>&lt;-</span> <span class='fu'>linalg_inv</span><span class='op'>(</span><span class='va'>AtA</span><span class='op'>)</span></span>
<span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='va'>inv</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>Atb</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>neq</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>neq</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>neq</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_errs</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq
1 40.8369 40.8369 40.8369</code></pre>
<p>Having confirmed that the direct way works, we may allow ourselves some sophistication. Four different matrix factorizations will make their appearance: Cholesky, LU, QR, and Singular Value Decomposition. The goal, in every case, is to avoid the expensive computation of the (pseudo-) inverse. Thats what all methods have in common. However, they do not differ just in the way the matrix is factorized, but also, in <em>which</em> matrix is. This has to do with the constraints the various methods impose. Roughly speaking, the order theyre listed in above reflects a falling slope of preconditions, or put differently, a rising slope of generality. Due to the constraints involved, the first two (Cholesky, as well as LU decomposition) will be performed on <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>, while the latter two (QR and SVD) operate on <span class="math inline">\(\mathbf{A}\)</span> directly. With them, there never is a need to compute <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>.</p>
<h2 id="least-squares-ii-cholesky-decomposition">Least squares (II): Cholesky decomposition</h2>
<p>In Cholesky decomposition, a matrix is factored into two triangular matrices of the same size, with one being the transpose of the other. This commonly is written either</p>
<p><span class="math display">\[
\mathbf{A} = \mathbf{L} \mathbf{L}^T
\]</span> or</p>
<p><span class="math display">\[
\mathbf{A} = \mathbf{R}^T\mathbf{R}
\]</span></p>
<p>Here symbols <span class="math inline">\(\mathbf{L}\)</span> and <span class="math inline">\(\mathbf{R}\)</span> denote lower-triangular and upper-triangular matrices, respectively.</p>
<p>For Cholesky decomposition to be possible, a matrix has to be both symmetric and positive definite. These are pretty strong conditions, ones that will not often be fulfilled in practice. In our case, <span class="math inline">\(\mathbf{A}\)</span> is not symmetric. This immediately implies we have to operate on <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> instead. And since <span class="math inline">\(\mathbf{A}\)</span> already is positive definite, we know that <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> is, as well.</p>
<p>In <code>torch</code>, we obtain the Cholesky decomposition of a matrix using <code>linalg_cholesky()</code>. By default, this call will return <span class="math inline">\(\mathbf{L}\)</span>, a lower-triangular matrix.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># AtA = L L_t</span></span>
<span><span class='va'>AtA</span> <span class='op'>&lt;-</span> <span class='va'>A</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>A</span><span class='op'>)</span></span>
<span><span class='va'>L</span> <span class='op'>&lt;-</span> <span class='fu'>linalg_cholesky</span><span class='op'>(</span><span class='va'>AtA</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Lets check that we can reconstruct <span class="math inline">\(\mathbf{A}\)</span> from <span class="math inline">\(\mathbf{L}\)</span>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>LLt</span> <span class='op'>&lt;-</span> <span class='va'>L</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>L</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>diff</span> <span class='op'>&lt;-</span> <span class='va'>LLt</span> <span class='op'>-</span> <span class='va'>AtA</span></span>
<span><span class='fu'>linalg_norm</span><span class='op'>(</span><span class='va'>diff</span>, ord <span class='op'>=</span> <span class='st'>"fro"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>torch_tensor
0.00258896
[ CPUFloatType{} ]</code></pre>
<p>Here, Ive computed the Frobenius norm of the difference between the original matrix and its reconstruction. The Frobenius norm individually sums up all matrix entries, and returns the square root. In theory, wed like to see zero here; but in the presence of numerical errors, the result is sufficient to indicate that the factorization worked fine.</p>
<p>Now that we have <span class="math inline">\(\mathbf{L}\mathbf{L}^T\)</span> instead of <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>, how does that help us? Its here that the magic happens, and youll find the same type of magic at work in the remaining three methods. The idea is that due to some decomposition, a more performant way arises of solving the system of equations that constitute a given task.</p>
<p>With <span class="math inline">\(\mathbf{L}\mathbf{L}^T\)</span>, the point is that <span class="math inline">\(\mathbf{L}\)</span> is triangular, and when thats the case the linear system can be solved by simple substitution. That is best visible with a tiny example:</p>
<p><span class="math display">\[
\begin{bmatrix}
  1 &amp; 0 &amp; 0\\
  2 &amp; 3 &amp; 0\\
  3 &amp; 4 &amp; 1
\end{bmatrix}
\begin{bmatrix}
  x1\\
  x2\\
  x3
\end{bmatrix}
=
\begin{bmatrix}
  1\\
  11\\
  15
\end{bmatrix}
\]</span></p>
<p>Starting in the top row, we immediately see that <span class="math inline">\(x1\)</span> equals <span class="math inline">\(1\)</span>; and once we know <em>that</em> it is straightforward to calculate, from row two, that <span class="math inline">\(x2\)</span> must be <span class="math inline">\(3\)</span>. The last row then tells us that <span class="math inline">\(x3\)</span> must be <span class="math inline">\(0\)</span>.</p>
<p>In code, <code>torch_triangular_solve()</code> is used to efficiently compute the solution to a linear system of equations where the matrix of predictors is lower- or upper-triangular. An additional requirement is for the matrix to be symmetric  but that condition we already had to satisfy in order to be able to use Cholesky factorization.</p>
<p>By default, <code>torch_triangular_solve()</code> expects the matrix to be upper- (not lower-) triangular; but there is a function parameter, <code>upper</code>, that lets us correct that expectation. The return value is a list, and its first item contains the desired solution. To illustrate, here is <code>torch_triangular_solve()</code>, applied to the toy example we manually solved above:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>some_L</span> <span class='op'>&lt;-</span> <span class='fu'>torch_tensor</span><span class='op'>(</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>0</span>, <span class='fl'>2</span>, <span class='fl'>3</span>, <span class='fl'>0</span>, <span class='fl'>3</span>, <span class='fl'>4</span>, <span class='fl'>1</span><span class='op'>)</span>, nrow <span class='op'>=</span> <span class='fl'>3</span>, byrow <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span><span class='op'>)</span></span>
<span><span class='va'>some_b</span> <span class='op'>&lt;-</span> <span class='fu'>torch_tensor</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>11</span>, <span class='fl'>15</span><span class='op'>)</span>, ncol <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span></span>
<span>  <span class='va'>some_b</span>,</span>
<span>  <span class='va'>some_L</span>,</span>
<span>  upper <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>x</span></span></code></pre>
</div>
</div>
<pre><code>torch_tensor
 1
 3
 0
[ CPUFloatType{3,1} ]</code></pre>
<p>Returning to our running example, the normal equations now look like this:</p>
<p><span class="math display">\[
\mathbf{L}\mathbf{L}^T \mathbf{x} = \mathbf{A}^T \mathbf{b}
\]</span></p>
<p>We introduce a new variable, <span class="math inline">\(\mathbf{y}\)</span>, to stand for <span class="math inline">\(\mathbf{L}^T \mathbf{x}\)</span>,</p>
<p><span class="math display">\[
\mathbf{L}\mathbf{y} = \mathbf{A}^T \mathbf{b}
\]</span></p>
<p>and compute the solution to <em>this</em> system:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>Atb</span> <span class='op'>&lt;-</span> <span class='va'>A</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>y</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span></span>
<span>  <span class='va'>Atb</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>,</span>
<span>  <span class='va'>L</span>,</span>
<span>  upper <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<p>Now that we have <span class="math inline">\(y\)</span>, we look back at how it was defined:</p>
<p><span class="math display">\[
\mathbf{y} = \mathbf{L}^T \mathbf{x}
\]</span></p>
<p>To determine <span class="math inline">\(\mathbf{x}\)</span>, we can thus again use <code>torch_triangular_solve()</code>:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span><span class='va'>y</span>, <span class='va'>L</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<p>And there we are.</p>
<p>As usual, we compute the prediction error:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>chol</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>chol</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>chol</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_errs</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol
1 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>Now that youve seen the rationale behind Cholesky factorization  and, as already suggested, the idea carries over to all other decompositions  you might like to save yourself some work making use of a dedicated convenience function, <code>torch_cholesky_solve()</code>. This will render obsolete the two calls to <code>torch_triangular_solve()</code>.</p>
<p>The following lines yield the same output as the code above  but, of course, they <em>do</em> hide the underlying magic.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>L</span> <span class='op'>&lt;-</span> <span class='fu'>linalg_cholesky</span><span class='op'>(</span><span class='va'>AtA</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_cholesky_solve</span><span class='op'>(</span><span class='va'>Atb</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, <span class='va'>L</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>chol2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>chol2</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>chol2</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol   chol2
1 40.8369 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>Lets move on to the next method  equivalently, to the next factorization.</p>
<h2 id="least-squares-iii-lu-factorization">Least squares (III): LU factorization</h2>
<p>LU factorization is named after the two factors it introduces: a lower-triangular matrix, <span class="math inline">\(\mathbf{L}\)</span>, as well as an upper-triangular one, <span class="math inline">\(\mathbf{U}\)</span>. In theory, there are no restrictions on LU decomposition: Provided we allow for row exchanges, effectively turning <span class="math inline">\(\mathbf{A} = \mathbf{L}\mathbf{U}\)</span> into <span class="math inline">\(\mathbf{A} = \mathbf{P}\mathbf{L}\mathbf{U}\)</span> (where <span class="math inline">\(\mathbf{P}\)</span> is a permutation matrix), we can factorize any matrix.</p>
<p>In practice, though, if we want to make use of <code>torch_triangular_solve()</code> , the input matrix has to be symmetric. Therefore, here too we have to work with <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>, not <span class="math inline">\(\mathbf{A}\)</span> directly. (And thats why Im showing LU decomposition right after Cholesky  theyre similar in what they make us do, though not at all similar in spirit.)</p>
<p>Working with <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span> means were again starting from the normal equations. We factorize <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>, then solve two triangular systems to arrive at the final solution. Here are the steps, including the not-always-needed permutation matrix <span class="math inline">\(\mathbf{P}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{A}^T \mathbf{A} \mathbf{x} &amp;= \mathbf{A}^T \mathbf{b} \\
\mathbf{P} \mathbf{L}\mathbf{U} \mathbf{x} &amp;= \mathbf{A}^T \mathbf{b} \\
\mathbf{L} \mathbf{y} &amp;= \mathbf{P}^T \mathbf{A}^T \mathbf{b} \\
\mathbf{y} &amp;= \mathbf{U} \mathbf{x}
\end{aligned}
\]</span></p>
<p>We see that when <span class="math inline">\(\mathbf{P}\)</span> <em>is</em> needed, there is an additional computation: Following the same strategy as we did with Cholesky, we want to move <span class="math inline">\(\mathbf{P}\)</span> from the left to the right. Luckily, what may look expensive  computing the inverse  is not: For a permutation matrix, its transpose reverses the operation.</p>
<p>Code-wise, were already familiar with most of what we need to do. The only missing piece is <code>torch_lu()</code>. <code>torch_lu()</code> returns a list of two tensors, the first a compressed representation of the three matrices <span class="math inline">\(\mathbf{P}\)</span>, <span class="math inline">\(\mathbf{L}\)</span>, and <span class="math inline">\(\mathbf{U}\)</span>. We can uncompress it using <code>torch_lu_unpack()</code> :</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lu</span> <span class='op'>&lt;-</span> <span class='fu'>torch_lu</span><span class='op'>(</span><span class='va'>AtA</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>P</span>, <span class='va'>L</span>, <span class='va'>U</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>torch_lu_unpack</span><span class='op'>(</span><span class='va'>lu</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>lu</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>We move <span class="math inline">\(\mathbf{P}\)</span> to the other side:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>Atb</span> <span class='op'>&lt;-</span> <span class='va'>P</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>Atb</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>All that remains to be done is solve two triangular systems, and we are done:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>y</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span></span>
<span>  <span class='va'>Atb</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>,</span>
<span>  <span class='va'>L</span>,</span>
<span>  upper <span class='op'>=</span> <span class='cn'>FALSE</span></span>
<span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span><span class='va'>y</span>, <span class='va'>U</span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lu</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>lu</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lu</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>[</span><span class='fl'>1</span>, <span class='op'>-</span><span class='fl'>5</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol      lu
1 40.8369 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>As with Cholesky decomposition, we can save ourselves the trouble of calling <code>torch_triangular_solve()</code> twice. <code>torch_lu_solve()</code> takes the decomposition, and directly returns the final solution:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lu</span> <span class='op'>&lt;-</span> <span class='fu'>torch_lu</span><span class='op'>(</span><span class='va'>AtA</span><span class='op'>)</span></span>
<span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_lu_solve</span><span class='op'>(</span><span class='va'>Atb</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, <span class='va'>lu</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>lu</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lu2</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>lu2</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>lu2</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>[</span><span class='fl'>1</span>, <span class='op'>-</span><span class='fl'>5</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol      lu      lu
1 40.8369 40.8369 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>Now, we look at the two methods that dont require computation of <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>.</p>
<h2 id="least-squares-iv-qr-factorization">Least squares (IV): QR factorization</h2>
<p>Any matrix can be decomposed into an orthogonal matrix, <span class="math inline">\(\mathbf{Q}\)</span>, and an upper-triangular matrix, <span class="math inline">\(\mathbf{R}\)</span>. QR factorization is probably the most popular approach to solving least-squares problems; it is, in fact, the method used by Rs <code>lm()</code>. In what ways, then, does it simplify the task?</p>
<p>As to <span class="math inline">\(\mathbf{R}\)</span>, we already know how it is useful: By virtue of being triangular, it defines a system of equations that can be solved step-by-step, by means of mere substitution. <span class="math inline">\(\mathbf{Q}\)</span> is even better. An orthogonal matrix is one whose columns are orthogonal  meaning, mutual dot products are all zero  and have unit norm; and the nice thing about such a matrix is that its inverse equals its transpose. In general, the inverse is hard to compute; the transpose, however, is easy. Seeing how computation of an inverse  solving <span class="math inline">\(\mathbf{x}=\mathbf{A}^{-1}\mathbf{b}\)</span>  is just the central task in least squares, its immediately clear how significant this is.</p>
<p>Compared to our usual scheme, this leads to a slightly shortened recipe. There is no dummy variable <span class="math inline">\(\mathbf{y}\)</span> anymore. Instead, we directly move <span class="math inline">\(\mathbf{Q}\)</span> to the other side, computing the transpose (which <em>is</em> the inverse). All that remains, then, is back-substitution. Also, since every matrix has a QR decomposition, we now directly start from <span class="math inline">\(\mathbf{A}\)</span> instead of <span class="math inline">\(\mathbf{A}^T\mathbf{A}\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{A}\mathbf{x} &amp;= \mathbf{b}\\
\mathbf{Q}\mathbf{R}\mathbf{x} &amp;= \mathbf{b}\\
\mathbf{R}\mathbf{x} &amp;= \mathbf{Q}^T\mathbf{b}\\
\end{aligned}
\]</span></p>
<p>In <code>torch</code>, <code>linalg_qr()</code> gives us the matrices <span class="math inline">\(\mathbf{Q}\)</span> and <span class="math inline">\(\mathbf{R}\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>Q</span>, <span class='va'>R</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>linalg_qr</span><span class='op'>(</span><span class='va'>A</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>On the right side, we used to have a convenience variable holding <span class="math inline">\(\mathbf{A}^T\mathbf{b}\)</span> ; here, we skip that step, and instead, do something immediately useful: move <span class="math inline">\(\mathbf{Q}\)</span> to the other side.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>Qtb</span> <span class='op'>&lt;-</span> <span class='va'>Q</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>The only remaining step now is to solve the remaining triangular system.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'>torch_triangular_solve</span><span class='op'>(</span><span class='va'>Qtb</span><span class='op'>$</span><span class='fu'>unsqueeze</span><span class='op'>(</span><span class='fl'>2</span><span class='op'>)</span>, <span class='va'>R</span><span class='op'>)</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span></span>
<span></span>
<span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>qr</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>qr</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>qr</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>[</span><span class='fl'>1</span>, <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>5</span>,<span class='fl'>7</span><span class='op'>)</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol      lu      qr
1 40.8369 40.8369 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>By now, youll be expecting for me to end this section saying there is also a dedicated solver in <code>torch</code>/<code>torch_linalg</code>, namely ). Well, not literally, no; but effectively, yes. If you call <code>linalg_lstsq()</code> passing <code>driver = "gels"</code>, QR factorization will be used.</p>
<h2 id="least-squares-v-singular-value-decomposition-svd">Least squares (V): Singular Value Decomposition (SVD)</h2>
<p>In true climactic order, the last factorization method we discuss is the most versatile, most diversely applicable, most semantically meaningful one: <em>Singular Value Decomposition (SVD)</em>. The third aspect, fascinating though it is, does not relate to our current task, so I wont go into it here. Here, it is universal applicability that matters: Every matrix can be composed into components SVD-style.</p>
<p>Singular Value Decomposition factors an input <span class="math inline">\(\mathbf{A}\)</span> into two orthogonal matrices, called <span class="math inline">\(\mathbf{U}\)</span> and <span class="math inline">\(\mathbf{V}^T\)</span>, and a diagonal one, named <span class="math inline">\(\mathbf{\Sigma}\)</span>, such that <span class="math inline">\(\mathbf{A} = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^T\)</span>. Here <span class="math inline">\(\mathbf{U}\)</span> and <span class="math inline">\(\mathbf{V}^T\)</span> are the <em>left</em> and <em>right singular vectors</em>, and <span class="math inline">\(\mathbf{\Sigma}\)</span> holds the <em>singular values</em>.</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{A}\mathbf{x} &amp;= \mathbf{b}\\
\mathbf{U}\mathbf{\Sigma}\mathbf{V}^T\mathbf{x} &amp;= \mathbf{b}\\
\mathbf{\Sigma}\mathbf{V}^T\mathbf{x} &amp;= \mathbf{U}^T\mathbf{b}\\
\mathbf{V}^T\mathbf{x} &amp;= \mathbf{y}\\
\end{aligned}
\]</span></p>
<p>We start by obtaining the factorization, using <code>linalg_svd()</code>. The argument <code>full_matrices = FALSE</code> tells <code>torch</code> that we want a <span class="math inline">\(\mathbf{U}\)</span> of dimensionality same as <span class="math inline">\(\mathbf{A}\)</span>, not expanded to 7588 x 7588.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>U</span>, <span class='va'>S</span>, <span class='va'>Vt</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>linalg_svd</span><span class='op'>(</span><span class='va'>A</span>, full_matrices <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>U</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>S</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>Vt</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<pre><code>[1] 7588   21
[1] 21
[1] 21 21</code></pre>
<p>We move <span class="math inline">\(\mathbf{U}\)</span> to the other side  a cheap operation, thanks to <span class="math inline">\(\mathbf{U}\)</span> being orthogonal.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>Utb</span> <span class='op'>&lt;-</span> <span class='va'>U</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>With both <span class="math inline">\(\mathbf{U}^T\mathbf{b}\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> being same-length vectors, we can use element-wise multiplication to do the same for <span class="math inline">\(\mathbf{\Sigma}\)</span>. We introduce a temporary variable, <code>y</code>, to hold the result.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>y</span> <span class='op'>&lt;-</span> <span class='va'>Utb</span> <span class='op'>/</span> <span class='va'>S</span></span></code></pre>
</div>
</div>
<p>Now left with the final system to solve, <span class="math inline">\(\mathbf{\mathbf{V}^T\mathbf{x} = \mathbf{y}}\)</span>, we again profit from orthogonality  this time, of the matrix <span class="math inline">\(\mathbf{V}^T\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>x</span> <span class='op'>&lt;-</span> <span class='va'>Vt</span><span class='op'>$</span><span class='fu'>t</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>y</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Wrapping up, lets calculate predictions and prediction error:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>svd</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>as.matrix</a></span><span class='op'>(</span><span class='va'>A</span><span class='op'>$</span><span class='fu'>matmul</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>all_errs</span><span class='op'>$</span><span class='va'>svd</span> <span class='op'>&lt;-</span> <span class='fu'>rmse</span><span class='op'>(</span><span class='va'>all_preds</span><span class='op'>$</span><span class='va'>b</span>, <span class='va'>all_preds</span><span class='op'>$</span><span class='va'>svd</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>all_errs</span><span class='op'>[</span><span class='fl'>1</span>, <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>5</span>, <span class='fl'>7</span><span class='op'>)</span><span class='op'>]</span></span></code></pre>
</div>
</div>
<pre><code>       lm   lstsq     neq    chol      lu     qr      svd
1 40.8369 40.8369 40.8369 40.8369 40.8369 40.8369 40.8369</code></pre>
<p>That concludes our tour of important least-squares algorithms. Next time, Ill present excerpts from the chapter on the Discrete Fourier Transform (DFT), again reflecting the focus on understanding what its all about. Thanks for reading!</p>
<p>Photo by <a href="https://unsplash.com/@pearseoh?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Pearse OHalloran</a> on <a href="https://unsplash.com/s/photos/squirrel?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<div class="article-footer">
  <p class="social_footer">
    <span class="disqus-comments">
      <i class="fas fa-comments"></i>
      &nbsp;
      <span class="disqus-comment-count" data-disqus-identifier="posts/2022-10-13-torch-linalg/">Comment on this article</span>
    </span>
    <span class="article-sharing">
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Five%20ways%20to%20do%20least%20squares%20%28with%20torch%29&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2022-10-13-torch-linalg%2F" aria-label="share on twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2022-10-13-torch-linalg%2F&amp;title=Five%20ways%20to%20do%20least%20squares%20%28with%20torch%29" aria-label="share on linkedin">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
    </span>
  </p>
  <script id="dsq-count-scr" src="https://tensorflow-for-r-blog.disqus.com/count.js" async></script>
  <div id="disqus_thread" class="hidden"></div>
  <script type="text/javascript" cookie-consent="functionality">
var disqus_config = function () {
  this.page.url = 'https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/';
  this.page.identifier = 'posts/2022-10-13-torch-linalg/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script>
  <p>
    <div class="subscribe">
<div id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy this blog? Get notified of new posts by email:</div>

<script src="https://app-ab02.marketo.com/js/forms2/js/forms2.min.js"></script>
<form class="mtktoBlogEmailForm" id="mktoForm_2224"></form>
<script>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</script>
Posts also available at <a href="https://www.r-bloggers.com">r-bloggers</a>

<script>
  document.addEventListener("DOMContentLoaded", function(){
    var menulink = document.querySelector("a[href='#category:R']");
    if (menulink) menulink.parentNode.style.display = "None";
    
    for (var e of document.querySelectorAll(".dt-tag")) {
      if (e.innerHTML == 'R') e.style.display = "None";
    }
  });
</script>
</div>
  </p>
</div>
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="reuse">Reuse</h3>
  <p>Text and figures are licensed under Creative Commons Attribution <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. The figures that have been reused from other sources don't fall under this license and can be recognized by a note in their caption: "Figure from ...".</p>
  <h3 id="citation">Citation</h3>
  <p>For attribution, please cite this work as</p>
  <pre class="citation-appendix short">Keydana (2022, Oct. 13). RStudio AI Blog: Five ways to do least squares (with torch). Retrieved from https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/</pre>
  <p>BibTeX citation</p>
  <pre class="citation-appendix long">@misc{keydanatorchlinalg,
  author = {Keydana, Sigrid},
  title = {RStudio AI Blog: Five ways to do least squares (with torch)},
  url = {https://blogs.rstudio.com/tensorflow/posts/2022-10-13-torch-linalg/},
  year = {2022}
}</pre>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
